<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="James S. Clark" />

<meta name="date" content="2025-10-28" />

<title>Generalized joint attribute modeling - gjam</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Generalized joint attribute modeling -
gjam</h1>
<h4 class="author"><a href="http://sites.nicholas.duke.edu/clarklab/">James S. Clark</a></h4>
<h4 class="date">2025-10-28</h4>


<div id="TOC">
<ul>
<li><a href="#overview" id="toc-overview"><span style="color:darkgreen">overview</span></a>
<ul>
<li><a href="#model-summary" id="toc-model-summary"><span style="color:teal">model summary</span></a></li>
<li><a href="#data-types" id="toc-data-types"><span style="color:teal">data types</span></a></li>
<li><a href="#effort-and-weight-of-discrete-data" id="toc-effort-and-weight-of-discrete-data"><span style="color:teal">effort and weight of discrete data</span></a></li>
</ul></li>
<li><a href="#using-gjam" id="toc-using-gjam"><span style="color:darkgreen">using gjam</span></a>
<ul>
<li><a href="#simulated-data" id="toc-simulated-data"><span style="color:teal">simulated data</span></a></li>
<li><a href="#my-data" id="toc-my-data"><span style="color:teal">my
data</span></a></li>
</ul></li>
<li><a href="#sensitivity-to-predictors" id="toc-sensitivity-to-predictors"><span style="color:darkgreen">sensitivity to predictors</span></a></li>
<li><a href="#plotting-output" id="toc-plotting-output"><span style="color:darkgreen">plotting output</span></a></li>
<li><a href="#flexibility-in-gjam" id="toc-flexibility-in-gjam"><span style="color:darkgreen">flexibility in gjam</span></a>
<ul>
<li><a href="#heterogeneous-effort" id="toc-heterogeneous-effort"><span style="color:teal">heterogeneous effort</span></a></li>
<li><a href="#specifying-censored-intervals" id="toc-specifying-censored-intervals"><span style="color:teal">specifying censored intervals</span></a></li>
<li><a href="#prior-distribution-on-coefficients" id="toc-prior-distribution-on-coefficients"><span style="color:teal">prior distribution on coefficients</span></a></li>
<li><a href="#species-factor-levels-that-do-not-occur" id="toc-species-factor-levels-that-do-not-occur"><span style="color:teal">species-factor levels that do not
occur</span></a></li>
<li><a href="#sample-effort-in-count-data" id="toc-sample-effort-in-count-data"><span style="color:teal">sample
effort in count data</span></a></li>
<li><a href="#sample-effort-in-composition-data" id="toc-sample-effort-in-composition-data"><span style="color:teal">sample effort in composition data</span></a></li>
<li><a href="#the-partition-in-ordinal-data" id="toc-the-partition-in-ordinal-data"><span style="color:teal">the
partition in ordinal data</span></a></li>
<li><a href="#categorical-data" id="toc-categorical-data"><span style="color:teal">categorical data</span></a></li>
<li><a href="#combinations-of-data-types" id="toc-combinations-of-data-types"><span style="color:teal">combinations of data types</span></a></li>
<li><a href="#random-effects" id="toc-random-effects"><span style="color:teal">random effects</span></a></li>
<li><a href="#missing-data-out-of-sample-prediction" id="toc-missing-data-out-of-sample-prediction"><span style="color:teal">missing data, out-of-sample
prediction</span></a></li>
<li><a href="#prediction-with-heterogenous-effort" id="toc-prediction-with-heterogenous-effort"><span style="color:teal">prediction with heterogenous effort</span></a></li>
<li><a href="#conditional-prediction" id="toc-conditional-prediction"><span style="color:teal">conditional
prediction</span></a></li>
<li><a href="#conditional-parameters" id="toc-conditional-parameters"><span style="color:teal">conditional
parameters</span></a></li>
<li><a href="#presence-only-data-with-effort" id="toc-presence-only-data-with-effort"><span style="color:teal">presence-only data with effort</span></a></li>
</ul></li>
<li><a href="#dimension-reduction" id="toc-dimension-reduction"><span style="color:darkgreen">dimension reduction</span></a>
<ul>
<li><a href="#big-s-composition-data-fungal-endophytes" id="toc-big-s-composition-data-fungal-endophytes"><span style="color:teal"><em>big-S</em> composition data: fungal
endophytes</span></a></li>
<li><a href="#interactions-and-indirect-effects" id="toc-interactions-and-indirect-effects"><span style="color:teal">interactions and indirect effects</span></a></li>
</ul></li>
<li><a href="#joint-trait-modeling" id="toc-joint-trait-modeling"><span style="color:darkgreen">joint trait modeling</span></a>
<ul>
<li><a href="#trait-response-model-trm" id="toc-trait-response-model-trm"><span style="color:teal">trait
response model (TRM)</span></a>
<ul>
<li><a href="#input-data" id="toc-input-data"><span style="color:brown">input data</span></a></li>
<li><a href="#traits-by-species" id="toc-traits-by-species"><span style="color:brown">traits by species</span></a></li>
<li><a href="#factors-in-this-example" id="toc-factors-in-this-example"><span style="color:brown">factors in
this example</span></a></li>
<li><a href="#trm-analysis" id="toc-trm-analysis"><span style="color:brown">TRM analysis</span></a></li>
<li><a href="#interactions-and-indirect-effects-1" id="toc-interactions-and-indirect-effects-1"><span style="color:brown">interactions and indirect effects</span></a></li>
</ul></li>
<li><a href="#predictive-trait-model-ptm" id="toc-predictive-trait-model-ptm"><span style="color:teal">predictive
trait model (PTM)</span></a>
<ul>
<li><a href="#start-with-species-abundance" id="toc-start-with-species-abundance"><span style="color:brown">start
with species abundance</span></a></li>
<li><a href="#trouble-shooting-in-ptm" id="toc-trouble-shooting-in-ptm"><span style="color:brown">trouble
shooting in PTM</span></a></li>
</ul></li>
</ul></li>
<li><a href="#selecting-variables" id="toc-selecting-variables"><span style="color:darkgreen">selecting variables</span></a></li>
<li><a href="#trouble-shooting" id="toc-trouble-shooting"><span style="color:darkgreen">trouble shooting</span></a></li>
<li><a href="#reference-notes" id="toc-reference-notes"><span style="color:darkgreen">reference notes</span></a>
<ul>
<li><a href="#model-summary-1" id="toc-model-summary-1"><span style="color:teal">model summary</span></a></li>
<li><a href="#more-on-parameter-dimensions" id="toc-more-on-parameter-dimensions"><span style="color:teal">more on
parameter dimensions</span></a></li>
<li><a href="#more-on-factors-in-mathbfx" id="toc-more-on-factors-in-mathbfx"><span style="color:teal">more on
factors in <span class="math inline">\(\mathbf{X}\)</span></span></a></li>
</ul></li>
<li><a href="#algorithm-summary" id="toc-algorithm-summary"><span style="color:darkgreen">algorithm summary</span></a></li>
<li><a href="#acknowledgements" id="toc-acknowledgements"><span style="color:darkgreen">acknowledgements</span></a></li>
<li><a href="#references" id="toc-references"><span style="color:darkgreen">references</span></a></li>
</ul>
</div>

<p><strong>version 2.5.2</strong></p>
<p><strong>citation:</strong></p>
<p><em>Clark, J.S., D. Nemergut, B. Seyednasrollah, P. Turner, and S.
Zhang. 2017. Generalized joint attribute modeling for biodiversity
analysis: Median-zero, multivariate, multifarious data, <a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecm.1241">Ecological
Monographs, 87, 34–56.</a></em></p>
<p><a href="http://sites.nicholas.duke.edu/clarklab/code/">website</a></p>
<p><br></p>
<div id="overview" class="section level1">
<h1><span style="color:darkgreen">overview</span></h1>
<p><code>gjam</code> models multivariate responses that can be
combinations of discrete and continuous variables, where interpretation
is needed on the observation scale. It was motivated by the challenges
of modeling distribution and abundance of multiple species, so-called
joint species distribution models (JSDMs). Because species and other
attributes are often recorded on many different scales and with
different levels of sampling effort, many analyses are limited to
presence-absence, the lowest common denominator. Combining species and
other attributes is challenging because some species groups are counted.
Some may be continuous cover values or basal area. Some may be recorded
in ordinal bins, such as ‘rare’, ‘moderate’, and ‘abundant’. Others may
be presence-absence. Some are composition data, either fractional
(continuous on (0, 1)) or counts (e.g., molecular and fossil pollen
data). Attributes such as body condition, infection status, and
herbivore damage are often included in field data. <code>gjam</code>
accommodate multifarious observations.</p>
<p>To allow transparent interpretation <code>gjam</code> avoids
non-linear link functions. This is a departure from generalized linear
models (GLMs) and most hierarchical Bayes models.</p>
<p>The integration of discrete and continuous data on the observed
scales makes use of <em>censoring</em>. Censoring extends a model for
continuous variables across censored intervals. Continuous observations
are uncensored. Censored observations are discrete and can depend on
sample effort.</p>
<p>Censoring is used with the <em>effort</em> for an observation to
combine continuous and discrete variables with appropriate weight. In
count data, effort is determined by the size of the sample plot, search
time, or both. It is comparable to the offset in GLMs. In count
composition data (e.g., microbiome, fossil pollen), effort is the total
count taken over all species. In <code>gjam</code>, discrete
observations can be viewed as censored versions of an underlying
continuous space.</p>
<p><code>gjam</code> generates an object of <code>class</code>
<code>&quot;gjam&quot;</code>, allowing it to appropriate the <code>summary</code>
and <code>print</code> functions in R. To avoid conflicts with other
packages, <code>gjam function</code> names begin with
<code>&quot;gjam&quot;</code>. <code>gjam</code> uses the
<code>RcppArmadillo</code> linear algebra library with the
<code>Rcpp</code> interface library for R/C++.</p>
<div id="model-summary" class="section level2">
<h2><span style="color:teal">model summary</span></h2>
<p>The basic model is detailed in Clark et al. (2017) and summarized at
the end of this vignette (see <strong>reference notes</strong>). An
observation consists of two vectors <span class="math inline">\((\mathbf{x}_i, \mathbf{y}_i)^n_{i = 1}\)</span>,
where <span class="math inline">\(\mathbf{x}_i\)</span> is a
length-<span class="math inline">\(Q\)</span> design vector (intercept
and predictors) and <span class="math inline">\(\mathbf{y}_i\)</span> is
a length-<span class="math inline">\(S\)</span> vector of response
variables, each potentially measured in different ways. <span class="math inline">\(\mathbf{y}_i\)</span> may include both continuous
and discrete variables. There is a latent vector <span class="math inline">\(\mathbf{w}_i\)</span> that represents response
variables all on a continuous scale. The vector <span class="math inline">\(\mathbf{w}_i\)</span> has the joint distribution
<span class="math inline">\(\mathbf{w}_i \sim MVN(\boldsymbol{\mu}_i,
\boldsymbol{\Sigma})\)</span>, where <span class="math inline">\(\boldsymbol{\mu}_i\)</span> is the length-<span class="math inline">\(S\)</span> mean vector, and <span class="math inline">\(\boldsymbol{\Sigma}\)</span>, is an <span class="math inline">\(S \times S\)</span> covariance matrix.</p>
<p>As a data-generating mechanism the model can be thought of like this:
There is a vector of continuous responses <span class="math inline">\(\mathbf{w}_{i}\)</span> generated from mean vector
<span class="math inline">\(\boldsymbol{\mu}_{i}\)</span> and covariance
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> (Fig. 1a). A
partition <span class="math inline">\(\mathbf{p}_{is} = (-\infty, \dots,
\infty)\)</span> segments the real line into intervals, some of which
are censored and others not. Each interval is defined by two values,
<span class="math inline">\((p_{is,k}, p_{is,k+1}]\)</span>. For a value
of <span class="math inline">\(w_{is}\)</span> that falls within a
censored interval <span class="math inline">\(k\)</span> the observed
<span class="math inline">\(y_{is}\)</span> is assigned to discrete
interval <span class="math inline">\(z_{is} = k\)</span>. For a value of
<span class="math inline">\(w_{is}\)</span> that falls in an uncensored
interval <span class="math inline">\(y_{is}\)</span> is assigned <span class="math inline">\(w_{is}\)</span>.</p>
<p>Of course, data present us with the inverse problem: the observed
<span class="math inline">\(y_{is}\)</span> are continuous or discrete,
with known or unknown partition <span class="math inline">\((p_{is,k},
p_{is,k+1}]\)</span> (Fig. 1b). Depending on how the data are observed,
we must impute the elements of <span class="math inline">\(n \times
S\)</span> matrix <span class="math inline">\(\mathbf{W}\)</span> that
lie within censored intervals. Unknown elements of <span class="math inline">\(\mathcal{P}\)</span> will also be imputed in order
to estimate <span class="math inline">\(\mathbf{B}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span>.</p>
<p><br></p>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p><strong>Censoring in gjam.</strong> As a data-generating model (a), a
realization <span class="math inline">\(w_{is}\)</span> that lies within
a censored interval is translated by the partition <span class="math inline">\(\mathbf{p}_{is}\)</span> to discrete <span class="math inline">\(y_{is}\)</span>. The distribution of data (bars at
left) is induced by the latent scale and the partition. For inference
(b), observed discrete <span class="math inline">\(y_{is}\)</span> takes
values on the latent scale from a truncated distribution.</p>
</div>
<div id="data-types" class="section level2">
<h2><span style="color:teal">data types</span></h2>
<p>The different types of data that can be included in the model are
summarized in Table 1, assigned to the <code>character</code> variable
<code>typeNames</code> that is included in the <code>modelList</code>
passed to <code>gjam</code>:</p>
<p><strong>Table 1. Partition for each data type</strong></p>
<table style="width:100%;">
<colgroup>
<col width="8%" />
<col width="12%" />
<col width="16%" />
<col width="40%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><code>typeNames</code></th>
<th align="center">Type</th>
<th align="center">Obs values</th>
<th align="center">Default partition</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>&#39;CON&#39;</code></td>
<td align="center">continuous, uncensored</td>
<td align="center"><span class="math inline">\((-\infty,
\infty)\)</span></td>
<td align="center">none</td>
<td>e.g., centered, standardized</td>
</tr>
<tr class="even">
<td align="center"><code>&#39;CA&#39;</code></td>
<td align="center">continuous abundance</td>
<td align="center"><span class="math inline">\([0, \infty)\)</span></td>
<td align="center"><span class="math inline">\((-\infty, 0,
\infty)\)</span></td>
<td>with zeros</td>
</tr>
<tr class="odd">
<td align="center"><code>&#39;DA&#39;</code></td>
<td align="center">discrete abundance</td>
<td align="center"><span class="math inline">\(\{0, 1, 2, \dots
\}\)</span></td>
<td align="center"><span class="math inline">\((-\infty,
\frac{1}{2E_{i}}, \frac{3}{2E_{i}}, \dots , \frac{max_s(y_{is}) -
1/2}{E_i}, \infty)^1\)</span></td>
<td>e.g., count data</td>
</tr>
<tr class="even">
<td align="center"><code>&#39;PA&#39;</code></td>
<td align="center">presence- absence</td>
<td align="center"><span class="math inline">\(\{0, 1\}\)</span></td>
<td align="center"><span class="math inline">\((-\infty, 0,
\infty)\)</span></td>
<td>unit variance scale</td>
</tr>
<tr class="odd">
<td align="center"><code>&#39;OC&#39;</code></td>
<td align="center">ordinal counts</td>
<td align="center"><span class="math inline">\(\{0, 1, 2, \dots , K
\}\)</span></td>
<td align="center"><span class="math inline">\((-\infty, 0, estimates,
\infty)\)</span></td>
<td>unit variance scale, imputed partition</td>
</tr>
<tr class="even">
<td align="center"><code>&#39;FC&#39;</code></td>
<td align="center">fractional composition</td>
<td align="center"><span class="math inline">\([0, 1]\)</span></td>
<td align="center"><span class="math inline">\((-\infty, 0, 1,
\infty)\)</span></td>
<td>relative abundance</td>
</tr>
<tr class="odd">
<td align="center"><code>&#39;CC&#39;</code></td>
<td align="center">count composition</td>
<td align="center"><span class="math inline">\(\{0, 1, 2, \dots
\}\)</span></td>
<td align="center"><span class="math inline">\((-\infty,
\frac{1}{2E_{i}}, \frac{3}{2E_{i}}, \dots , 1 - \frac{1}{2E_i},
\infty)^1\)</span></td>
<td>relative abundance counts</td>
</tr>
<tr class="even">
<td align="center"><code>&#39;CAT&#39;</code></td>
<td align="center">categorical</td>
<td align="center"><span class="math inline">\(\{0, 1\}\)</span></td>
<td align="center"><span class="math inline">\((-\infty, max_{k}(0,
w_{is,k}), \infty)^2\)</span></td>
<td>unit variance, multiple levels</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(^1\)</span> For <code>&#39;DA&#39;</code> and
<code>&#39;CC&#39;</code> data the second element of the partition is not zero,
but rather depends on effort. There is thus zero-inflation. The default
partition for each data type can be changed with the function
<code>gjamCensorY</code> (see <strong>specifying censored
intervals</strong>).<br />
<span class="math inline">\(^2\)</span> For <code>&#39;CAT&#39;</code> data
species <span class="math inline">\(s\)</span> has <span class="math inline">\(K_s - 1\)</span> non-reference categories. The
category with the largest <span class="math inline">\(w_{is,k}\)</span>
is the ‘1’, all others are zeros.</p>
<p><br></p>
</div>
<div id="effort-and-weight-of-discrete-data" class="section level2">
<h2><span style="color:teal">effort and weight of discrete
data</span></h2>
<p>The partition for a discrete interval <span class="math inline">\(k\)</span> depends on effort for sample <span class="math inline">\(i\)</span></p>
<p><span class="math display">\[(p_{i,k}, p_{i,k+1}] = \left(\frac{k -
1/2}{E_{i}}, \frac{k + 1/2}{E_{i}}\right]\]</span></p>
<p>Effort affects the partition and, thus, the weight of each
observation; wide intervals allow large variance, and vice versa. For
<strong>discrete abundance</strong> (<code>&#39;DA&#39;</code>) data on plots of
a given area, large plots contribute more weight than small plots.
Because plots have different areas one might choose to model <span class="math inline">\(w_{is}\)</span> on a ‘per-area’ scale (density)
rather than a ‘per-plot’ scale. If so, plot area becomes the ‘effort’.
Here is a table of variables for the case where counts represent the
same density of trees per area, but have different effort due to
different plot areas:</p>
<table>
<colgroup>
<col width="25%" />
<col width="19%" />
<col width="27%" />
<col width="5%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">count <span class="math inline">\(y_{is} =
z_{is}\)</span></th>
<th align="center">plot area <span class="math inline">\(E_{i}\)</span></th>
<th align="center">density <span class="math inline">\(w_{is}\)</span></th>
<th align="right">bin <span class="math inline">\(k\)</span></th>
<th align="center">density <span class="math inline">\(\mathbf{p}_{ik}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">10</td>
<td align="center">0.1 ha</td>
<td align="center">100 ha<span class="math inline">\(^{-1}\)</span></td>
<td align="right">11</td>
<td align="center">(95, 105]</td>
</tr>
<tr class="even">
<td align="right">100</td>
<td align="center">1.0 ha</td>
<td align="center">100 ha<span class="math inline">\(^{-1}\)</span></td>
<td align="right">101</td>
<td align="center">(99.5, 100.5]</td>
</tr>
</tbody>
</table>
<p>The wide partition on the 0.1-ha plot admits large variance around
the observation of 10 trees per 0.1 ha plot. Wide variance on an
observation decreases its contribution to the fit. Conversely, the
narrow partition on the 1.0-ha plot constrains density to a narrow
interval around the observed value.</p>
<p>For <strong>composition count</strong> (<code>&#39;CC&#39;</code>) data
effort is represented by the total count. For <span class="math inline">\(0 &lt; y_{is} &lt; E_i\)</span> the variable <span class="math inline">\(0 &lt; w_{is} &lt; 1\)</span>, i.e., the
composition scale. Using the same partition as previously the table for
two observations that represent the fraction 0.10 with different effort
(e.g., total reads in PCR data) looks like this:</p>
<table>
<colgroup>
<col width="25%" />
<col width="18%" />
<col width="20%" />
<col width="9%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">count <span class="math inline">\(y_{is} =
z_{is}\)</span></th>
<th align="right">total count <span class="math inline">\(E_{i}\)</span></th>
<th align="center">fraction <span class="math inline">\(w_{is}\)</span></th>
<th align="right">bin <span class="math inline">\(k\)</span></th>
<th align="center">fraction <span class="math inline">\(\mathbf{p}_{ik}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">10</td>
<td align="right">100</td>
<td align="center">0.1</td>
<td align="right">11</td>
<td align="center">(0.095, 0.105]</td>
</tr>
<tr class="even">
<td align="right">10,000</td>
<td align="right">100,000</td>
<td align="center">0.1</td>
<td align="right">10,001</td>
<td align="center">(0.099995, 0.100005]</td>
</tr>
</tbody>
</table>
<p>Again, on the composition scale <span class="math inline">\([0,
1]\)</span>, weight of the observation is determined by the partition
width and, in turn, effort.</p>
<p><br></p>
</div>
</div>
<div id="using-gjam" class="section level1">
<h1><span style="color:darkgreen">using gjam</span></h1>
<p>It’s easiest to start with the examples from <code>gjam</code> help
pages. This section provides additional examples and explanation.</p>
<div id="simulated-data" class="section level2">
<h2><span style="color:teal">simulated data</span></h2>
<p>Simulated data are used to check that the algorithm can recover true
parameter values and predict data, including underlying latent
variables. To illustrate I simulate a sample of size <span class="math inline">\(n = 500\)</span> for <span class="math inline">\(S
= 10\)</span> species and <span class="math inline">\(Q = 4\)</span>
predictors. To indicate that all species are <em>continuous
abundance</em> data I specify <code>typeNames</code> as
<code>&#39;CA&#39;</code>. <code>CA</code> data are continuous above zero, with
point mass at zero.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(gjam)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(<span class="at">n =</span> <span class="dv">500</span>, <span class="at">S =</span> <span class="dv">10</span>, <span class="at">Q =</span> <span class="dv">4</span>, <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">summary</span>(f)</span></code></pre></div>
<p>The object <code>f</code> includes elements needed to analyze the
simulated data set. <code>f$typeNames</code> is a length-<span class="math inline">\(S\)</span> <code>character vector</code>. The
<code>formula</code> follows standard R syntax. It does not start with
<code>y ~</code>, because gjam is multivariate. The multivariate
response is supplied as a <span class="math inline">\(n \times
S\)</span> <code>matrix</code> or <code>data.frame ydata</code>. Here is
the <code>formula</code> for this example:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>f<span class="sc">$</span>formula</span></code></pre></div>
<p>The simulated parameter values are returned from
<code>gjamSimData</code> in the list <code>f$trueValues</code>, shown in
Table 2, with the corresponding names of estimates from
<code>function gjam</code>, which I discuss below:</p>
<p><strong>Table 2. Variable names and dimensions in simulation and
fitting</strong></p>
<table>
<colgroup>
<col width="9%" />
<col width="35%" />
<col width="8%" />
<col width="12%" />
<col width="35%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">model</th>
<th align="center"><code>$trueValues</code><span class="math inline">\(^{1}\)</span></th>
<th align="center"><code>$parameters</code><span class="math inline">\(^{2}\)</span></th>
<th align="center"><code>$chains</code><span class="math inline">\(^{2}\)</span></th>
<th align="left">dimensions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathbf{B}^3_{Q \times
S}\)</span></td>
<td align="center"><code>beta</code></td>
<td align="center"><code>betaMu</code></td>
<td align="center"><code>bgibbs</code></td>
<td align="left"><span class="math inline">\(W\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathbf{B}^3_{u, Q \times
S}\)</span></td>
<td align="center">-</td>
<td align="center"><code>betaMuUn</code></td>
<td align="center"><code>bgibbsUn</code></td>
<td align="left"><span class="math inline">\(W/X\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\tilde{\mathbf{B}}^3_{Q_1
\times S}\)</span></td>
<td align="center">-</td>
<td align="center"><code>betaStandXmu</code></td>
<td align="center"><code>bFacGibbs</code></td>
<td align="left">dimensionless</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\boldsymbol{\Sigma}_{S
\times S}\)</span></td>
<td align="center"><code>sigma</code></td>
<td align="center"><code>sigMu</code></td>
<td align="center"><code>sgibbs</code></td>
<td align="left"><span class="math inline">\(W_{s}W_{s&#39;}\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathbf{R}_{S \times
S}\)</span></td>
<td align="center"><code>corSpec</code></td>
<td align="center"><code>corMu</code></td>
<td align="center"></td>
<td align="left">correlation</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathbf{f}_{Q_1}^4\)</span></td>
<td align="center">-</td>
<td align="center"><code>fMu</code></td>
<td align="center"><code>fSensGibbs</code></td>
<td align="left">dimensionless</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathbf{F}_{Q_1 \times
Q_1}^4\)</span></td>
<td align="center">-</td>
<td align="center"><code>fmatrix</code></td>
<td align="center"></td>
<td align="left">dimensionless</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathbf{E}_{S \times
S}\)</span></td>
<td align="center">-</td>
<td align="center"><code>ematrix</code></td>
<td align="center">-</td>
<td align="left">dimensionless</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathcal{P}^5\)</span></td>
<td align="center"><code>cuts</code></td>
<td align="center"><code>cutMu</code></td>
<td align="center"><code>cgibbs</code></td>
<td align="left">correlation</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(K^6\)</span></td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center"><code>kgibbs</code></td>
<td align="left">dimensionless</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\sigma^2\)</span> <span class="math inline">\(^6\)</span></td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center"><code>sigErrGibbs</code></td>
<td align="left"><span class="math inline">\(W^2\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\boldsymbol{\alpha}_{Q
\times M}^7\)</span></td>
<td align="center">-</td>
<td align="center"><code>betaTraitMu</code></td>
<td align="center"><code>agibbs</code></td>
<td align="left"><span class="math inline">\(W/X\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\boldsymbol{\Omega}_{M
\times M}^7\)</span></td>
<td align="center">-</td>
<td align="center"><code>sigmaTraitMu</code></td>
<td align="center"><code>mgibbs</code></td>
<td align="left"><span class="math inline">\(W_{m}U_{m&#39;}\)</span>
<span class="math inline">\(^8\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(^1\)</span> simulated object from
<code>gjamSimData</code>.</p>
<p><span class="math inline">\(^2\)</span> fitted object from
<code>gjam</code>.</p>
<p><span class="math inline">\(^3\)</span> coefficients are <span class="math inline">\(\mathbf{B}_u\)</span>: unstandardized; <span class="math inline">\(\mathbf{B}\)</span>: standardized for <span class="math inline">\(\mathbf{X}\)</span>; <span class="math inline">\(\tilde{\mathbf{B}}\)</span>: standardized for
<span class="math inline">\(\mathbf{X}\)</span>, correlation scale for
<span class="math inline">\(\mathbf{W}\)</span> and factor levels
relative to the mean for each factor (see section
<em><span style="color:teal">factors in <span class="math inline">\(\mathbf{X}\)</span></em></span>**).</p>
<p><span class="math inline">\(^4\)</span> sensitivities based on
unstandardized <span class="math inline">\(\mathbf{B}\)</span> and
covariance scales <span class="math inline">\(\Sigma\)</span>.</p>
<p><span class="math inline">\(^5\)</span> Only when <code>ydata</code>
includes ordinal types <code>&quot;OC&quot;</code>.</p>
<p><span class="math inline">\(^6\)</span> Only with dimension
reduction, <code>reductList</code> is included in
<code>modelList</code>.</p>
<p><span class="math inline">\(^7\)</span> Only for trait analysis,
<code>traitList</code> is included in <code>modelList</code> (Trait
vignette).</p>
<p><br></p>
<p>The dimension for response <span class="math inline">\(Y\)</span> is
<span class="math inline">\(W \times E\)</span>, where <span class="math inline">\(W\)</span> is the latent variable scale, and <span class="math inline">\(E\)</span> is sample effort. When effort <span class="math inline">\(E\)</span> = 1, then <span class="math inline">\(Y\)</span> and <span class="math inline">\(W\)</span> have the same dimension.</p>
<p>The matrix <span class="math inline">\(\mathbf{F}\)</span> contains
the covariance between predictors in <span class="math inline">\(\mathbf{X}\)</span> in terms of the responses they
elicit from <span class="math inline">\(\mathbf{Y}\)</span>. The
diagonal vector <span class="math inline">\(\mathbf{f} = diag(
\mathbf{F} )\)</span> is the sensitivity of the entire response matrix
to each predictor in <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>The matrix <span class="math inline">\(\mathbf{E}\)</span> is the
correlation among species in terms of their responses to <span class="math inline">\(\mathbf{X}\)</span>. Relationships to outputs are
discussed in the <strong>Reference notes</strong>.</p>
<p>Simulated data are typical of real data in that there is a large
fraction of zeros.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">bty =</span> <span class="st">&#39;n&#39;</span>, <span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">family=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="fu">hist</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,f<span class="sc">$</span>y), <span class="at">nclass =</span> <span class="dv">50</span>, <span class="at">plot =</span> F)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="fu">plot</span>( h<span class="sc">$</span>counts, h<span class="sc">$</span>mids,<span class="at">type =</span> <span class="st">&#39;s&#39;</span> )</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>w,f<span class="sc">$</span>y,<span class="at">cex =</span> .<span class="dv">2</span> )</span></code></pre></div>
<p><br></p>
<p>Here is a short Gibbs sampler to estimate parameters and fit the
data. The function <code>gjam</code> needs the <code>formula</code> for
the model, the <code>data.frame xdata</code>, which includes the
predictors, the response <code>matrix</code> or
<code>data.frame ydata</code>, and a <code>modelList</code> specifying
number of Gibbs steps <code>ng</code>, the <code>burnin</code>, and
<code>typeNames</code>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">1000</span>, <span class="at">burnin =</span> <span class="dv">100</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="fu">summary</span>(out)</span></code></pre></div>
<p>The <code>print</code> function acts like <code>summary</code></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">print</span>(out)</span></code></pre></div>
<p>Among the objects to consider initially are the design matrix
<code>out$inputs$xUnstand</code>, response matrix
<code>out$inputs$y</code>, and the MCMC <code>out$chains</code> with
these names and sizes:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">summary</span>(out<span class="sc">$</span>chains)</span></code></pre></div>
<p><code>$chains</code> is a list of matrices, each with <code>ng</code>
rows and as many columns as needed to hold parameter estimates. For
example, each row of <code>$chains$bgibbs</code> is a length-<span class="math inline">\(QS\)</span> vector of values for the <span class="math inline">\(Q \times S\)</span> matrix <span class="math inline">\(\mathbf{B}\)</span>, standardized for <span class="math inline">\(\mathbf{X}\)</span>. In other words, a coefficient
<span class="math inline">\(\mathbf{B}_{qs}\)</span> has the units of
<span class="math inline">\(w_s\)</span>. <code>$chains$sgibbs</code>
holds either the <span class="math inline">\(S(S + 1)/2\)</span> unique
values of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> or
the <span class="math inline">\(N \times r\)</span> unique values of the
dimension reduced covariance matrix. A summary of the
<code>chains</code> is given in Table 2.</p>
<p>Additional summaries are available in the list
<code>inputs</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">summary</span>(out<span class="sc">$</span>inputs)</span></code></pre></div>
<p>The matrix <code>classBySpec</code> shows the number of observations
in each interval. For this example of continuous data censored at zero,
the two labels are <span class="math inline">\(k \in \{0, 1\}\)</span>
corresponding to the intervals <span class="math inline">\((p_{s,0},
p_{s,1}] = (-\infty,0]\)</span> and <span class="math inline">\((p_{s,1}, p_{s,2}) = (0, \infty)\)</span>. The
length-<span class="math inline">\((K + 1)\)</span> partition vector is
the same for all species, <span class="math inline">\(\mathbf{p} =
(-\infty, 0, \infty)\)</span>. Here is <code>classBySpec</code> for this
example:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>out<span class="sc">$</span>inputs<span class="sc">$</span>classBySpec</span></code></pre></div>
<p>The first interval is censored (all values of <span class="math inline">\(y_{is}\)</span> = 0). The second interval is not
censored (<span class="math inline">\(y_{is} = w_{is}\)</span>).</p>
<p>The fitted coefficients in <code>$parameters</code>, as summarized in
Table 2. For example, here is posterior mean estimate of unstandardized
coefficients <span class="math inline">\(\mathbf{B}_u\)</span>,</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaMu</span></code></pre></div>
<p>Here are posterior summaries,</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaMu         <span class="co"># S by M coefficient matrix unstandardized</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaSe         <span class="co"># S by M coefficient SE</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXmu   <span class="co"># S by M standardized for X</span></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXWmu  <span class="co"># (S-F) by M standardized for W/X, centered factors</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTable        <span class="co"># SM by stats posterior summary</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXTable  <span class="co"># SM by stats posterior summary</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXWTable <span class="co"># (S-F)M by stats posterior summary</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sensBeta         <span class="co"># sensitivity to response variables</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sensTable        <span class="co"># sensitivity to predictor variables</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a> </span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sigMu            <span class="co"># S by S covariance matrix omega</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sigSe            <span class="co"># S by S covariance std errors</span></span></code></pre></div>
<p>Again, check Table 2 for names of all fitted coefficients.</p>
<p>The data are also predicted in <code>gjam</code>, summarized by
predictive means and standard errors. These are contained in <span class="math inline">\(n \times Q\)</span> matrices
<code>$prediction$xpredMu</code> and <code>$prediction$xpredSd</code>
and <span class="math inline">\(n \times S\)</span> matrices
<code>$prediction$ypredMu</code> and <code>$prediction$ypredSd</code>.
These are in-sample predictions.</p>
<p>The output can be viewed with the function <code>gjamPlot</code>:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">n =</span> <span class="dv">500</span>, <span class="at">S =</span> <span class="dv">10</span>, <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span> )</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">1000</span>, <span class="at">burnin =</span> <span class="dv">200</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">trueValues =</span> f<span class="sc">$</span>trueValues, <span class="at">GRIDPLOTS =</span> T )</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> pl )</span></code></pre></div>
<p><code>gjamPlot</code> creates a number of plots comparing true and
estimated parameters (for simulated data).</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">par</span>( <span class="at">bty =</span> <span class="st">&#39;n&#39;</span>, <span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>) )</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>trueValues<span class="sc">$</span>beta, out<span class="sc">$</span>parameters<span class="sc">$</span>betaMu, <span class="at">cex =</span> .<span class="dv">2</span> )</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>trueValues<span class="sc">$</span>corSpec, out<span class="sc">$</span>parameters<span class="sc">$</span>corMu, <span class="at">cex =</span> .<span class="dv">2</span> )</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>y,out<span class="sc">$</span>prediction<span class="sc">$</span>ypredMu, <span class="at">cex =</span> .<span class="dv">2</span> )</span></code></pre></div>
<p>To process the output beyond what is provided in
<code>gjamPlot</code> I can work directly with the
<code>chains</code>.</p>
</div>
<div id="my-data" class="section level2">
<h2><span style="color:teal">my data</span></h2>
<p><code>gjam</code> uses the standard <code>R</code> syntax in the
<code>formula</code> that I would use with functions like
<code>lm</code> and <code>glm</code>. Because <code>gjam</code> uses
inverse prediction to summarize large multivariate output, it is
important to abide by this syntax. For example, to analyze a model with
quadratic and interaction terms, I might simply construct my own design
matrix with these columns included, i.e., side-stepping the standard
syntax for these effects that can be specified in <code>formula</code>.
This would be fine for model fitting. However, without specifying this
in the <code>formula</code> there is no way for <code>gjam</code> to
know that these columns are in fact non-linear transformations of other
columns. Without this knowledge there is no way to properly predict
them. The prediction that <code>gjam</code> would return would include
silly variable combinations.</p>
<p>To illustrate proper model specification I use a few lines from the
<code>data.frame</code> of predictors in the <code>forestTraits</code>
data set:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">library</span>(repmis)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="st">&quot;https://github.com/jimclarkatduke/gjam/blob/master/forestTraits.RData?raw=True&quot;</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="fu">source_data</span>(d)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>xdata <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>xdata[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">7</span>,<span class="dv">8</span>)]</span></code></pre></div>
<p>Here are a few rows:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>xdata[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span></code></pre></div>
<p>Here is a simple model specification with <code>as.formula()</code>
that includes only main effects:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>( <span class="sc">~</span> temp <span class="sc">+</span> deficit <span class="sc">+</span> soil )</span></code></pre></div>
<p>The design matrix <code>x</code> that is generated in
<code>gjam</code> has an intercept, two covariates, and four columns for
the multilevel factor <code>soil</code>:</p>
<pre><code>##   (Intercept)  temp deficit soilreference
## 1           1  1.22    0.04             1
## 2           1  0.18    0.21             1
## 3           1 -0.94    0.20             0
## 4           1  0.64    0.82             1
## 5           1  0.82   -0.18             1</code></pre>
<p>To include interactions between <code>temp</code> and
<code>soil</code> I use the symbol ‘<code>*</code>’:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>( <span class="sc">~</span> temp<span class="sc">*</span>soil )</span></code></pre></div>
<p>Here is the design matrix that results from this <code>formula</code>
with interaction terms indicated by the symbol <code>&#39;:&#39;</code></p>
<pre><code>##   (Intercept)  temp soilreference temp:soilreference
## 1           1  1.22             1               1.22
## 2           1  0.18             1               0.18
## 3           1 -0.94             0               0.00
## 4           1  0.64             1               0.64
## 5           1  0.82             1               0.82</code></pre>
<p>For a quadratic term I use the <code>R</code> function
<code>I()</code>:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>( <span class="sc">~</span> temp <span class="sc">+</span> <span class="fu">I</span>(temp<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> deficit )</span></code></pre></div>
<p>Here is the design matrix with linear and quadratic terms:</p>
<pre><code>##   (Intercept)  temp I(temp^2) deficit
## 1           1  1.22    1.4884    0.04
## 2           1  0.18    0.0324    0.21
## 3           1 -0.94    0.8836    0.20
## 4           1  0.64    0.4096    0.82
## 5           1  0.82    0.6724   -0.18</code></pre>
<p>Here is a quadratic response surface for <code>temp</code> and
<code>deficit</code>:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>( <span class="sc">~</span> temp<span class="sc">*</span>deficit <span class="sc">+</span> <span class="fu">I</span>(temp<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(deficit<span class="sc">^</span><span class="dv">2</span>) )</span></code></pre></div>
<p>Here is the design matrix with all combinations:</p>
<pre><code>##   (Intercept)  temp deficit I(temp^2) I(deficit^2) temp:deficit
## 1           1  1.22    0.04    1.4884       0.0016       0.0488
## 2           1  0.18    0.21    0.0324       0.0441       0.0378
## 3           1 -0.94    0.20    0.8836       0.0400      -0.1880
## 4           1  0.64    0.82    0.4096       0.6724       0.5248
## 5           1  0.82   -0.18    0.6724       0.0324      -0.1476</code></pre>
<p>These are examples of the <code>formula</code> options available in
<code>gjam</code>. Using them will allow for proper inverse prediction
of <code>x</code>. To optimize MCMC, gjam does not predict
<code>x</code> for higher order polynomials–they are rarely used, being
both hard to interpret and a cause of unstable predictions. To
accelerate MCMC I can set <code>PREDICTX = F</code> in the
<code>modelList</code>.</p>
<p>I can use this model to analyze a tree data set. For my data set I
use the tree data contained in <code>forestTraits</code>. It is stored
in de-zeroed (sparse matrix) format, so I extract it with the function
<code>gjamReZero</code>. Here are dimensions and the upper left corner
of the response matrix <span class="math inline">\(\mathbf{Y}\)</span>,</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>y  <span class="ot">&lt;-</span> <span class="fu">gjamReZero</span>(forestTraits<span class="sc">$</span>treesDeZero)  <span class="co"># extract y</span></span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>treeYdata  <span class="ot">&lt;-</span> <span class="fu">gjamTrimY</span>(y,<span class="dv">10</span>)<span class="sc">$</span>y             <span class="co"># at least 10 plots</span></span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a><span class="fu">dim</span>(treeYdata)</span>
<span id="cb23-4"><a href="#cb23-4" tabindex="-1"></a>treeYdata[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<p>In code that follows I treat responses as discrete counts,
<code>typeNames = &#39;DA&#39;</code>. Because of the large number of columns
(98) I speed things up by calling for dimension reduction, passed as
<span class="math inline">\(N \times r = 20 \times 8\)</span>:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>ml   <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2500</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> <span class="st">&#39;DA&#39;</span>, </span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>              <span class="at">reductList =</span> <span class="fu">list</span>(<span class="at">r =</span> <span class="dv">8</span>, <span class="at">N =</span> <span class="dv">20</span>) )</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>form <span class="ot">&lt;-</span> <span class="fu">as.formula</span>( <span class="sc">~</span> temp<span class="sc">*</span>deficit <span class="sc">+</span> <span class="fu">I</span>(temp<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">I</span>(deficit<span class="sc">^</span><span class="dv">2</span>) )</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>out  <span class="ot">&lt;-</span> <span class="fu">gjam</span>(form, <span class="at">xdata =</span> xdata, <span class="at">ydata =</span> treeYdata, <span class="at">modelList =</span> ml)</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>specNames <span class="ot">&lt;-</span> <span class="fu">colnames</span>(treeYdata)</span>
<span id="cb24-6"><a href="#cb24-6" tabindex="-1"></a>specColor <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;black&#39;</span>,<span class="fu">ncol</span>(treeYdata))</span>
<span id="cb24-7"><a href="#cb24-7" tabindex="-1"></a>specColor[ <span class="fu">c</span>(<span class="fu">grep</span>(<span class="st">&#39;quer&#39;</span>,specNames),<span class="fu">grep</span>(<span class="st">&#39;cary&#39;</span>,specNames)) ] <span class="ot">&lt;-</span> <span class="st">&#39;#d95f02&#39;</span></span>
<span id="cb24-8"><a href="#cb24-8" tabindex="-1"></a>specColor[ <span class="fu">c</span>(<span class="fu">grep</span>(<span class="st">&#39;acer&#39;</span>,specNames),<span class="fu">grep</span>(<span class="st">&#39;frax&#39;</span>,specNames)) ] <span class="ot">&lt;-</span> <span class="st">&#39;#1b9e77&#39;</span></span>
<span id="cb24-9"><a href="#cb24-9" tabindex="-1"></a>specColor[ <span class="fu">c</span>(<span class="fu">grep</span>(<span class="st">&#39;abie&#39;</span>,specNames),<span class="fu">grep</span>(<span class="st">&#39;pice&#39;</span>,specNames)) ] <span class="ot">&lt;-</span> <span class="st">&#39;#377eb8&#39;</span></span>
<span id="cb24-10"><a href="#cb24-10" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> <span class="fu">list</span>(<span class="at">GRIDPLOTS=</span>T, <span class="at">specColor =</span> specColor) )</span></code></pre></div>
<p>Additional information on variable types and their treatment in
<code>gjam</code> is included later in this document and in the other
<code>gjam vignettes</code>.</p>
<p><br></p>
</div>
</div>
<div id="sensitivity-to-predictors" class="section level1">
<h1><span style="color:darkgreen">sensitivity to predictors</span></h1>
<p>The sensitivity of an individual response variable <span class="math inline">\(s\)</span> to an individual predictor <span class="math inline">\(q\)</span> is given by the coefficient <span class="math inline">\(\beta_{qs}\)</span>. This granularity is useful,
but it is often desirable to have a sensitivity that applies to the full
response matrix. That sensitivity is given by</p>
<p><span class="math display">\[
\mathbf{f} = diag \left( \mathbf{B} \Sigma^{-1} \mathbf{B&#39;} \right)
\]</span> (Brynjarsdottir and Gelfand. 2014, Clark et al. 2017). These
coefficients are evaluated on the scale that is standardized scale for
<span class="math inline">\(\mathbf{X}\)</span> and correlation scale
<span class="math inline">\(\mathbf{Y}\)</span>–they are dimensionless.
In the notation of the Appendix this is <span class="math inline">\(\mathbf{B}_r\)</span>. A plot of these values is
displayed when I call <code>gjamPlot</code>.</p>
<p>I can also evaluate sensitivity for a species group <span class="math inline">\(g\)</span> as</p>
<p><span class="math display">\[
\mathbf{f}_g = diag \left( \mathbf{B}_g \Sigma_g^{-1} \mathbf{B&#39;}_g
\right)
\]</span> where <span class="math inline">\(\mathbf{B}_g\)</span>
includes columns for the species in group <span class="math inline">\(g\)</span>, and <span class="math inline">\(\Sigma_g\)</span> is the covariance matrix for
group <span class="math inline">\(g\)</span> conditional on remaining
species in the model.</p>
<p>In the help page for the function <code>gjamSensitivity</code> is
this example comparing sensitivity for a simulated data set with
multiple data types against a group that includes only the composition
count (<code>&#39;CC&#39;</code>) data. Note that the latter is supplied
identified by <code>group</code>, which is a
<code>character string</code> of column names in <code>ydata</code>:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>cols  <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">&#39;#1f78b4&#39;</span>, <span class="st">&#39;#33a02c&#39;</span> )</span>
<span id="cb25-2"><a href="#cb25-2" tabindex="-1"></a>types <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;DA&#39;</span>,<span class="st">&#39;DA&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CA&#39;</span>,<span class="st">&#39;CA&#39;</span>,<span class="st">&#39;PA&#39;</span>,<span class="st">&#39;PA&#39;</span>)         </span>
<span id="cb25-3"><a href="#cb25-3" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(<span class="at">S =</span> <span class="fu">length</span>(types), <span class="at">typeNames =</span> types)</span>
<span id="cb25-4"><a href="#cb25-4" tabindex="-1"></a>ml    <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng =</span> <span class="dv">500</span>, <span class="at">burnin =</span> <span class="dv">50</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames)</span>
<span id="cb25-5"><a href="#cb25-5" tabindex="-1"></a>out   <span class="ot">&lt;-</span> <span class="fu">gjam</span>(f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml)</span>
<span id="cb25-6"><a href="#cb25-6" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" tabindex="-1"></a>ynames <span class="ot">&lt;-</span> <span class="fu">colnames</span>(f<span class="sc">$</span>y)</span>
<span id="cb25-8"><a href="#cb25-8" tabindex="-1"></a>group  <span class="ot">&lt;-</span> ynames[types <span class="sc">==</span> <span class="st">&#39;CC&#39;</span>]</span>
<span id="cb25-9"><a href="#cb25-9" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" tabindex="-1"></a>full <span class="ot">&lt;-</span> <span class="fu">gjamSensitivity</span>(out)</span>
<span id="cb25-11"><a href="#cb25-11" tabindex="-1"></a>cc   <span class="ot">&lt;-</span> <span class="fu">gjamSensitivity</span>(out, group)</span>
<span id="cb25-12"><a href="#cb25-12" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">range</span>( <span class="fu">c</span>(full, cc) )</span>
<span id="cb25-13"><a href="#cb25-13" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" tabindex="-1"></a>nt <span class="ot">&lt;-</span> <span class="fu">ncol</span>(full)</span>
<span id="cb25-15"><a href="#cb25-15" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" tabindex="-1"></a><span class="fu">boxplot</span>( full, <span class="at">boxwex =</span> <span class="fl">0.2</span>,  <span class="at">at =</span> <span class="dv">1</span><span class="sc">:</span>nt <span class="sc">-</span> .<span class="dv">15</span>, <span class="at">col =</span> cols[<span class="dv">1</span>], <span class="at">log=</span><span class="st">&#39;y&#39;</span>,</span>
<span id="cb25-17"><a href="#cb25-17" tabindex="-1"></a>         <span class="at">ylim =</span> ylim, <span class="at">xaxt =</span> <span class="st">&#39;n&#39;</span>, <span class="at">xlab =</span> <span class="st">&#39;Predictors&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Sensitivity&#39;</span>)</span>
<span id="cb25-18"><a href="#cb25-18" tabindex="-1"></a><span class="fu">boxplot</span>( cc, <span class="at">boxwex =</span> <span class="fl">0.2</span>, <span class="at">at =</span> <span class="dv">1</span><span class="sc">:</span>nt <span class="sc">+</span> .<span class="dv">15</span>, <span class="at">col =</span> cols[<span class="dv">2</span>], <span class="at">add=</span>T,</span>
<span id="cb25-19"><a href="#cb25-19" tabindex="-1"></a>         <span class="at">xaxt =</span> <span class="st">&#39;n&#39;</span>)</span>
<span id="cb25-20"><a href="#cb25-20" tabindex="-1"></a><span class="fu">axis</span>( <span class="dv">1</span>, <span class="at">at=</span><span class="dv">1</span><span class="sc">:</span>nt,<span class="at">labels=</span><span class="fu">colnames</span>(full) )</span>
<span id="cb25-21"><a href="#cb25-21" tabindex="-1"></a><span class="fu">legend</span>( <span class="st">&#39;bottomright&#39;</span>,<span class="fu">c</span>(<span class="st">&#39;full response&#39;</span>,<span class="st">&#39;CC data&#39;</span>),</span>
<span id="cb25-22"><a href="#cb25-22" tabindex="-1"></a>        <span class="at">text.col =</span> cols, <span class="at">bty=</span><span class="st">&#39;n&#39;</span> )</span></code></pre></div>
<p>Again, the scale is dimensionless. Here is a comparison between two
groups:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>group  <span class="ot">&lt;-</span> ynames[types <span class="sc">==</span> <span class="st">&#39;CA&#39;</span>]</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>ca   <span class="ot">&lt;-</span> <span class="fu">gjamSensitivity</span>(out, group)</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" tabindex="-1"></a>ylim <span class="ot">&lt;-</span> <span class="fu">range</span>( <span class="fu">rbind</span>(cc,ca) )</span>
<span id="cb26-5"><a href="#cb26-5" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" tabindex="-1"></a>nt <span class="ot">&lt;-</span> <span class="fu">ncol</span>(full)</span>
<span id="cb26-7"><a href="#cb26-7" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" tabindex="-1"></a><span class="fu">boxplot</span>( ca, <span class="at">boxwex =</span> <span class="fl">0.2</span>,  <span class="at">at =</span> <span class="dv">1</span><span class="sc">:</span>nt <span class="sc">-</span> .<span class="dv">15</span>, <span class="at">col =</span> cols[<span class="dv">1</span>], <span class="at">log=</span><span class="st">&#39;y&#39;</span>,</span>
<span id="cb26-9"><a href="#cb26-9" tabindex="-1"></a>         <span class="at">xaxt =</span> <span class="st">&#39;n&#39;</span>, <span class="at">ylim =</span> ylim, <span class="at">xlab =</span> <span class="st">&#39;Predictors&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Sensitivity&#39;</span>)</span>
<span id="cb26-10"><a href="#cb26-10" tabindex="-1"></a><span class="fu">boxplot</span>( cc, <span class="at">boxwex =</span> <span class="fl">0.2</span>, <span class="at">at =</span> <span class="dv">1</span><span class="sc">:</span>nt <span class="sc">+</span> .<span class="dv">15</span>, <span class="at">col =</span> cols[<span class="dv">2</span>], <span class="at">add=</span>T,</span>
<span id="cb26-11"><a href="#cb26-11" tabindex="-1"></a>         <span class="at">xaxt =</span> <span class="st">&#39;n&#39;</span>)</span>
<span id="cb26-12"><a href="#cb26-12" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>,<span class="at">at=</span><span class="dv">1</span><span class="sc">:</span>nt,<span class="at">labels=</span><span class="fu">colnames</span>(full))</span>
<span id="cb26-13"><a href="#cb26-13" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&#39;bottomright&#39;</span>,<span class="fu">c</span>(<span class="st">&#39;CA data&#39;</span>,<span class="st">&#39;CC data&#39;</span>),</span>
<span id="cb26-14"><a href="#cb26-14" tabindex="-1"></a>       <span class="at">text.col =</span> cols, <span class="at">bty =</span> <span class="st">&#39;n&#39;</span> )</span></code></pre></div>
<p><br></p>
</div>
<div id="plotting-output" class="section level1">
<h1><span style="color:darkgreen">plotting output</span></h1>
<p>In the foregoing example arguments passed to <code>gjamPlot</code> in
the <code>list plotPars</code> included <code>SMALLPLOTS = F</code> (do
not compress margins and axes), <code>GRIDPLOTS = T</code> (draw grid
diagrams as heat maps for parameter values and predictions). In this
section I summarize plots generated by <code>gjamPlot</code>.</p>
<p>By default, plots are rendered to the screen. I enter ‘return’ to
render the next plot. Faster execution obtains if I write plots directly
to pdf files, with <code>SAVEPLOTS = T</code>. I can specify a folder
this way:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>plotPars <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">GRIDPLOTS=</span>T, <span class="at">SAVEPLOTS =</span> T, <span class="at">outfolder =</span> <span class="st">&#39;plots&#39;</span> )</span></code></pre></div>
<p>In all plots, posterior distributions and predictions are shown as
<span class="math inline">\(68\%\)</span> (boxes) and <span class="math inline">\(95\%\)</span> (whiskers) intervals, respectively.
Here are the plots in alphabetical order by file name:</p>
<table>
<colgroup>
<col width="17%" />
<col width="82%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Name</th>
<th align="left">Comments</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>betaAll</code></td>
<td align="left">Posterior <span class="math inline">\(\mathbf{B}\)</span></td>
</tr>
<tr class="even">
<td align="right"><code>beta_(variable)</code></td>
<td align="left">Posterior distributions, one file per variable</td>
</tr>
<tr class="odd">
<td align="right"><code>betaChains</code></td>
<td align="left">Example MCMC chains for <span class="math inline">\(\mathbf{B}\)</span> (has it converged?)</td>
</tr>
<tr class="even">
<td align="right"><code>clusterDataE</code></td>
<td align="left">Cluster analysis of raw data and <span class="math inline">\(\textbf{E}\)</span> matrix</td>
</tr>
<tr class="odd">
<td align="right"><code>clusterGridB</code></td>
<td align="left">Cluster and grid plot of <span class="math inline">\(\mathbf{E}\)</span> and <span class="math inline">\(\mathbf{B}\)</span></td>
</tr>
<tr class="even">
<td align="right"><code>clusterGridE</code></td>
<td align="left">Cluster and grid plot of <span class="math inline">\(\mathbf{E}\)</span></td>
</tr>
<tr class="odd">
<td align="right"><code>clusterGridR</code></td>
<td align="left">Cluster and grid plot of <span class="math inline">\(\mathbf{R}\)</span></td>
</tr>
<tr class="even">
<td align="right"><code>corChains</code></td>
<td align="left">Example MCMC chains for <span class="math inline">\(\textbf{R}\)</span></td>
</tr>
<tr class="odd">
<td align="right"><code>dimRed</code></td>
<td align="left">Dimension reduction (see <code>vignette</code>) for
<span class="math inline">\(\Sigma\)</span> matrix</td>
</tr>
<tr class="even">
<td align="right"><code>gridF_B</code></td>
<td align="left">Grid plot of sensitivity <span class="math inline">\(\mathbf{F}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>, ordered by clustering <span class="math inline">\(\mathbf{F}\)</span></td>
</tr>
<tr class="odd">
<td align="right"><code>gridR_E</code></td>
<td align="left">Grid plot of <span class="math inline">\(\mathbf{R}\)</span> and <span class="math inline">\(\mathbf{E}\)</span> ordered by clustering <span class="math inline">\(\mathbf{R}\)</span></td>
</tr>
<tr class="even">
<td align="right"><code>gridR</code></td>
<td align="left">Grid plot of <span class="math inline">\(\mathbf{R}\)</span>, ordered by cluster
analysis.</td>
</tr>
<tr class="odd">
<td align="right"><code>gridY_E</code></td>
<td align="left">Grid plot of correlation for data <span class="math inline">\(\mathbf{Y}\)</span> and <span class="math inline">\(\mathbf{E}\)</span>, ordered by clustering
cor(<span class="math inline">\(\mathbf{Y}\)</span>)</td>
</tr>
<tr class="even">
<td align="right"><code>gridTraitB</code></td>
<td align="left">If traits are predicted, see <code>gjam vignette</code>
on traits.</td>
</tr>
<tr class="odd">
<td align="right"><code>ordination</code></td>
<td align="left">PCA of <span class="math inline">\(\mathbf{E}\)</span>
matrix, including eigenvalues (cumulative)</td>
</tr>
<tr class="even">
<td align="right"><code>partition</code></td>
<td align="left">If ordinal responses, posterior distribution of <span class="math inline">\(\mathcal{P}\)</span></td>
</tr>
<tr class="odd">
<td align="right"><code>richness</code></td>
<td align="left">Predictive distribution with distribution of data
(histogram)</td>
</tr>
<tr class="even">
<td align="right"><code>sensitivity</code></td>
<td align="left">Overall sensitivity <span class="math inline">\(\textbf{f}\)</span> by predictor</td>
</tr>
<tr class="odd">
<td align="right"><code>traits</code></td>
<td align="left">If traits are predicted, see <code>gjam vignette</code>
on traits.</td>
</tr>
<tr class="even">
<td align="right"><code>traitPred</code></td>
<td align="left">If traits are predicted, see <code>gjam vignette</code>
on traits.</td>
</tr>
<tr class="odd">
<td align="right"><code>trueVsPars</code></td>
<td align="left">If simulated data and <code>trueValues</code> included
in <code>plotPars</code></td>
</tr>
<tr class="even">
<td align="right"><code>xPred</code></td>
<td align="left">Inverse predictive distribution of of <span class="math inline">\(\mathbf{X}\)</span></td>
</tr>
<tr class="odd">
<td align="right"><code>xPredFactors</code></td>
<td align="left">Inverse predictive distribution of factor levels</td>
</tr>
<tr class="even">
<td align="right"><code>yPred</code></td>
<td align="left">Predicted <span class="math inline">\(\mathbf{Y}\)</span>, in-sample (blue bars),
out-of-sample (dots), and distribution of data (histogram)</td>
</tr>
<tr class="odd">
<td align="right"><code>yPredAll</code></td>
<td align="left">If <code>PLOTALLY</code> all response predictions
shown</td>
</tr>
</tbody>
</table>
<p>If the <code>plotPars</code> list passed to <code>gjamPlot</code>
specifies <code>GRIDPLOTS = T</code>, then grid and cluster plots are
generated as gridded values for <span class="math inline">\(\mathbf{B}\)</span>, <span class="math inline">\(\boldsymbol{\Sigma}\)</span> and <span class="math inline">\(\mathbf{R}\)</span>. Gridplots of matrix <span class="math inline">\(\mathbf{R}\)</span> show conditional and marginal
dependence in white and grey. In plots of <span class="math inline">\(\mathbf{E}\)</span> marginal independence is shown
in grey, but conditional independence is not shown, as the matrix does
not have an inverse (Clark et al. 2017).</p>
<p>The sensitivity matrix <span class="math inline">\(\mathbf{F}\)</span> is shown together in a plot
with individual species responses <span class="math inline">\(\mathbf{B}\)</span>.</p>
<p>The plot in which the model residual correlation <span class="math inline">\(\mathbf{R}\)</span> and the response correlation
<span class="math inline">\(\mathbf{B}\)</span> are compared are ordered
by their similiarity in the <span class="math inline">\(\mathbf{R}\)</span>. If the two contain similar
structure, then it will be evident in this comparison. There is no
reason to expect them to be similar.</p>
<p>For large <span class="math inline">\(S\)</span> the labels are not
shown on the graphs, they would be too small. The order of species and
the cluster groups to which they belong are returned in
<code>fit$clusterOrder</code> and <code>fit$clusterIndex</code>.</p>
<p><br></p>
</div>
<div id="flexibility-in-gjam" class="section level1">
<h1><span style="color:darkgreen">flexibility in gjam</span></h1>
<div id="heterogeneous-effort" class="section level2">
<h2><span style="color:teal">heterogeneous effort</span></h2>
<p>Here is an example with discrete abundance data, now with
heterogeneous sample effort. Heterogeneous effort applies where
vegetation plots have different areas, animal survey data have variable
search times, or catch returns from fishing vessels have different gear
and/or trawling times. Here I simulate a list containing the columns and
the effort that applies to those columns, shown for 50 observations:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>S  <span class="ot">&lt;-</span> <span class="dv">5</span>                             </span>
<span id="cb28-2"><a href="#cb28-2" tabindex="-1"></a>n  <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb28-3"><a href="#cb28-3" tabindex="-1"></a>ef <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">columns =</span> <span class="dv">1</span><span class="sc">:</span>S, <span class="at">values =</span> <span class="fu">round</span>(<span class="fu">runif</span>(n,.<span class="dv">5</span>,<span class="dv">5</span>),<span class="dv">1</span>) )</span>
<span id="cb28-4"><a href="#cb28-4" tabindex="-1"></a>f  <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(n, S, <span class="at">typeNames =</span> <span class="st">&#39;DA&#39;</span>, <span class="at">effort =</span> ef)</span>
<span id="cb28-5"><a href="#cb28-5" tabindex="-1"></a>ef</span></code></pre></div>
<p>If <code>ef$values</code> consists of a length-n <code>vector</code>,
then gjam assumes each value applies to all columns in the corresponding
row specified in the <code>vector ef$columns</code>. This is the case
shown above and would apply when effort is plot area, search time,
sample volume, and so forth. Alternatively, <code>values</code> can be
supplied as a <code>matrix</code>, having the same dimensions as
<code>ydata</code>. As a <code>matrix</code>, <code>ef$values</code> can
have elements that differ by observation and species. For example,
camera trap data detect large animals at greater distances than small
animals (column differences), and each camera can be deployed for
different lengths of time (row differences). For simulation purposes
<code>gjamSimData</code> only accepts a <code>vector</code>. However,
for fitting with <code>gjam</code> <code>effort$values</code> can be
supplied as a <code>matrix</code> with as many columns as are listed in
<code>effort$columns</code>.</p>
<p>Because observations are discrete the continuous latent variables
<span class="math inline">\(w_{is}\)</span> are censored. Unlike the
previous continuous example, observations <span class="math inline">\(y_{is}\)</span> now assume only discrete
values:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>w, f<span class="sc">$</span>y, <span class="at">cex =</span> .<span class="dv">2</span>, <span class="at">xlab =</span> <span class="st">&#39;Latent w scale&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Observed y&#39;</span> )</span></code></pre></div>
<p>The large scatter reflects the variable effort represented by each
observation. Incorporating the effort scale gives this plot:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a><span class="fu">plot</span>(f<span class="sc">$</span>w<span class="sc">*</span>ef<span class="sc">$</span>values, f<span class="sc">$</span>y, <span class="at">cex =</span> .<span class="dv">2</span>, <span class="at">xlab =</span> <span class="st">&#39;Latent w time effort&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Observed y&#39;</span>)</span></code></pre></div>
<p>The heterogeneous effort affects the weight of each observation in
model fitting. The <code>effort</code> is entered in
<code>modelList</code>. Increase the number of iterations and look at
plots:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>S   <span class="ot">&lt;-</span> <span class="dv">10</span>                             </span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>n   <span class="ot">&lt;-</span> <span class="dv">1500</span></span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>ef  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">columns =</span> <span class="dv">1</span><span class="sc">:</span>S, <span class="at">values =</span> <span class="fu">round</span>(<span class="fu">runif</span>(n,.<span class="dv">5</span>,<span class="dv">5</span>),<span class="dv">1</span>) )</span>
<span id="cb31-4"><a href="#cb31-4" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(n, S, <span class="at">typeNames =</span> <span class="st">&#39;DA&#39;</span>, <span class="at">effort =</span> ef)</span>
<span id="cb31-5"><a href="#cb31-5" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng =</span> <span class="dv">1000</span>, <span class="at">burnin =</span> <span class="dv">250</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames, <span class="at">effort =</span> ef)</span>
<span id="cb31-6"><a href="#cb31-6" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>(f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml)</span>
<span id="cb31-7"><a href="#cb31-7" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">trueValues =</span> f<span class="sc">$</span>trueValues )</span>
<span id="cb31-8"><a href="#cb31-8" tabindex="-1"></a><span class="fu">gjamPlot</span>(<span class="at">output =</span> out, <span class="at">plotPars =</span> pl)</span></code></pre></div>
<p>Use <code>summary(out)</code> to see a summary of effort.</p>
</div>
<div id="specifying-censored-intervals" class="section level2">
<h2><span style="color:teal">specifying censored intervals</span></h2>
<p>To analyze data that are censored at specific intervals, I specify
the censored values and the intervals to which those values apply. In
the help page for <code>gjamCensorY</code> I discuss a
<code>vector</code> of <code>values</code> and a corresponding
<code>matrix</code> of upper and lower bounds in two rows and one column
for each element in <code>values</code>. For example, if an observer
stops counting wildebeest or sea lions at, say, 100 animals, I can set
this as a censored interval:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a><span class="co"># assumes there is a data matrix ydata</span></span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>intv  <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(upper,<span class="cn">Inf</span>),<span class="dv">2</span>)</span>
<span id="cb32-4"><a href="#cb32-4" tabindex="-1"></a><span class="fu">rownames</span>(intv) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;lower&#39;</span>,<span class="st">&#39;upper&#39;</span>)</span>
<span id="cb32-5"><a href="#cb32-5" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> <span class="fu">gjamCensorY</span>(<span class="at">values =</span> upper, <span class="at">intervals =</span> intv, <span class="at">y =</span> f<span class="sc">$</span>ydata, <span class="at">type=</span><span class="st">&#39;DA&#39;</span>)</span></code></pre></div>
<p>There are two objects returned by <code>gjamCensor</code>. The
<code>list $censor</code> holds two lists, the <code>$columns</code>,
indicating which columns in <code>$y</code> are censored, and the
<code>$partition</code>, giving the values and bounds for the partition.
Because I did not specify <code>whichcol</code> in my call to
<code>gjamCensorY</code>, censoring defaults to all columns in
<code>ydata</code>. The object <code>$y</code> matches the mode and
dimensions of the input <code>y</code> (a <code>matrix</code> or
<code>data.frame</code>). This new version of the response matrix
replaces any values in <code>ydata</code> that fall within a censored
interval with the censored <code>value</code>. This feature is useful
when observers are inconsistent on the assignment of intervals or where
an analyst distrusts the precision reported in data. For example, if
counts range to thousands, but it is known that counts beyond 100 are
inaccurate, then all counts above 100 are censored and, thus,
uncertain.</p>
<p>Censoring can be applied differently to each response variable. For
example, chemical constitents reported as concentrations in a sample,
sometimes reach non-zero minimum values, taken as detection limits for
that instrument and that constituent (detection limits can differ for
each constituent). In this case, there is a <code>list</code> for each
column in <code>ydata</code>. I can generate this <code>list</code> with
a loop, where the censored interval for each column <code>j</code> spans
from <code>-Inf</code> to <code>min(ydata[,j])</code>,</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>miny   <span class="ot">&lt;-</span> <span class="fu">apply</span>(f<span class="sc">$</span>ydata, <span class="dv">2</span>, min, <span class="at">na.rm=</span>T)     <span class="co">#minimum value by column</span></span>
<span id="cb33-2"><a href="#cb33-2" tabindex="-1"></a>censor <span class="ot">&lt;-</span>  <span class="fu">numeric</span>(<span class="dv">0</span>)     </span>
<span id="cb33-3"><a href="#cb33-3" tabindex="-1"></a>p      <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="at">dimnames=</span><span class="fu">list</span>(<span class="fu">c</span>(<span class="st">&quot;values&quot;</span>,<span class="st">&quot;lower&quot;</span>,<span class="st">&quot;upper&quot;</span>), <span class="cn">NULL</span>))</span>
<span id="cb33-4"><a href="#cb33-4" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">ncol</span>(f<span class="sc">$</span>ydata)){</span>
<span id="cb33-6"><a href="#cb33-6" tabindex="-1"></a>  p[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">c</span>(miny[j], <span class="sc">-</span><span class="cn">Inf</span>, miny[j])</span>
<span id="cb33-7"><a href="#cb33-7" tabindex="-1"></a>  jlist  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="st">&quot;columns&quot;</span> <span class="ot">=</span> j, <span class="st">&quot;partition&quot;</span> <span class="ot">=</span> p)</span>
<span id="cb33-8"><a href="#cb33-8" tabindex="-1"></a>  censor <span class="ot">&lt;-</span> <span class="fu">c</span>(censor, <span class="fu">list</span>(jlist))</span>
<span id="cb33-9"><a href="#cb33-9" tabindex="-1"></a>  <span class="fu">names</span>(censor)[j] <span class="ot">&lt;-</span> <span class="st">&#39;CA&#39;</span></span>
<span id="cb33-10"><a href="#cb33-10" tabindex="-1"></a>}</span></code></pre></div>
<p>This <code>list censor</code> can be passed directly to
<code>gjam</code> in the <code>list modelList</code>.</p>
</div>
<div id="prior-distribution-on-coefficients" class="section level2">
<h2><span style="color:teal">prior distribution on
coefficients</span></h2>
<p>Informative prior distributions in regression models are rare,
perhaps partly because it is hard to assign both magnitude (e.g., large
or small prior mean value) and weight (large or small prior variance)
without obscuring the relative contributions of prior and data. Prior
distributions for regression coefficients are typically Gaussian, having
support on <span class="math inline">\((-\infty, \infty)\)</span>. In
many cases, the sign of the effect is known, but the magnitude is not.
Ad hoc experimentation with prior mean and variance can, at best, only
insure that ‘most’ of the posterior distribution is positive or
negative. Yet, it can be important to use prior information, especially
in the multivariate setting, where covariances between responses can
result in estimates where the sign of a coefficient effect makes no
sense.</p>
<p>The knowledge of the ‘direction’ of the effect can be readily
implmented with uniform priors truncated at zero, having the advantage
that the posterior distribution that preserves the shape of the
likelihood, but is restricted to positive or negative values (Clark et
al. 2013).</p>
<p>The prior distribution for <span class="math inline">\(\mathbf{B}\)</span> is either non-informative (if
unspecified) or truncated by limits provided in the
<code>list betaPrior</code>. The <code>betaPrior list</code> contains
the two matrices <code>lo</code> and <code>hi</code>. The rows of these
matrices have <code>rownames</code> that match explanatory variables in
the <code>formula</code> and <code>colnames</code> in
<code>xdata</code>. In the example that follows I fit a model for FIA
data to winter temperature <code>temp</code>, climatic
<code>deficit</code>, and their interaction. For this example, I use a
prior distribution having positive effects of warm winters and negative
effects of climate deficit. This prior is set up with the function
<code>gjamPriorTemplate</code>.</p>
<p>The prior distribution is also the place to exclude specific
predictor/response combinations, by setting them equal to
<code>NA</code> in <code>lo</code> or <code>hi</code>. Here is an
example of informative priors on some coefficients:</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>xdata   <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>xdata</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="sc">~</span> temp<span class="sc">*</span>deficit)</span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>snames  <span class="ot">&lt;-</span> <span class="fu">colnames</span>(treeYdata)</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a><span class="co"># warm winter</span></span>
<span id="cb34-6"><a href="#cb34-6" tabindex="-1"></a>hot <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;liquStyr&quot;</span>,<span class="st">&quot;liriTuli&quot;</span>,<span class="st">&quot;pinuEchi&quot;</span>,<span class="st">&quot;pinuElli&quot;</span>,<span class="st">&quot;pinuPalu&quot;</span>,<span class="st">&quot;pinuTaed&quot;</span>,</span>
<span id="cb34-7"><a href="#cb34-7" tabindex="-1"></a>         <span class="st">&quot;querImbr&quot;</span>,<span class="st">&quot;querLaur&quot;</span>,<span class="st">&quot;querLyra&quot;</span>,<span class="st">&quot;querMich&quot;</span>,<span class="st">&quot;querMueh&quot;</span>,<span class="st">&quot;querNigr&quot;</span>,</span>
<span id="cb34-8"><a href="#cb34-8" tabindex="-1"></a>         <span class="st">&quot;querPhel&quot;</span>,<span class="st">&quot;querVirg&quot;</span>)  <span class="co"># arbitrary spp, positive winter temp</span></span>
<span id="cb34-9"><a href="#cb34-9" tabindex="-1"></a>nh <span class="ot">&lt;-</span> <span class="fu">length</span>(hot)</span>
<span id="cb34-10"><a href="#cb34-10" tabindex="-1"></a>lo  <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&#39;list&#39;</span>, nh)</span>
<span id="cb34-11"><a href="#cb34-11" tabindex="-1"></a><span class="fu">names</span>(lo) <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&#39;temp&#39;</span>,hot,<span class="at">sep=</span><span class="st">&#39;_&#39;</span>)</span>
<span id="cb34-12"><a href="#cb34-12" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nh)lo[[j]] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb34-13"><a href="#cb34-13" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" tabindex="-1"></a><span class="co"># humid climate (negative deficit)</span></span>
<span id="cb34-15"><a href="#cb34-15" tabindex="-1"></a>humid <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;abieBals&quot;</span>, <span class="st">&quot;betuAlle&quot;</span>, <span class="st">&quot;querNigr&quot;</span>, <span class="st">&quot;querPhel&quot;</span>)  <span class="co">#again, arbitrary</span></span>
<span id="cb34-16"><a href="#cb34-16" tabindex="-1"></a>nh <span class="ot">&lt;-</span> <span class="fu">length</span>(humid)</span>
<span id="cb34-17"><a href="#cb34-17" tabindex="-1"></a>hi  <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&#39;list&#39;</span>, nh)</span>
<span id="cb34-18"><a href="#cb34-18" tabindex="-1"></a><span class="fu">names</span>(hi) <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&#39;deficit&#39;</span>,humid,<span class="at">sep=</span><span class="st">&#39;_&#39;</span>)</span>
<span id="cb34-19"><a href="#cb34-19" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nh)hi[[j]] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb34-20"><a href="#cb34-20" tabindex="-1"></a>                      </span>
<span id="cb34-21"><a href="#cb34-21" tabindex="-1"></a>bp <span class="ot">&lt;-</span> <span class="fu">gjamPriorTemplate</span>(formula, xdata, <span class="at">ydata =</span> treeYdata, <span class="at">lo =</span> lo, <span class="at">hi=</span>hi)</span>
<span id="cb34-22"><a href="#cb34-22" tabindex="-1"></a>rl <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="dv">10</span>, <span class="at">r =</span> <span class="dv">5</span>) </span>
<span id="cb34-23"><a href="#cb34-23" tabindex="-1"></a>ml <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng=</span><span class="dv">1000</span>, <span class="at">burnin=</span><span class="dv">200</span>, <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span>, <span class="at">betaPrior =</span> bp, <span class="at">reductList=</span>rl)</span>
<span id="cb34-24"><a href="#cb34-24" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>(formula, xdata, <span class="at">ydata =</span> treeYdata, <span class="at">modelList =</span> ml)</span>
<span id="cb34-25"><a href="#cb34-25" tabindex="-1"></a></span>
<span id="cb34-26"><a href="#cb34-26" tabindex="-1"></a>sc  <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;grey&#39;</span>,<span class="fu">ncol</span>(treeYdata))</span>
<span id="cb34-27"><a href="#cb34-27" tabindex="-1"></a>sc[snames <span class="sc">%in%</span> hot] <span class="ot">&lt;-</span> <span class="st">&#39;#ff7f00&#39;</span>      <span class="co"># highlight informative priors</span></span>
<span id="cb34-28"><a href="#cb34-28" tabindex="-1"></a>sc[snames <span class="sc">%in%</span> humid] <span class="ot">&lt;-</span> <span class="st">&#39;#1f78b4&#39;</span></span>
<span id="cb34-29"><a href="#cb34-29" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">GRIDPLOTS =</span> T, <span class="at">specColor =</span> sc)</span>
<span id="cb34-30"><a href="#cb34-30" tabindex="-1"></a><span class="fu">gjamPlot</span>(<span class="at">output =</span> out, <span class="at">plotPars =</span> pl)</span></code></pre></div>
<p>The combination of <code>lo</code> and <code>hi</code> set the limits
for posterior draws from the truncated multivariate normal distribution.
The <code>help</code> page for <code>gjamPriorTemplate</code> provides
an example with informative priors specified for individual
predictor-response combinations.</p>
</div>
<div id="species-factor-levels-that-do-not-occur" class="section level2">
<h2><span style="color:teal">species-factor levels that do not
occur</span></h2>
<p>There can be times when specific species-predictor combinations could
be omitted. For example, some species may never occur on some soil
types. If I want to estimate <span class="math inline">\(\beta\)</span>
conditioned on some elements being zero, I could do the following:</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="sc">~</span> temp <span class="sc">+</span> soil)</span>
<span id="cb35-2"><a href="#cb35-2" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" tabindex="-1"></a><span class="co"># find species-soil type combinations that occur less than 5 times</span></span>
<span id="cb35-4"><a href="#cb35-4" tabindex="-1"></a>y0 <span class="ot">&lt;-</span> treeYdata</span>
<span id="cb35-5"><a href="#cb35-5" tabindex="-1"></a>y0[ y0 <span class="sc">&gt;</span> <span class="dv">0</span> ] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb35-6"><a href="#cb35-6" tabindex="-1"></a>soil <span class="ot">&lt;-</span> <span class="fu">rep</span>( <span class="fu">as.character</span>(xdata<span class="sc">$</span>soil), <span class="fu">ncol</span>(y0) )</span>
<span id="cb35-7"><a href="#cb35-7" tabindex="-1"></a>soil <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&#39;soil&#39;</span>, soil, <span class="at">sep=</span><span class="st">&#39;&#39;</span>) <span class="co"># soil is a factor, so full name begins with variable name</span></span>
<span id="cb35-8"><a href="#cb35-8" tabindex="-1"></a>spec <span class="ot">&lt;-</span> <span class="fu">rep</span>( <span class="fu">colnames</span>(y0), <span class="at">each =</span> <span class="fu">nrow</span>(y0) )</span>
<span id="cb35-9"><a href="#cb35-9" tabindex="-1"></a>specBySoil <span class="ot">&lt;-</span> <span class="fu">tapply</span>( <span class="fu">as.vector</span>(y0), <span class="fu">list</span>(spec, soil), sum )</span>
<span id="cb35-10"><a href="#cb35-10" tabindex="-1"></a>wna  <span class="ot">&lt;-</span> <span class="fu">which</span>( specBySoil <span class="sc">&lt;</span> <span class="dv">5</span>, <span class="at">arr.ind =</span> T )                   <span class="co"># only if at least 5 observations</span></span>
<span id="cb35-11"><a href="#cb35-11" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" tabindex="-1"></a><span class="co"># assign NA to excluded coefficients using species-variable names</span></span>
<span id="cb35-13"><a href="#cb35-13" tabindex="-1"></a>nh <span class="ot">&lt;-</span> <span class="fu">nrow</span>(wna)</span>
<span id="cb35-14"><a href="#cb35-14" tabindex="-1"></a>lo  <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&#39;list&#39;</span>, nh)</span>
<span id="cb35-15"><a href="#cb35-15" tabindex="-1"></a><span class="fu">names</span>(lo) <span class="ot">&lt;-</span> <span class="fu">paste</span>( <span class="fu">rownames</span>(specBySoil)[wna[,<span class="dv">1</span>]], <span class="fu">colnames</span>(specBySoil)[wna[,<span class="dv">2</span>]], <span class="at">sep=</span><span class="st">&#39;_&#39;</span> )</span>
<span id="cb35-16"><a href="#cb35-16" tabindex="-1"></a>hi <span class="ot">&lt;-</span> lo</span>
<span id="cb35-17"><a href="#cb35-17" tabindex="-1"></a><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nh)lo[[j]] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb35-18"><a href="#cb35-18" tabindex="-1"></a>hi <span class="ot">&lt;-</span> lo</span>
<span id="cb35-19"><a href="#cb35-19" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" tabindex="-1"></a><span class="co"># setup prior and fit model</span></span>
<span id="cb35-21"><a href="#cb35-21" tabindex="-1"></a>bp  <span class="ot">&lt;-</span> <span class="fu">gjamPriorTemplate</span>(formula, xdata, <span class="at">ydata =</span> treeYdata, <span class="at">lo =</span> lo, <span class="at">hi=</span>hi)</span>
<span id="cb35-22"><a href="#cb35-22" tabindex="-1"></a>rl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="dv">10</span>, <span class="at">r =</span> <span class="dv">5</span>) </span>
<span id="cb35-23"><a href="#cb35-23" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng=</span><span class="dv">1000</span>, <span class="at">burnin=</span><span class="dv">200</span>, <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span>, <span class="at">betaPrior =</span> bp, <span class="at">reductList=</span>rl)</span>
<span id="cb35-24"><a href="#cb35-24" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>(formula, xdata, <span class="at">ydata =</span> treeYdata, <span class="at">modelList =</span> ml)</span></code></pre></div>
<p>The values in <code>out$parameters$betaMu</code> will show these
omitted values as <code>NA</code>.</p>
</div>
<div id="sample-effort-in-count-data" class="section level2">
<h2><span style="color:teal">sample effort in count data</span></h2>
<p>Discrete count (<code>&#39;DA&#39;</code>) data have effort associated with
search time, plot area, and so forth. When the effort values are
measured in units that result in large differences between data types
sampled with different efforts, model fitting deteriorates. The modeling
scale is <span class="math inline">\(W = Y/E\)</span>, where <span class="math inline">\(Y\)</span> are counts, and <span class="math inline">\(E\)</span> is effort. Units that make <span class="math inline">\(E\)</span> large, can make <span class="math inline">\(W\)</span> vanishingly small. When counts per unit
effort span different orders of magnitude for different data types,
consider changing the units on effort to bring them more in alignment
with one another. Model predictions for ground beetles (pitfall traps)
and small mammals (live traps) in our NEON analysis improved by shifting
from trap-days to trap-months.</p>
</div>
<div id="sample-effort-in-composition-data" class="section level2">
<h2><span style="color:teal">sample effort in composition
data</span></h2>
<p>Composition count (<code>&#39;CC&#39;</code>) data have heterogenous effort
due to different numbers of counts for each sample. For example, in
microbiome data, the number of reads per sample can range from <span class="math inline">\(10^{2}\)</span> to <span class="math inline">\(10^{6}\)</span>. Typically, the number of reads
does not depend on total abundance. It is generally agreed that only
relative differences are important. gjam knows that the effort in
<code>CC</code> data is the total count for the sample, so
<code>effort</code> does not need to be specified. Here is an example
with simulated data:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">S =</span> <span class="dv">8</span>, <span class="at">typeNames =</span> <span class="st">&#39;CC&#39;</span> )</span>
<span id="cb36-2"><a href="#cb36-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb36-3"><a href="#cb36-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb36-4"><a href="#cb36-4" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> <span class="fu">list</span>( <span class="at">trueValues =</span> f<span class="sc">$</span>trueValues) )</span></code></pre></div>
<p>For comparison, here is an example with fractional composition, where
there is no effort:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">S =</span> <span class="dv">10</span>, <span class="at">typeNames =</span> <span class="st">&#39;FC&#39;</span> )</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> <span class="fu">list</span>( <span class="at">trueValues =</span> f<span class="sc">$</span>trueValues ) )</span></code></pre></div>
</div>
<div id="the-partition-in-ordinal-data" class="section level2">
<h2><span style="color:teal">the partition in ordinal data</span></h2>
<p>Ordinal count (<code>&#39;OC&#39;</code>) data are collected where abundance
must be evaluated rapidly or precise measurements are difficult. Because
there is no absolute scale the partition must be inferred. Here is an
example with 10 species:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">typeNames =</span> <span class="st">&#39;OC&#39;</span> ) </span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb38-3"><a href="#cb38-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span></code></pre></div>
<p>A simple plot of the posterior mean values of <code>cutMu</code>
shows the estimates with true values from simulation:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a><span class="fu">par</span>( <span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">bty =</span> <span class="st">&#39;n&#39;</span> )</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">strsplit</span>(<span class="fu">colnames</span>(out<span class="sc">$</span>parameters<span class="sc">$</span>cutMu),<span class="st">&#39;C-&#39;</span>) <span class="co">#only saved columns</span></span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>keep <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">as.numeric</span>(<span class="fu">unlist</span>(keep)), <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> T)[,<span class="dv">2</span>]</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a><span class="fu">plot</span>( f<span class="sc">$</span>trueValues<span class="sc">$</span>cuts[,keep], out<span class="sc">$</span>parameters<span class="sc">$</span>cutMu, <span class="at">xlab =</span> <span class="st">&#39;True partition&#39;</span>,</span>
<span id="cb39-5"><a href="#cb39-5" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&#39;Estimated partition&#39;</span>)</span></code></pre></div>
<p>Here are plots:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">trueValues =</span> f<span class="sc">$</span>trueValues)</span>
<span id="cb40-2"><a href="#cb40-2" tabindex="-1"></a><span class="fu">gjamPlot</span>(<span class="at">output =</span> out, <span class="at">plotPars =</span> pl)</span></code></pre></div>
</div>
<div id="categorical-data" class="section level2">
<h2><span style="color:teal">categorical data</span></h2>
<p>Categorical data have levels within groups. The levels are unordered.
The columns in <code>ydata</code> that hold categorical responses are
declared as <code>typeNames = &quot;CAT&quot;</code>. In observation vector <span class="math inline">\(\mathbf{y}_{i}\)</span> there are elements for one
less than the number of factor levels. Suppose that observations are
obtained on attributes of individual plants, each plant being an
observation. The group <code>leaf</code> type might have four levels
broadleaf decidious <code>bd</code>, needleleaf decidious
<code>nd</code>, broadleaf evergreen <code>be</code>, and needleaf
evergreen <code>ne</code>. A second group <code>xylem</code> anatomy
might have three levels diffuse porous <code>dp</code>, ring porous
<code>rp</code>, and tracheid <code>tr</code>. In both cases I assign
the last class to be a reference class, <code>other</code>. Ten rows of
the response matrix data might look like this:</p>
<pre><code>##    leaf xylem
## 1    bd    dp
## 2    nd    rp
## 3    nd    dp
## 4    be    rp
## 5    be    dp
## 6 other    rp
## 7    bd    rp</code></pre>
<p>This <code>data.frame ydata</code> becomes this response matrix
<code>y</code>:</p>
<pre><code>##      leaf_bd leaf_nd leaf_be leaf_other xylem_dp xylem_rp xylem_other
## [1,]       1       0       0          0        1        0           0
## [2,]       0       1       0          0        0        1           0
## [3,]       0       1       0          0        1        0           0
## [4,]       0       0       1          0        0        1           0
## [5,]       0       0       1          0        1        0           0
## [6,]       0       0       0          1        0        1           0
## [7,]       1       0       0          0        0        1           0</code></pre>
<p><code>gjam</code> expands the two groups into four and three columns
in <code>y</code>, respectively. As for composition data there is one
redundant column for each group. Here is an example with simulated data,
having two categorical groups:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a>types <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">&#39;CAT&#39;</span>, <span class="st">&#39;CAT&#39;</span> )</span>
<span id="cb43-2"><a href="#cb43-2" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">n =</span> <span class="dv">3000</span>, <span class="at">S =</span> <span class="fu">length</span>(types), <span class="at">typeNames =</span> types )</span>
<span id="cb43-3"><a href="#cb43-3" tabindex="-1"></a>ml    <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">1500</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames, <span class="at">PREDICTX =</span> F )</span>
<span id="cb43-4"><a href="#cb43-4" tabindex="-1"></a>out   <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, <span class="at">xdata =</span> f<span class="sc">$</span>xdata, <span class="at">ydata =</span> f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb43-5"><a href="#cb43-5" tabindex="-1"></a><span class="fu">gjamPlot</span>( out, <span class="at">plotPars =</span> <span class="fu">list</span>(<span class="at">trueValues =</span> f<span class="sc">$</span>trueValues, <span class="at">PLOTALLY =</span> T) )</span></code></pre></div>
</div>
<div id="combinations-of-data-types" class="section level2">
<h2><span style="color:teal">combinations of data types</span></h2>
<p>One of the advantages of gjam is that it combines data of many types.
Here is an example showing joint analysis of 12 species represented by
five data types, specified by column:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a>types <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;OC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CC&#39;</span>,<span class="st">&#39;CA&#39;</span>,<span class="st">&#39;CA&#39;</span>,<span class="st">&#39;PA&#39;</span>,<span class="st">&#39;PA&#39;</span> ) </span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a>f     <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">S =</span> <span class="fu">length</span>(types), <span class="at">Q =</span> <span class="dv">5</span>, <span class="at">typeNames =</span> types )</span>
<span id="cb44-3"><a href="#cb44-3" tabindex="-1"></a>ml    <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames )</span>
<span id="cb44-4"><a href="#cb44-4" tabindex="-1"></a>out   <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb44-5"><a href="#cb44-5" tabindex="-1"></a>tmp   <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( f<span class="sc">$</span>typeNames, out<span class="sc">$</span>inputs<span class="sc">$</span>classBySpec[,<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>] )</span>
<span id="cb44-6"><a href="#cb44-6" tabindex="-1"></a><span class="fu">print</span>( tmp )</span></code></pre></div>
<p>I have displayed the first 10 columns of <code>classBySpec</code>
from the <code>inputs</code> of <code>out</code>, with their
<code>typeNames</code>. The ordinal count (<code>&#39;OC&#39;</code>) data
occupy lower intervals. The width of each interval in <code>OC</code>
data depends on the estimate of the partition in <code>cutMu</code>.</p>
<p>The composition count (<code>&#39;CC&#39;</code>) data occupy a broader range
of intervals. Because <code>CC</code> data are only relative, there is
information on only <span class="math inline">\(S - 1\)</span> species.
One species is selected as <code>other</code>. The <code>other</code>
class can be a collection of rare species (Clark et al. 2017).</p>
<p>Both continuous abundance (<code>&#39;CA&#39;</code>) and presence-absence
(<code>&#39;PA&#39;</code>) data have two intervals. For CA data only the first
interval is censored, the zeros (see above). For <code>PA</code> data
both interval are censored; it is a multivariate probit.</p>
<p>Here are some plots for analysis of this model:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> <span class="fu">list</span>(<span class="at">trueValues =</span> f<span class="sc">$</span>trueValues, <span class="at">GRIDPLOTS =</span> T) )</span></code></pre></div>
</div>
<div id="random-effects" class="section level2">
<h2><span style="color:teal">random effects</span></h2>
<p>In addition to random effects on species used in dimension reduction,
<code>gjam</code> allows for random groups. Examples could be observer
effects for bird point counts or plot effects, where there are multiple
observations per plot. Just like fixed effects, random effects should
have replication. In other words, if I want to estimate an observer
effect, I should have multiple observations for each observer. For plot
effects, I want replication within plots.</p>
<p>To specify random groups, I provide the name of the column in
<code>xdata</code> that holds the group indicator. This can be entered
as an integer, a factor level, or a character variable.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a>modelList<span class="sc">$</span>random <span class="ot">&lt;-</span> <span class="st">&#39;columnNameInXdata&#39;</span></span></code></pre></div>
<p>This column will be the basis for the random groups. Any rare groups
(less than a few observations) will be aggregated into a single
<code>rareGroups</code> category, again, to insure replication.</p>
<p>In the <code>gjam</code> output, here are objects related to random
effects in <code>output$parameters</code>:</p>
<table>
<thead>
<tr class="header">
<th align="right">object</th>
<th align="right">dimension</th>
<th align="center">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>randByGroupMu</code></td>
<td align="right"><code>S</code> by <code>G</code></td>
<td align="center">random groups, mean</td>
</tr>
<tr class="even">
<td align="right"><code>randByGroupSe</code></td>
<td align="right"><code>S</code> by <code>G</code></td>
<td align="center">SE</td>
</tr>
<tr class="odd">
<td align="right"><code>groupIndex</code></td>
<td align="right"><code>n</code></td>
<td align="center">group index for observations</td>
</tr>
</tbody>
</table>
</div>
<div id="missing-data-out-of-sample-prediction" class="section level2">
<h2><span style="color:teal">missing data, out-of-sample
prediction</span></h2>
<p>gjam identifies missing values in <code>xdata</code> and
<code>ydata</code> and models them as part of the posterior
distribution. These are located at <code>$missing$xmiss</code> and
<code>$missing$ymiss</code>. The estimates for missing <span class="math inline">\(\mathbf{X}\)</span> are
<code>$missing$xmissMu</code> and <code>$missing$xmissSe</code>. The
estimates for missing <span class="math inline">\(\mathbf{Y}\)</span>
are <code>$missing$ymissMu</code> and <code>$missing$ymissSe</code>.</p>
<p>To simulate missing data use <code>nmiss</code> to indicate the
number of missing values. The actual value will be less than
<code>nmiss</code>:</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(<span class="at">typeNames =</span> <span class="st">&#39;OC&#39;</span>, <span class="at">nmiss =</span> <span class="dv">20</span>)</span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a><span class="fu">which</span>(<span class="fu">is.na</span>(f<span class="sc">$</span>xdata), <span class="at">arr.ind =</span> T)</span></code></pre></div>
<p>Note that missing values are assumed to occur in random rows and
columns, but not in column one, which is the intercept and known. No
further action is needed for model fitting, as <code>gjam</code> knows
to treat these as missing data.</p>
<p>Out-of-sample prediction of <span class="math inline">\(\mathbf{Y}\)</span> is not part of the posterior
distribution. For model fitting, holdouts can be specified randomly in
<code>modelList</code> with <code>holdoutN</code> (the number of plots
to be held out at random) or with <code>holdoutIndex</code> (observation
numbers, i.e., row numbers in <code>x</code> and <code>y</code>). The
latter can be useful when a comparison of predictions is desired for
different models using the same plots as holdouts.</p>
<p>When observations are held out, <code>gjam</code> provides
out-of-sample prediction for both <code>x[holdoutIndex,]</code> and
<code>y[holdoutIndex,]</code>. The holdouts are not included in the
fitting of <span class="math inline">\(\boldsymbol{B}\)</span>,<span class="math inline">\(\boldsymbol{\Sigma}\)</span>, or <span class="math inline">\(\mathcal{P}\)</span>. For prediction of
<code>y[holdoutIndex,]</code>, the values of
<code>x[holdoutIndex,]</code> are known, and sampling for
<code>w[holdoutIndex,]</code> is done with multivariate normal
distribution, without censoring. This is done because the censoring
depends on <code>y[holdoutIndex,]</code>, which taken to be unknown.
This sample of <code>w[holdoutIndex,]</code> becomes a prediction for
<code>y[holdoutIndex,]</code> using the partition (Figure 1a).</p>
<p>For inverse prediction of <code>x[holdoutIndex,]</code> the values of
<code>y[holdoutIndex,]</code> are known. This represents the situation
where a sample of the community is available, and the investigator would
like to predict the environment of origin.</p>
<p>Here is an example with simulated data having both missing values and
holdout observations:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span>, <span class="at">nmiss =</span> <span class="dv">20</span> )</span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames, <span class="at">holdoutN =</span> <span class="dv">50</span> )</span>
<span id="cb48-3"><a href="#cb48-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb48-4"><a href="#cb48-4" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" tabindex="-1"></a><span class="fu">par</span>( <span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">bty =</span> <span class="st">&#39;n&#39;</span> )</span>
<span id="cb48-6"><a href="#cb48-6" tabindex="-1"></a>xMu  <span class="ot">&lt;-</span> out<span class="sc">$</span>prediction<span class="sc">$</span>xpredMu        <span class="co"># inverse prediction of x</span></span>
<span id="cb48-7"><a href="#cb48-7" tabindex="-1"></a>xSd  <span class="ot">&lt;-</span> out<span class="sc">$</span>prediction<span class="sc">$</span>xpredSd</span>
<span id="cb48-8"><a href="#cb48-8" tabindex="-1"></a>yMu  <span class="ot">&lt;-</span> out<span class="sc">$</span>prediction<span class="sc">$</span>ypredMu        <span class="co"># predicted y</span></span>
<span id="cb48-9"><a href="#cb48-9" tabindex="-1"></a>hold <span class="ot">&lt;-</span> out<span class="sc">$</span>modelList<span class="sc">$</span>holdoutIndex    <span class="co"># holdout observations (rows)</span></span>
<span id="cb48-10"><a href="#cb48-10" tabindex="-1"></a></span>
<span id="cb48-11"><a href="#cb48-11" tabindex="-1"></a><span class="fu">plot</span>(out<span class="sc">$</span>inputs<span class="sc">$</span>xUnstand[hold,<span class="sc">-</span><span class="dv">1</span>],xMu[hold,<span class="sc">-</span><span class="dv">1</span>], <span class="at">cex=</span>.<span class="dv">2</span>, <span class="at">xlab=</span><span class="st">&#39;True&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Predictive mean&#39;</span>)</span>
<span id="cb48-12"><a href="#cb48-12" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;holdouts in x&#39;</span>)</span>
<span id="cb48-13"><a href="#cb48-13" tabindex="-1"></a><span class="fu">abline</span>( <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb48-14"><a href="#cb48-14" tabindex="-1"></a><span class="fu">plot</span>(out<span class="sc">$</span>inputs<span class="sc">$</span>y[hold,], yMu[hold,], <span class="at">cex=</span>.<span class="dv">2</span>, <span class="at">xlab=</span><span class="st">&#39;True&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb48-15"><a href="#cb48-15" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;holdouts in y&#39;</span>)</span>
<span id="cb48-16"><a href="#cb48-16" tabindex="-1"></a><span class="fu">abline</span>( <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb48-17"><a href="#cb48-17" tabindex="-1"></a></span>
<span id="cb48-18"><a href="#cb48-18" tabindex="-1"></a>xmiss   <span class="ot">&lt;-</span> out<span class="sc">$</span>missing<span class="sc">$</span>xmiss                              <span class="co"># locations of missing x</span></span>
<span id="cb48-19"><a href="#cb48-19" tabindex="-1"></a>xmissMu <span class="ot">&lt;-</span> out<span class="sc">$</span>missing<span class="sc">$</span>xmissMu</span>
<span id="cb48-20"><a href="#cb48-20" tabindex="-1"></a>xmissSe <span class="ot">&lt;-</span> out<span class="sc">$</span>missing<span class="sc">$</span>xmissSe</span>
<span id="cb48-21"><a href="#cb48-21" tabindex="-1"></a>xmean   <span class="ot">&lt;-</span> <span class="fu">apply</span>(f<span class="sc">$</span>xdata,<span class="dv">2</span>,mean,<span class="at">na.rm=</span>T)[xmiss[,<span class="dv">2</span>]] <span class="co"># column means for missing values</span></span>
<span id="cb48-22"><a href="#cb48-22" tabindex="-1"></a><span class="fu">plot</span>(xmean, xmissMu, <span class="at">xlab=</span><span class="st">&#39;Variable mean&#39;</span>, <span class="at">ylab=</span><span class="st">&#39;Missing estimate&#39;</span>) <span class="co">#posterior estimates</span></span>
<span id="cb48-23"><a href="#cb48-23" tabindex="-1"></a><span class="fu">segments</span>(xmean, xmissMu <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>xmissSe, xmean, xmissMu <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>xmissSe)          <span class="co">#approx 95% CI</span></span>
<span id="cb48-24"><a href="#cb48-24" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;missing x&#39;</span>)</span></code></pre></div>
<p>Note that there are no ‘true’ values in the simulation for missing
x–the last graph at right just shows estimates relative to mean values
for respective variables.</p>
</div>
<div id="prediction-with-heterogenous-effort" class="section level2">
<h2><span style="color:teal">prediction with heterogenous
effort</span></h2>
<p>Out-of-sample prediction can not only be done by holding out samples
in <code>gjam</code>. It can also be done post-fitting, with the
function <code>gjamPredict</code>. In this second case, a prediction
grid is passed together with the fitted object generated by
<code>gjam</code>. Here is an example with counts (<code>DA</code>) and
continuous data (<code>CA</code>). I simulate, fit, and predict these
data with heterogeneous sample effort:</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a>sc   <span class="ot">&lt;-</span> <span class="dv">3</span>                                            <span class="co"># no. CA responses</span></span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a>sd   <span class="ot">&lt;-</span> <span class="dv">10</span>                                           <span class="co"># no. DA responses</span></span>
<span id="cb49-3"><a href="#cb49-3" tabindex="-1"></a>tn   <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fu">rep</span>(<span class="st">&#39;CA&#39;</span>,sc),<span class="fu">rep</span>(<span class="st">&#39;DA&#39;</span>,sd) )               <span class="co"># combine CA and DA obs</span></span>
<span id="cb49-4"><a href="#cb49-4" tabindex="-1"></a>S    <span class="ot">&lt;-</span> <span class="fu">length</span>(tn)</span>
<span id="cb49-5"><a href="#cb49-5" tabindex="-1"></a>n    <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb49-6"><a href="#cb49-6" tabindex="-1"></a>emat <span class="ot">&lt;-</span> <span class="fu">matrix</span>( <span class="fu">runif</span>(n,.<span class="dv">5</span>,<span class="dv">5</span>), n, sd )                <span class="co"># simulated DA effort</span></span>
<span id="cb49-7"><a href="#cb49-7" tabindex="-1"></a>eff  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">columns =</span> <span class="fu">c</span>((sc<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>S), <span class="at">values =</span> emat )</span>
<span id="cb49-8"><a href="#cb49-8" tabindex="-1"></a>f    <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">n =</span> n, <span class="at">typeNames =</span> tn, <span class="at">effort =</span> eff )</span>
<span id="cb49-9"><a href="#cb49-9" tabindex="-1"></a>ml   <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames, <span class="at">effort =</span> f<span class="sc">$</span>effort )</span>
<span id="cb49-10"><a href="#cb49-10" tabindex="-1"></a>out  <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb49-11"><a href="#cb49-11" tabindex="-1"></a><span class="fu">gjamPredict</span>( out, <span class="at">y2plot =</span> <span class="fu">colnames</span>(f<span class="sc">$</span>ydata)[tn <span class="sc">==</span> <span class="st">&#39;DA&#39;</span>] ) <span class="co"># predict DA data</span></span></code></pre></div>
<p>The prediction plot fits the data well, because it assumes the same
effort. However, I might wish to predict data with a standard level of
effort, say ‘1’. This new effort is taken in the same units as was used
to fit the data, e.g., plot area, time observed, and so on. I use the
same design matrix, but specify this new effort. Here I first predict
the data with the actual effort, followed by the new effort of 1</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">&#39;#1b9e77&#39;</span>,<span class="st">&#39;#d95f02&#39;</span> )</span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>new  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">xdata =</span> f<span class="sc">$</span>xdata, <span class="at">effort=</span>eff, <span class="at">nsim =</span> <span class="dv">500</span> ) <span class="co"># effort unchanged </span></span>
<span id="cb50-3"><a href="#cb50-3" tabindex="-1"></a>p1   <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>( <span class="at">output =</span> out, <span class="at">newdata =</span> new )</span>
<span id="cb50-4"><a href="#cb50-4" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" tabindex="-1"></a><span class="fu">plot</span>(f<span class="sc">$</span>y[,tn <span class="sc">==</span> <span class="st">&#39;DA&#39;</span>], p1<span class="sc">$</span>sdList<span class="sc">$</span>yMu[,tn <span class="sc">==</span> <span class="st">&#39;DA&#39;</span>], </span>
<span id="cb50-6"><a href="#cb50-6" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Observed&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Predicted&#39;</span>, <span class="at">cex=</span>.<span class="dv">2</span>, <span class="at">col =</span> cols[<span class="dv">1</span>] )</span>
<span id="cb50-7"><a href="#cb50-7" tabindex="-1"></a><span class="fu">abline</span>( <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">lty =</span> <span class="dv">2</span> )</span>
<span id="cb50-8"><a href="#cb50-8" tabindex="-1"></a></span>
<span id="cb50-9"><a href="#cb50-9" tabindex="-1"></a>new<span class="sc">$</span>effort<span class="sc">$</span>values <span class="ot">&lt;-</span> eff<span class="sc">$</span>values<span class="sc">*</span><span class="dv">0</span> <span class="sc">+</span> <span class="dv">1</span>                 <span class="co"># predict for effort = 1</span></span>
<span id="cb50-10"><a href="#cb50-10" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>( <span class="at">output =</span> out, <span class="at">newdata =</span> new )</span>
<span id="cb50-11"><a href="#cb50-11" tabindex="-1"></a></span>
<span id="cb50-12"><a href="#cb50-12" tabindex="-1"></a><span class="fu">points</span>( f<span class="sc">$</span>y[,tn <span class="sc">==</span> <span class="st">&#39;DA&#39;</span>], p2<span class="sc">$</span>sdList<span class="sc">$</span>yMu[,tn <span class="sc">==</span> <span class="st">&#39;DA&#39;</span>], <span class="at">col=</span> cols[<span class="dv">2</span>], <span class="at">cex=</span>.<span class="dv">2</span> )</span>
<span id="cb50-13"><a href="#cb50-13" tabindex="-1"></a><span class="fu">legend</span>( <span class="st">&#39;topleft&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;Actual effort&#39;</span>, <span class="st">&#39;Effort = 1&#39;</span>), <span class="at">text.col =</span> cols, <span class="at">bty=</span><span class="st">&#39;n&#39;</span> )</span></code></pre></div>
<p>The orange dots show what the model would predict had effort on all
observations been equal to 1.</p>
</div>
<div id="conditional-prediction" class="section level2">
<h2><span style="color:teal">conditional prediction</span></h2>
<p><code>gjam</code> can predict a subset of columns in <code>y</code>
conditional on other columns using the function
<code>gjamPredict</code>. Here is an example using the model fitted in
the previous section. Consider model prediction in the case where the
second plant species is absent, and the first species is at its mean
value. In other words, for these plant species abundances, what is the
effect of model predictors? I compare it to predictions where I first
condition on the observed values for the first two plant species. I do
not specify a new version of <code>xdata</code>, but rather include the
columns of <code>y</code> to condition on:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">&#39;#1b9e77&#39;</span>,<span class="st">&#39;#d95f02&#39;</span>,<span class="st">&#39;#e7298a&#39;</span> )</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" tabindex="-1"></a>condCols <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span></span>
<span id="cb51-4"><a href="#cb51-4" tabindex="-1"></a>pCols    <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>S)[<span class="sc">-</span>condCols]</span>
<span id="cb51-5"><a href="#cb51-5" tabindex="-1"></a></span>
<span id="cb51-6"><a href="#cb51-6" tabindex="-1"></a>new <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ydataCond =</span> f<span class="sc">$</span>y[,condCols], <span class="at">nsim=</span><span class="dv">200</span>)         <span class="co"># cond on observed CA data</span></span>
<span id="cb51-7"><a href="#cb51-7" tabindex="-1"></a>p1  <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>(<span class="at">output =</span> out, <span class="at">newdata =</span> new)<span class="sc">$</span>sdList<span class="sc">$</span>yMu[,pCols]</span>
<span id="cb51-8"><a href="#cb51-8" tabindex="-1"></a></span>
<span id="cb51-9"><a href="#cb51-9" tabindex="-1"></a>new    <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ydataCond =</span> f<span class="sc">$</span>y[,condCols]<span class="sc">*</span><span class="dv">0</span>, <span class="at">nsim=</span><span class="dv">200</span>)    <span class="co"># spp 1, 2 absent</span></span>
<span id="cb51-10"><a href="#cb51-10" tabindex="-1"></a>p2     <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>(<span class="at">output =</span> out, <span class="at">newdata =</span> new)<span class="sc">$</span>sdList<span class="sc">$</span>yMu[,pCols]</span>
<span id="cb51-11"><a href="#cb51-11" tabindex="-1"></a></span>
<span id="cb51-12"><a href="#cb51-12" tabindex="-1"></a>obs <span class="ot">&lt;-</span> f<span class="sc">$</span>y[,pCols]</span>
<span id="cb51-13"><a href="#cb51-13" tabindex="-1"></a><span class="fu">plot</span>( <span class="fu">jitter</span>(obs), p2, <span class="at">xlab=</span><span class="st">&#39;Observed&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Predicted&#39;</span>, <span class="at">cex=</span>.<span class="dv">1</span>, </span>
<span id="cb51-14"><a href="#cb51-14" tabindex="-1"></a>      <span class="at">ylim=</span><span class="fu">range</span>(<span class="fu">c</span>(p1,p2)), <span class="at">col =</span> cols[<span class="dv">1</span>] )</span>
<span id="cb51-15"><a href="#cb51-15" tabindex="-1"></a><span class="fu">points</span>( <span class="fu">jitter</span>(obs), out<span class="sc">$</span>prediction<span class="sc">$</span>ypredMu[,pCols], <span class="at">col=</span>cols[<span class="dv">2</span>], <span class="at">cex=</span>.<span class="dv">1</span>)</span>
<span id="cb51-16"><a href="#cb51-16" tabindex="-1"></a><span class="fu">points</span>( <span class="fu">jitter</span>(obs), p1, <span class="at">col=</span>cols[<span class="dv">3</span>], <span class="at">cex=</span>.<span class="dv">1</span>)</span>
<span id="cb51-17"><a href="#cb51-17" tabindex="-1"></a><span class="fu">abline</span>( <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb51-18"><a href="#cb51-18" tabindex="-1"></a><span class="fu">legend</span>( <span class="st">&#39;topleft&#39;</span>, </span>
<span id="cb51-19"><a href="#cb51-19" tabindex="-1"></a>        <span class="fu">c</span>(<span class="st">&#39;Conditioned on absent spp 1:3&#39;</span>, <span class="st">&#39;Unconditional&#39;</span>, <span class="st">&#39;Conditioned on observed spp 1:3&#39;</span>), </span>
<span id="cb51-20"><a href="#cb51-20" tabindex="-1"></a>        <span class="at">text.col =</span> cols, <span class="at">bty=</span><span class="st">&#39;n&#39;</span>)</span></code></pre></div>
<p>In the first case, I held the values for columns 1 and 2 at the
values observed. This conditioning on observed values changes the
predictions of other variables. In the second case, I conditioned on the
specific values of <code>y</code> mentioned above. Both differ from the
unconditional prediction.</p>
<p>When there are large covariances in the estimates of <span class="math inline">\(\Sigma\)</span> the conditional predictions can
differ dramatically from anything observed. In fact, if I condition on
values of y that are well outside the data predictions will make no
sense at all. Conversely, if covariances in <span class="math inline">\(\Sigma\)</span> are near zero conditional
distributions will not look much different from unconditional
predictions. With dimension reduction we have only a crude estimate of
<span class="math inline">\(\Sigma\)</span>, so conditional prediction
was be judged accordingly.</p>
<p>Here is a second example, where I ask how knowledge of some species
affects ability to predict others.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a><span class="fu">library</span>(repmis)</span>
<span id="cb52-2"><a href="#cb52-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="st">&quot;https://github.com/jimclarkatduke/gjam/blob/master/forestTraits.RData?raw=True&quot;</span></span>
<span id="cb52-3"><a href="#cb52-3" tabindex="-1"></a><span class="fu">source_data</span>(d)</span>
<span id="cb52-4"><a href="#cb52-4" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" tabindex="-1"></a>xdata <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>xdata                            <span class="co"># n X Q</span></span>
<span id="cb52-6"><a href="#cb52-6" tabindex="-1"></a>ydata <span class="ot">&lt;-</span> <span class="fu">gjamReZero</span>( forestTraits<span class="sc">$</span>treesDeZero )        <span class="co"># n X S</span></span>
<span id="cb52-7"><a href="#cb52-7" tabindex="-1"></a>ydata <span class="ot">&lt;-</span> ydata[,<span class="fu">colnames</span>(ydata) <span class="sc">!=</span> <span class="st">&#39;other&#39;</span>]</span>
<span id="cb52-8"><a href="#cb52-8" tabindex="-1"></a>ydata <span class="ot">&lt;-</span> <span class="fu">gjamTrimY</span>( ydata, <span class="dv">200</span>, <span class="at">OTHER=</span>F )<span class="sc">$</span>y</span></code></pre></div>
<p>Here is a model fitted to the forest <code>&quot;DA&quot;</code> data:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a>ml      <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2500</span>, <span class="at">burnin =</span> <span class="dv">1000</span>, <span class="at">typeNames =</span> <span class="st">&#39;DA&#39;</span>, </span>
<span id="cb53-2"><a href="#cb53-2" tabindex="-1"></a>                 <span class="at">PREDICTX =</span> F )</span>
<span id="cb53-3"><a href="#cb53-3" tabindex="-1"></a>formula <span class="ot">&lt;-</span> <span class="fu">as.formula</span>(<span class="sc">~</span> temp <span class="sc">+</span> deficit<span class="sc">*</span>moisture)</span>
<span id="cb53-4"><a href="#cb53-4" tabindex="-1"></a>output  <span class="ot">&lt;-</span> <span class="fu">gjam</span>( formula, xdata, ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb53-5"><a href="#cb53-5" tabindex="-1"></a></span>
<span id="cb53-6"><a href="#cb53-6" tabindex="-1"></a><span class="co"># prediction</span></span>
<span id="cb53-7"><a href="#cb53-7" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">nsim=</span><span class="dv">100</span> )</span>
<span id="cb53-8"><a href="#cb53-8" tabindex="-1"></a>tmp     <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>( output, <span class="at">newdata=</span>newdata )</span>
<span id="cb53-9"><a href="#cb53-9" tabindex="-1"></a>full    <span class="ot">&lt;-</span> tmp<span class="sc">$</span>sdList<span class="sc">$</span>yMu</span></code></pre></div>
<p>Here I condition on half of the species and predict the other
half:</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a>cols    <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="st">&#39;#1b9e77&#39;</span>,<span class="st">&#39;#d95f02&#39;</span> )</span>
<span id="cb54-2"><a href="#cb54-2" tabindex="-1"></a>cnames  <span class="ot">&lt;-</span> <span class="fu">sample</span>( <span class="fu">colnames</span>(ydata), S<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb54-3"><a href="#cb54-3" tabindex="-1"></a>wc      <span class="ot">&lt;-</span> <span class="fu">match</span>(cnames, <span class="fu">colnames</span>(ydata))</span>
<span id="cb54-4"><a href="#cb54-4" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ydataCond =</span> ydata[,cnames], <span class="at">nsim=</span><span class="dv">100</span>)</span>
<span id="cb54-5"><a href="#cb54-5" tabindex="-1"></a>tmp     <span class="ot">&lt;-</span> <span class="fu">gjamPredict</span>(output, <span class="at">newdata =</span> newdata)</span>
<span id="cb54-6"><a href="#cb54-6" tabindex="-1"></a>condy   <span class="ot">&lt;-</span> tmp<span class="sc">$</span>sdList<span class="sc">$</span>yMu</span>
<span id="cb54-7"><a href="#cb54-7" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" tabindex="-1"></a><span class="fu">plot</span>(ydata[,<span class="sc">-</span>wc], full[,<span class="sc">-</span>wc], <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fu">range</span>(ydata)), </span>
<span id="cb54-9"><a href="#cb54-9" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&#39;Observed&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Predicted&#39;</span>, <span class="at">col =</span> cols[<span class="dv">1</span>], <span class="at">cex =</span> .<span class="dv">3</span>)</span>
<span id="cb54-10"><a href="#cb54-10" tabindex="-1"></a><span class="fu">abline</span>( <span class="dv">0</span>, <span class="dv">1</span>, <span class="at">lty=</span><span class="dv">2</span> )</span>
<span id="cb54-11"><a href="#cb54-11" tabindex="-1"></a><span class="fu">points</span>( ydata[,<span class="sc">-</span>wc], condy[,<span class="sc">-</span>wc], <span class="at">col =</span> cols[<span class="dv">2</span>], <span class="at">cex =</span> .<span class="dv">3</span>)</span>
<span id="cb54-12"><a href="#cb54-12" tabindex="-1"></a><span class="fu">legend</span>( <span class="st">&#39;topleft&#39;</span>, <span class="fu">c</span>(<span class="st">&#39;Unconditional&#39;</span>, <span class="st">&#39;Conditional on half of species&#39;</span>), </span>
<span id="cb54-13"><a href="#cb54-13" tabindex="-1"></a>        <span class="at">text.col =</span> cols[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], <span class="at">bty=</span><span class="st">&#39;n&#39;</span> )</span></code></pre></div>
<p>Again, the conditional prediction can differ from the unconditional
one, due to the covariances between species.</p>
</div>
<div id="conditional-parameters" class="section level2">
<h2><span style="color:teal">conditional parameters</span></h2>
<p>The parameters used for conditional prediction can be obtained with
the function <code>gjamConditionalParameters</code>. The coeffficients
come from a partition of the response vector as <span class="math inline">\(\mathbf{w}&#39; = [\mathbf{u},
\mathbf{v}]\)</span> with coefficient and covariance matrices</p>
<p><span class="math display">\[
\mathbf{B} =
\begin{bmatrix}
\mathbf{B}_u \\
\mathbf{B}_v \\
\end{bmatrix},
\Sigma =
\begin{bmatrix}
\Sigma_{uu} &amp; \Sigma_{uv} \\
\Sigma_{vu} &amp; \Sigma_{vv} \\
\end{bmatrix}
\]</span></p>
<p>Write the conditional distribution for responses in <span class="math inline">\(\mathbf{u}\)</span> conditioned on values set for
the others in <span class="math inline">\(\mathbf{v}\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{u}|\mathbf{v} &amp;\sim MVN \left( \mathbf{C}\mathbf{x} +
\mathbf{A}\mathbf{v}, \mathbf{P} \right) \\
\mathbf{A} &amp;= \Sigma_{uv} \Sigma^{-1}_{vv} \\
\mathbf{C} &amp;= \mathbf{B}_u - \mathbf{A}\mathbf{B}_v \\
\mathbf{P} &amp;= \Sigma_{uu} - \mathbf{A}\Sigma_{vu}
\end{aligned}
\]</span> <code>gjamConditionalParameters</code> takes the fitted
<code>gjam</code> object and returns these three matrices, each as a
matrix of posterior means and standard errors and as a table with 95%
credible intervals. The <code>vector conditionOn</code> holds the column
names in <code>ydata</code> for the variables that I want to condition
on, i.e., in the subvector <span class="math inline">\(\mathbf{v}\)</span>,</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a><span class="fu">gjamConditionalParameters</span>( output, <span class="at">conditionOn =</span> <span class="fu">c</span>(<span class="st">&#39;acerSacc&#39;</span>,<span class="st">&#39;betuAlle&#39;</span>,<span class="st">&#39;faguGran&#39;</span>,<span class="st">&#39;querRubr&#39;</span>) )</span></code></pre></div>
<p>Matrix <span class="math inline">\(\mathbf{A}\)</span> is like a
regression matrix on species. It is a <span class="math inline">\(S_u
\times S_v\)</span> matrix holding the effects of each response in
<code>conditionOn</code> (<span class="math inline">\(\mathbf{v}\)</span>) on the other columns (<span class="math inline">\(\mathbf{u}\)</span>).</p>
<p>Matrix <span class="math inline">\(\mathbf{C}\)</span> are regression
coefficients on predictors in <span class="math inline">\(\mathbf{x}\)</span>, after extracting the
contribution from other species. It is a <span class="math inline">\(S_u
\times Q\)</span> matrix.</p>
<p>Matrix <span class="math inline">\(\mathbf{P}\)</span> is the <span class="math inline">\(S_u \times S_u\)</span> conditional
covariance.</p>
</div>
<div id="presence-only-data-with-effort" class="section level2">
<h2><span style="color:teal">presence-only data with effort</span></h2>
<p>If I have a model for effort, then incidence data can have a
likelihood, i.e., a probability assigned to observations that are
aggregated into groups of known effort. I cannot model absence for the
aggregate data unless I know how much effort was devoted to searching
for it. Effort is widely known to have large spatio-temporal and
taxonomic bias.</p>
<p>If I know the effort for a region, even in terms of a model (e.g.,
distance from universities and museums, from rivers or trails, numbers
of a species already in collections), I can treat aggregate data as
counts. If I do not know effort, out of desperation I might use the
total numbers of all species counted in a region as a crude index of
effort. The <code>help</code> page for function
<code>gjamPoints2Grid</code> provides examples to aggregate incidence
data with (x, y) locations to a lattice.</p>
<p>If effort is known I can supply a prediction grid
<code>predGrid</code> for the known effort map and aggregate incidence
to that map. I can then model the data are <code>&#39;DA&#39;</code> data,
specifying effort as in the example above.</p>
<p>If effort is unknown, I can model the data as composition data,
<code>&#39;CC&#39;</code>. Again, this is a desperate measure, because there are
many reasons why even the total for all species at a lattice point might
not represent relative effort.</p>
<p><br></p>
</div>
</div>
<div id="dimension-reduction" class="section level1">
<h1><span style="color:darkgreen">dimension reduction</span></h1>
<p>Microbiome, genetic, and hyperspectral satelitte data are examples of
observations characterized by a large number of response variables <span class="math inline">\(S\)</span> (e.g., species); we refer to such data
sets as <em>‘big-S’</em>. Covariance <span class="math inline">\(\boldsymbol{\Sigma}\)</span> has dimension <span class="math inline">\(S \times S\)</span>, with <span class="math inline">\(S(S + 1)/2\)</span> unique elements, the
<em>S</em> diagonal elements plus <span class="math inline">\(1/2\)</span> of the off-diagonal elements. For
example, a data set with <span class="math inline">\(S = 100\)</span>
has 5050 unique elements in <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. It must be inverted,
an order<span class="math inline">\((S^{3})\)</span> operation. Even in
cases where <span class="math inline">\(\Sigma\)</span> can be inverted
the number of observations may not be sufficient to accurately estimate
the large number of parameters in the model. In gjam, <em>big-S</em> is
handled by generating a low-order approximation of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. The rank of <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is reduced by finding
structure, essentially groups of responses that respond similarly.
(Taylor-Rodriguez et al. 2017).</p>
<p>The interpretation of a reduced model warrants a few words. If we
replace <span class="math inline">\(\boldsymbol{\Sigma}\)</span> with a
much smaller number of estimates, we cannot insist that we can know the
covariance between every species. If <span class="math inline">\(\boldsymbol{\Sigma}\)</span> does not contain
structure that can be adequately summarized with fewer estimates, then
we have at best a version of the model that soaks up some of the
dependence structure that is important for estimating <span class="math inline">\(\mathbf{B}\)</span>. On the other hand <span class="math inline">\(\boldsymbol{\Sigma}\)</span> may contain
substantial structure that can be captured by a small number of
estimates. We first point out that an analysis of <em>big-S</em> data
sets need not include every species that might be recorded in a data set
and how gjam functions can be used to trim large data sets. We then
describe dimension reduction in gjam.</p>
<p>A species <em>s</em> that bears no relationship to any of the
predictors in <span class="math inline">\(\mathbf{X}\)</span> (all <span class="math inline">\(\mathbf{B}_{s}\)</span> small) or to other species
<em>s’</em> (all <span class="math inline">\(\boldsymbol{\Sigma}_{s&#39;,s}\)</span> small)
will not be ‘explained’ by the model. Such species will contribute
little to the model fit, while degrading performance. Consider either of
two options for reducing the number of species in the model,
<em>trimming</em> and <em>aggregation</em>.</p>
<p><strong>Trim</strong> species that are not of interest, that will not
affect the fit, or both.</p>
<p><strong>Aggregation</strong> can be based on a number of criteria,
such as phylogenetic similarity (e.g., members of the same genus), by
functional similarity (e.g., a feeding guild, C<sub>3</sub> vs
C<sub>4</sub> plants), and so forth. Rare species can be aggregated into
a single group. For example, Clark et al. (2014) include 96 tree species
that occur on a minimum of 50 forest inventory plots in eastern North
America. The remaining species can be gathered into a single class. When
this option is used the name <em>‘other’</em> is assigned to this class
in the plots-by-species matrix <code>ydata</code>. Including this class
is important where species compete, such as forest trees. It can also be
used as a reference category for composition data, summarized below</p>
<p>In gjam, the total number of covariance parameter estimates is
reduced to <span class="math inline">\(N \times r\)</span>, where <span class="math inline">\(r &lt; N &lt;&lt; S\)</span>. The integer <span class="math inline">\(N\)</span> represents the potential number of
response groups. The integer <span class="math inline">\(r\)</span> is
the dimensionality of each group. In other words, large <em>N</em> means
more groups, and large <em>r</em> increases the flexibility of those
<em>N</em> groups.</p>
<p>Dimension reduction is invoked in one of two ways. <strong>The first
way</strong> is automatic, when i) a data set includes more species than
can be fitted given sample size <em>n</em> or when ii) <em>S</em> is too
large irrespective of <em>n</em>.</p>
<p><strong>A second way</strong> to invoke dimension reduction is to
specify it in <code>modelList</code>, through the
<code>list reductList</code>. Here is an example using simulated data,
where the number of species is twice the number of observations.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" tabindex="-1"></a>f   <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>( <span class="at">n =</span> <span class="dv">100</span>, <span class="at">S =</span> <span class="dv">200</span>, <span class="at">typeNames=</span><span class="st">&#39;CA&#39;</span> )</span>
<span id="cb56-2"><a href="#cb56-2" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> f<span class="sc">$</span>typeNames, </span>
<span id="cb56-3"><a href="#cb56-3" tabindex="-1"></a>            <span class="at">reductList =</span> <span class="fu">list</span>(<span class="at">r =</span> <span class="dv">15</span>, <span class="at">N =</span> <span class="dv">25</span>), <span class="at">PREDICTX =</span> F )  </span>
<span id="cb56-4"><a href="#cb56-4" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>( f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata, f<span class="sc">$</span>ydata, <span class="at">modelList =</span> ml )</span>
<span id="cb56-5"><a href="#cb56-5" tabindex="-1"></a><span class="fu">gjamPlot</span>( <span class="at">output =</span> out, <span class="at">plotPars =</span> <span class="fu">list</span>(<span class="at">trueValues =</span> f<span class="sc">$</span>trueValues) )</span></code></pre></div>
<p>The full matrix is not stored, so gjam needs time to construct
versions of it as needed. The setting <code>PREDICTX = F</code> can be
included in <code>modelList</code> to speed up computation, when
prediction of inputs is not of interest.</p>
<p>The massive reduction in rank of the covariance matrix means that the
we cannot estimate the ‘true’ version of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>, particularly given
the fact that the simulator does not generate a structured <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. These appear as
highly structured <code>GRIDPLOTS</code> for the posterior mean
estimates of the correlation matrix <span class="math inline">\(\mathbf{R}\)</span>. However, we can still obtain
estimates of <span class="math inline">\(\mathbf{B}\)</span> and
predictions of <span class="math inline">\(\mathbf{Y}\)</span> that are
close to true values.</p>
<p>To override the automatic dimension reduction for a large response
matrix, specify <code>modelList$REDUCT &lt;- FALSE</code>.</p>
<div id="big-s-composition-data-fungal-endophytes" class="section level2">
<h2><span style="color:teal"><em>big-S</em> composition data: fungal
endophytes</span></h2>
<p>Microbiome data are often <em>big-S, small-n</em>; with thousands of
response variables, columns in <span class="math inline">\(\mathbf{Y}\)</span> (e.g., OTUs). They are also
composition count (<code>&#39;CC&#39;</code>) data, discrete counts, but not
related to absolute abundance; they are meaningful in a relative sense.
Because data only inform about relative abundance, there is information
for only <span class="math inline">\(S - 1\)</span> species. If there
are thousands of OTUs, most of which are rare and thus not explained by
the model, consider aggregating the many rare types into a single
<code>other</code> class.</p>
<p>Fungal endophytes were sequenced on host tree seedlings (Hersh et
al. 2016). In the data set <code>fungEnd</code> there is a compressed
version of responses <code>yDeZero</code> containing OTU counts, a
<code>data.frame</code> <code>xdata</code> containing predictors, and
<code>status</code>, a vector of host responses, 0 for morbid, 1 for no
signs of morbidity. Several histograms show the overwhelming numbers of
zeros. Here we extract the data, stored in de-zeroed format, and
generate some plots:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" tabindex="-1"></a><span class="fu">library</span>(repmis)</span>
<span id="cb57-2"><a href="#cb57-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="st">&quot;https://github.com/jimclarkatduke/gjam/blob/master/fungEnd.RData?raw=True&quot;</span></span>
<span id="cb57-3"><a href="#cb57-3" tabindex="-1"></a><span class="fu">source_data</span>(d)</span>
<span id="cb57-4"><a href="#cb57-4" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" tabindex="-1"></a>xdata  <span class="ot">&lt;-</span> fungEnd<span class="sc">$</span>xdata</span>
<span id="cb57-6"><a href="#cb57-6" tabindex="-1"></a>otu    <span class="ot">&lt;-</span> <span class="fu">gjamReZero</span>(fungEnd<span class="sc">$</span>yDeZero)</span>
<span id="cb57-7"><a href="#cb57-7" tabindex="-1"></a>status <span class="ot">&lt;-</span> fungEnd<span class="sc">$</span>status</span>
<span id="cb57-8"><a href="#cb57-8" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" tabindex="-1"></a><span class="fu">par</span>( <span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">bty=</span><span class="st">&#39;n&#39;</span> )</span>
<span id="cb57-10"><a href="#cb57-10" tabindex="-1"></a><span class="fu">hist</span>( status, <span class="at">main=</span><span class="st">&#39;Host condition (morbid = 0)&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;Host obs&#39;</span> )</span>
<span id="cb57-11"><a href="#cb57-11" tabindex="-1"></a><span class="fu">hist</span>( otu, <span class="at">nclass=</span><span class="dv">100</span>, <span class="at">ylab =</span> <span class="st">&quot;Reads&quot;</span>, <span class="at">main =</span> <span class="st">&quot;OTU&#39;s&quot;</span> )</span>
<span id="cb57-12"><a href="#cb57-12" tabindex="-1"></a>nobs <span class="ot">&lt;-</span> <span class="fu">gjamTrimY</span>( otu, <span class="at">minObs =</span> <span class="dv">1</span>, <span class="at">OTHER =</span> F )<span class="sc">$</span>nobs</span>
<span id="cb57-13"><a href="#cb57-13" tabindex="-1"></a><span class="fu">hist</span>( nobs<span class="sc">/</span><span class="fu">ncol</span>(otu), <span class="at">nclass=</span><span class="dv">100</span>, <span class="at">xlab =</span> <span class="st">&#39;Fraction of observations&#39;</span>, </span>
<span id="cb57-14"><a href="#cb57-14" tabindex="-1"></a>      <span class="at">ylab =</span> <span class="st">&#39;Frequency&#39;</span>, <span class="at">main=</span><span class="st">&#39;Incidence&#39;</span> )</span></code></pre></div>
<p>The graph on the left shows that two thirds of host seedlings are in
the morbid condition. The middle graph shows that an individual OTU may
be counted &gt; 40,000 times in an obseration, but the vast majority of
observations (96%) are zero. The graph on the right shows the frequency
for the fraction of observations in which each OTU occurs. The most
common OTU occurs in 23% of observations, but most occur only once or
twice.</p>
<p>The model will provide no information on the rarest taxa. Here we
trim <code>otu</code> to include only OTUs that occur in &gt; 100
observations. The rarest OTUs are aggregated into the last column of
<code>y</code> with the column name <code>other</code>:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" tabindex="-1"></a>tmp <span class="ot">&lt;-</span> <span class="fu">gjamTrimY</span>(otu, <span class="at">minObs =</span> <span class="dv">100</span>)</span>
<span id="cb58-2"><a href="#cb58-2" tabindex="-1"></a>y   <span class="ot">&lt;-</span> tmp<span class="sc">$</span>y</span>
<span id="cb58-3"><a href="#cb58-3" tabindex="-1"></a><span class="fu">dim</span>(fungEnd<span class="sc">$</span>y)               <span class="co"># all OTUs</span></span>
<span id="cb58-4"><a href="#cb58-4" tabindex="-1"></a><span class="fu">dim</span>(y)                       <span class="co"># trimmed data</span></span>
<span id="cb58-5"><a href="#cb58-5" tabindex="-1"></a><span class="fu">tail</span>(<span class="fu">colnames</span>(y))            <span class="co"># &#39;other&#39; class added</span></span></code></pre></div>
<p>The full response matrix includes the OTU composition counts and the
host status in column 1:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" tabindex="-1"></a>ydata <span class="ot">&lt;-</span> <span class="fu">cbind</span>(status, y)     <span class="co"># host status is also a response</span></span>
<span id="cb59-2"><a href="#cb59-2" tabindex="-1"></a>S     <span class="ot">&lt;-</span> <span class="fu">ncol</span>(ydata)</span>
<span id="cb59-3"><a href="#cb59-3" tabindex="-1"></a>typeNames    <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;CC&#39;</span>,S)   <span class="co"># composition count data</span></span>
<span id="cb59-4"><a href="#cb59-4" tabindex="-1"></a>typeNames[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="st">&#39;PA&#39;</span>          <span class="co"># binary host status </span></span></code></pre></div>
<p>The interactions in the model involve two factors <code>poly</code>
(two levels, polyculture vs monoculture) and <code>host</code> (eight
factor levels, one for each host species). I assign
<code>acerRubr</code> as the reference class for <code>host</code>,</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" tabindex="-1"></a>xdata<span class="sc">$</span>host <span class="ot">&lt;-</span> <span class="fu">relevel</span>(xdata<span class="sc">$</span>host,<span class="st">&#39;acerRubr&#39;</span>)</span></code></pre></div>
<p>For this example we specify up to <span class="math inline">\(N =
20\)</span> clusters with <span class="math inline">\(r = 3\)</span>
columns each. Here is an analysis of host seedling and polyculture
effect on combined host morbidity status and the microbiome
composition:</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" tabindex="-1"></a>ml <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> typeNames, </span>
<span id="cb61-2"><a href="#cb61-2" tabindex="-1"></a>            <span class="at">reductList =</span> <span class="fu">list</span>(<span class="at">r =</span> <span class="dv">8</span>, <span class="at">N =</span> <span class="dv">15</span>) )</span>
<span id="cb61-3"><a href="#cb61-3" tabindex="-1"></a>output <span class="ot">&lt;-</span> <span class="fu">gjam</span>(<span class="sc">~</span> host<span class="sc">*</span>poly, xdata, ydata, <span class="at">modelList =</span> ml)</span></code></pre></div>
<p>Here is output:</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">ncol</span>(ydata)</span>
<span id="cb62-2"><a href="#cb62-2" tabindex="-1"></a>specColor     <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;blue&#39;</span>,S)</span>
<span id="cb62-3"><a href="#cb62-3" tabindex="-1"></a>specColor[<span class="dv">1</span>]  <span class="ot">&lt;-</span> <span class="st">&#39;#b2182b&#39;</span>                 <span class="co"># highlight host status</span></span>
<span id="cb62-4"><a href="#cb62-4" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">gjamPlot</span>( output, <span class="at">plotPars =</span> <span class="fu">list</span>(<span class="at">specColor =</span> specColor, <span class="at">GRIDPLOTS =</span> T,</span>
<span id="cb62-5"><a href="#cb62-5" tabindex="-1"></a>                                         <span class="at">SIGONLY =</span> T) )</span>
<span id="cb62-6"><a href="#cb62-6" tabindex="-1"></a>fit<span class="sc">$</span>eComs[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span></code></pre></div>
<p>Check the chains for convergence. Those coefficients that do not
converge are poorly represented in factorial factor combinations.</p>
<p>Again, the low dimensional version of covariance <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is expected to
perform best when there is structure in the data. The responses in
matrix <span class="math inline">\(\mathbf{E}\)</span>, returned in
<code>fit$ematrix</code>, classify OTUs in three main groups, contained
in <code>fit$eComs</code>.</p>
</div>
<div id="interactions-and-indirect-effects" class="section level2">
<h2><span style="color:teal">interactions and indirect
effects</span></h2>
<p>A plot of main effects, interactions, and indirect effects is used in
this example to show contributions to host status, the response variable
<code>status</code>. The effects on host status of on responses is
available as a table with standard errors and credible intervals:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" tabindex="-1"></a>beta <span class="ot">&lt;-</span> output<span class="sc">$</span>parameters<span class="sc">$</span>betaTable</span>
<span id="cb63-2"><a href="#cb63-2" tabindex="-1"></a>ws   <span class="ot">&lt;-</span> <span class="fu">grep</span>( <span class="st">&#39;status_&#39;</span>,<span class="fu">rownames</span>(beta) )  <span class="co"># find coefficients for status</span></span>
<span id="cb63-3"><a href="#cb63-3" tabindex="-1"></a>beta[ws,]</span></code></pre></div>
<p>Following the intercept are rows showing main effects. These are
followed by interaction terms. A quick visual of coefficients having
credible intervals that exclude zero is here:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" tabindex="-1"></a>ws <span class="ot">&lt;-</span> <span class="fu">which</span>(beta<span class="sc">$</span>sig95 <span class="sc">==</span> <span class="st">&#39;*&#39;</span>)</span>
<span id="cb64-2"><a href="#cb64-2" tabindex="-1"></a>beta[ws,]</span></code></pre></div>
<p>with <code>-</code> and <code>+</code> indicating negative and
postive values.</p>
<p>Here I use the function <code>gamIIE</code> to create the object
<code>fit1</code>, a <code>list</code> of these main, interaction, and
indirect effects. I specify not to include the response variable
<code>other</code> as an indirect effect on <code>status</code>, because
we want to focus on the effects of microbes that have been assigned to
known taxonomic groups.</p>
<p>I specify the values for main effects that are involved in the
interactions between <code>poly</code> and <code>host</code>. Each
factor has one less column in the design matrix <code>x</code> than
factor levels. <code>poly</code> has two classes in <code>xdata</code>,
one each for monoculture and polyculture, so there is one
<code>poly</code> column in <code>x</code>. <code>host</code> has eight
species in <code>xdata</code>, so there are seven columns in
<code>x</code>. Recall that we assigned <code>acerRubr</code> to be the
reference class, so there is no column for it in <code>x</code>.</p>
<p>The vector of predictor values <code>xvector</code> passed to
<code>gjamIIE</code> has the same elements and names as columns in
<code>x</code>. For this reason it is easiest to simply assign it a row
in <code>x</code>, then change the values. The only values that
influence interactions are those that are involved in interaction terms,
as specified in <code>formula</code>.</p>
<p>For the following plots I copy the first row of <code>x</code>. In
the first are main effects of all predictors on <code>status</code>. In
the second plot is interactions with <code>poly</code> set to 1. In the
third plot are indirect effects of the microbes:</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> output<span class="sc">$</span>inputs<span class="sc">$</span>xUnstand</span>
<span id="cb65-2"><a href="#cb65-2" tabindex="-1"></a>xvector <span class="ot">&lt;-</span> x[<span class="dv">1</span>,]<span class="sc">*</span><span class="dv">0</span></span>
<span id="cb65-3"><a href="#cb65-3" tabindex="-1"></a><span class="fu">names</span>(xvector)  <span class="ot">&lt;-</span> <span class="fu">colnames</span>(x)</span>
<span id="cb65-4"><a href="#cb65-4" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" tabindex="-1"></a>xvector[<span class="st">&#39;hostfraxAmer&#39;</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb65-6"><a href="#cb65-6" tabindex="-1"></a>xvector[<span class="st">&#39;polypoly&#39;</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb65-7"><a href="#cb65-7" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">gjamIIE</span>(output, xvector, <span class="at">omitY =</span> <span class="st">&#39;other&#39;</span>)</span>
<span id="cb65-8"><a href="#cb65-8" tabindex="-1"></a></span>
<span id="cb65-9"><a href="#cb65-9" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">bty=</span><span class="st">&#39;n&#39;</span>, <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>), </span>
<span id="cb65-10"><a href="#cb65-10" tabindex="-1"></a>    <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">1</span>), <span class="at">tcl =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">mgp =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb65-11"><a href="#cb65-11" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit1, <span class="at">response =</span> <span class="st">&#39;status&#39;</span>, <span class="at">effectMu =</span> <span class="st">&#39;direct&#39;</span>, </span>
<span id="cb65-12"><a href="#cb65-12" tabindex="-1"></a>            <span class="at">effectSd =</span> <span class="st">&#39;direct&#39;</span>, <span class="at">legLoc =</span> <span class="st">&#39;bottomright&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb65-13"><a href="#cb65-13" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Direct effect by host&#39;</span>)</span>
<span id="cb65-14"><a href="#cb65-14" tabindex="-1"></a></span>
<span id="cb65-15"><a href="#cb65-15" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit1, <span class="at">response =</span> <span class="st">&#39;status&#39;</span>, <span class="at">effectMu =</span> <span class="st">&#39;int&#39;</span>, <span class="at">effectSd =</span> <span class="st">&#39;int&#39;</span>,</span>
<span id="cb65-16"><a href="#cb65-16" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;topright&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>,<span class="dv">10</span>))</span>
<span id="cb65-17"><a href="#cb65-17" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Interactions with polyculture&#39;</span>)</span>
<span id="cb65-18"><a href="#cb65-18" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit1, <span class="at">response =</span> <span class="st">&#39;status&#39;</span>, <span class="at">effectMu =</span> <span class="st">&#39;ind&#39;</span>, <span class="at">effectSd =</span> <span class="st">&#39;ind&#39;</span>,</span>
<span id="cb65-20"><a href="#cb65-20" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;topright&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb65-21"><a href="#cb65-21" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;Indirect effect of microbiome&#39;</span>)</span></code></pre></div>
<p>The plot at left is the direct effect, which includes both the main
effects plus interactions and plotted relative to the mean over all
hosts. The interaction contribution at center is the effect of each
host, when grown in polyculture (<code>poly = ref1</code>) and of
polyculture when the <code>host = &#39;fraxAmer</code>.</p>
<p>The indirect effects bring with them the main effects and interaction
effects on each microbial taxon. In this example the indirect effects
are noisy, showing large 95% intervals.</p>
<p><br></p>
</div>
</div>
<div id="joint-trait-modeling" class="section level1">
<h1><span style="color:darkgreen">joint trait modeling</span></h1>
<p>Because it accommodates different data types gjam can be used to
model ecological traits by either of two approaches (<a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.1453">Clark
2016</a>). One approach uses community weighted mean/mode (CWMM) trait
values for a plot <span class="math inline">\(i\)</span> as a response
vector <span class="math inline">\(\mathbf{u}_{i}\)</span>, where each
trait has a corresponding data type designation in
<code>typeNames</code>. I discuss this approach first. I then summarize
the second approach, predictive trait modeling.</p>
<div id="trait-response-model-trm" class="section level2">
<h2><span style="color:teal">trait response model (TRM)</span></h2>
<p>There are <span class="math inline">\(n\)</span> observations of
<span class="math inline">\(M\)</span> traits to be explained by <span class="math inline">\(Q - 1\)</span> predictors in design matrix <span class="math inline">\(\mathbf{X}\)</span>. The Trait Response Model
(TRM) in <a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.1453">Clark
2016</a> is</p>
<p><span class="math display">\[\mathbf{w}_{i} \sim
MVN(\mathbf{A}&#39;\mathbf{x}_{i},\Omega)\]</span></p>
<p>where <span class="math inline">\(\mathbf{w}_{i}\)</span> is a
length-<span class="math inline">\(M\)</span> vector of expected CWMM
values, <span class="math inline">\(\mathbf{A}\)</span> is the <span class="math inline">\(Q \times M\)</span> matrix of coefficients, and
<span class="math inline">\(\Omega\)</span> is the <span class="math inline">\(M \times M\)</span> residual covariance (diagram
below). After describing the setup and model fitting I show how gjam
summarizes the estimates and predictions.</p>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p><strong>Trait response model</strong> showing the sizes of matrices
for a sample containing <em>n</em> observations, <em>M</em> traits, and
<em>Q</em> predictors.</p>
<p><br></p>
<div id="input-data" class="section level3">
<h3><span style="color:brown">input data</span></h3>
<p>Data contained in <code>forestTraits</code> include predictors in
<code>xdata</code>, a character vector of data types in
<code>traitTypes</code>, and <code>treesDeZero</code>, which contains
tree biomass in de-zeroed format. Here the data are loaded, re-zeroed
with <code>gjamReZero</code>:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" tabindex="-1"></a><span class="fu">library</span>(repmis)</span>
<span id="cb66-2"><a href="#cb66-2" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="st">&quot;https://github.com/jimclarkatduke/gjam/blob/master/forestTraits.RData?raw=True&quot;</span></span>
<span id="cb66-3"><a href="#cb66-3" tabindex="-1"></a><span class="fu">source_data</span>(d)</span>
<span id="cb66-4"><a href="#cb66-4" tabindex="-1"></a></span>
<span id="cb66-5"><a href="#cb66-5" tabindex="-1"></a>xdata <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>xdata                          <span class="co"># n X Q</span></span>
<span id="cb66-6"><a href="#cb66-6" tabindex="-1"></a>types <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>traitTypes                     <span class="co"># 12 trait types </span></span>
<span id="cb66-7"><a href="#cb66-7" tabindex="-1"></a>sbyt  <span class="ot">&lt;-</span> forestTraits<span class="sc">$</span>specByTrait                    <span class="co"># S X 12</span></span>
<span id="cb66-8"><a href="#cb66-8" tabindex="-1"></a>pbys  <span class="ot">&lt;-</span> <span class="fu">gjamReZero</span>(forestTraits<span class="sc">$</span>treesDeZero)        <span class="co"># n X S</span></span>
<span id="cb66-9"><a href="#cb66-9" tabindex="-1"></a>pbys  <span class="ot">&lt;-</span> <span class="fu">gjamTrimY</span>(pbys,<span class="dv">5</span>)<span class="sc">$</span>y                         <span class="co"># at least 5 plots</span></span>
<span id="cb66-10"><a href="#cb66-10" tabindex="-1"></a>sbyt  <span class="ot">&lt;-</span> sbyt[<span class="fu">match</span>(<span class="fu">colnames</span>(pbys),<span class="fu">rownames</span>(sbyt)),] <span class="co"># trait matrix matches ydata</span></span>
<span id="cb66-11"><a href="#cb66-11" tabindex="-1"></a><span class="fu">identical</span>(<span class="fu">rownames</span>(sbyt),<span class="fu">colnames</span>(pbys))</span></code></pre></div>
<p>The matrix <code>pbys</code> holds biomass values for species. The
first six columns of <code>sbyt</code> are centered and standardized.
The three ordinal classes are integer values, but do not represent an
absolute scale (see below). The three groups of categorical variables in
<code>data.frame sbyt</code> have different numbers of levels shown
here:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" tabindex="-1"></a><span class="fu">table</span>(sbyt<span class="sc">$</span>leaf)      <span class="co"># four levels</span></span>
<span id="cb67-2"><a href="#cb67-2" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" tabindex="-1"></a><span class="fu">table</span>(sbyt<span class="sc">$</span>xylem)     <span class="co"># diffuse/tracheid vs ring-porous</span></span>
<span id="cb67-4"><a href="#cb67-4" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" tabindex="-1"></a><span class="fu">table</span>(sbyt<span class="sc">$</span>repro)     <span class="co"># two levels</span></span></code></pre></div>
<p>These species traits are translated into community-weighted means and
modes (CWMM) by the function <code>gjamSpec2Trait</code>:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" tabindex="-1"></a>tmp         <span class="ot">&lt;-</span> <span class="fu">gjamSpec2Trait</span>(pbys, sbyt, types)</span>
<span id="cb68-2"><a href="#cb68-2" tabindex="-1"></a>tTypes      <span class="ot">&lt;-</span> tmp<span class="sc">$</span>traitTypes                  <span class="co"># M = 15 values</span></span>
<span id="cb68-3"><a href="#cb68-3" tabindex="-1"></a>u           <span class="ot">&lt;-</span> tmp<span class="sc">$</span>plotByCWM                   <span class="co"># n X M</span></span>
<span id="cb68-4"><a href="#cb68-4" tabindex="-1"></a>censor      <span class="ot">&lt;-</span> tmp<span class="sc">$</span>censor                      <span class="co"># (0, 1) censoring, two-level CAT&#39;s</span></span>
<span id="cb68-5"><a href="#cb68-5" tabindex="-1"></a>specByTrait <span class="ot">&lt;-</span> tmp<span class="sc">$</span>specByTrait                 <span class="co"># S X M</span></span>
<span id="cb68-6"><a href="#cb68-6" tabindex="-1"></a>M           <span class="ot">&lt;-</span> <span class="fu">ncol</span>(u)</span>
<span id="cb68-7"><a href="#cb68-7" tabindex="-1"></a>n           <span class="ot">&lt;-</span> <span class="fu">nrow</span>(u)</span>
<span id="cb68-8"><a href="#cb68-8" tabindex="-1"></a><span class="fu">cbind</span>(<span class="fu">colnames</span>(u),tTypes)                      <span class="co"># M trait names and types</span></span></code></pre></div>
</div>
<div id="traits-by-species" class="section level3">
<h3><span style="color:brown">traits by species</span></h3>
<p>Note the change in data types by comparing <code>types</code> for
individuals of a species with <code>tTypes</code> for CWMM values at the
plot scale. At the plot scale <code>tTypes</code> has <span class="math inline">\(M = 15\)</span> values, because the leaf
<code>&#39;CAT&#39;</code> group in <code>types</code> includes four levels,
which are expanded to four <code>&#39;FC&#39;</code> columns in <code>u</code>.
The two-level groups <code>&#39;xylem&#39;</code> and <code>&#39;repro&#39;</code> are
transformed to censored continuous values on (0, 1) and thus each occupy
a single column in <code>u</code>.</p>
<p>As discussed in <a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.1453">Clark
(2016)</a> the interpretation of CWMM values in <code>u</code> is not
the same as the interpretation of species-level traits assigned in
<code>forestTraits$specByTrait</code>. Let <span class="math inline">\(\mathbf{T&#39;}\)</span> be a species-by-traits
matrix <code>specByTrait</code>, constructed as CWMM values in function
<code>gjamSpec2Trait</code>. The row names of <code>specByTrait</code>
match the column names for the <span class="math inline">\(n \times
S\)</span> species abundance matrix <code>plotByTrees</code>. The latter
is referenced to individuals of a species.</p>
<p>The plot-by-trait matrix <code>u</code> is referenced to a location,
i.e., one row in matrix <code>u</code>. It is a CWMM, with values
derived from measurements on individual trees, but combined to produce a
weighted value for each location. Ordinal traits (<code>shade</code>,
<code>drought</code>, <code>flood</code>) are community weighted modes,
because ordinal scores cannot be averaged. The CWMM value for a plot may
not be the same data type as the trait measured on an individual tree
<code>sbyt</code>. Here is a table of 15 columns in <code>u</code>:</p>
<table>
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="27%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">trait</th>
<th align="center"><code>typeName</code></th>
<th align="center">partition</th>
<th align="left">comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>gmPerSeed</code></td>
<td align="center"><code>CON</code></td>
<td align="center"><span class="math inline">\((-\infty,
\infty)\)</span></td>
<td align="left">centered, standardized</td>
</tr>
<tr class="even">
<td align="center"><code>maxHt</code></td>
<td align="center"><code>CON</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="odd">
<td align="center"><code>leafN</code></td>
<td align="center"><code>CON</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="even">
<td align="center"><code>leafP</code></td>
<td align="center"><code>CON</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="odd">
<td align="center"><code>SLA</code></td>
<td align="center"><code>CON</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="even">
<td align="center"><code>woodSG</code></td>
<td align="center"><code>CON</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="odd">
<td align="center"><code>shade</code></td>
<td align="center"><code>OC</code></td>
<td align="center"><span class="math inline">\((-\infty, 0, p_{s1},
p_{s2}, p_{s3}, p_{s4}, \infty)\)</span></td>
<td align="left">five tolerance bins</td>
</tr>
<tr class="even">
<td align="center"><code>drought</code></td>
<td align="center"><code>OC</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="odd">
<td align="center"><code>flood</code></td>
<td align="center"><code>OC</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="even">
<td align="center"><code>leaf_broaddeciduous</code></td>
<td align="center"><code>FC</code></td>
<td align="center"><span class="math inline">\((-\infty, 0, 1,
\infty)\)</span></td>
<td align="left">categorical traits become FC data as CWMs</td>
</tr>
<tr class="odd">
<td align="center"><code>leaf_broadevergreen</code></td>
<td align="center"><code>FC</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="even">
<td align="center"><code>leaf_needleevergreen</code></td>
<td align="center"><code>FC</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="odd">
<td align="center"><code>leaf_other</code></td>
<td align="center"><code>FC</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
<tr class="even">
<td align="center"><code>repro_monoecious</code></td>
<td align="center"><code>CA</code></td>
<td align="center"><span class="math inline">\((-\infty, 0, 1,
\infty)\)</span></td>
<td align="left">two categories become continuous (censored)</td>
</tr>
<tr class="odd">
<td align="center"><code>xylem_ring</code></td>
<td align="center"><code>CA</code></td>
<td align="center">”</td>
<td align="left">”</td>
</tr>
</tbody>
</table>
<p>The first six <code>CON</code> variables are continuous, centered,
and standardized, as is often done in trait studies. In gjam
<code>CON</code> is the only data type that is not assumed to be
censored at zero.</p>
<p>The three <code>OC</code> variables are ordinal classes, lacking an
absolute scale–the partition must be estimated.</p>
<p>The four fractional composition <code>FC</code> columns are the
levels of the single <code>CAT</code> variable <code>leaf</code>,
expanded by the function <code>gjamSpec2Trait</code>.</p>
<p>The last two traits in <code>u</code> are fractions with two classes,
only one of which is included here. They are censored at both 0 and 1,
the intervals <span class="math inline">\((-\infty, 0)\)</span> and
<span class="math inline">\((1, \infty)\)</span>. This censoring can be
generated using <code>gjamCensorY</code>:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" tabindex="-1"></a>censorList    <span class="ot">&lt;-</span> <span class="fu">gjamCensorY</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">intervals =</span> <span class="fu">cbind</span>( <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>,<span class="dv">0</span>),<span class="fu">c</span>(<span class="dv">1</span>,<span class="cn">Inf</span>) ), </span>
<span id="cb69-2"><a href="#cb69-2" tabindex="-1"></a>                             <span class="at">y =</span> u, <span class="at">whichcol =</span> <span class="fu">c</span>(<span class="dv">13</span><span class="sc">:</span><span class="dv">14</span>))<span class="sc">$</span>censor</span></code></pre></div>
<p>This censoring was already done with <code>gjamSpec2Trait</code>,
which knows to treat <code>&#39;CAT&#39;</code> data with only two levels as
censored <code>&#39;CA&#39;</code> data. In this case the
<code>values = c(0,1)</code> indicates that zeros and ones in the data
indicate censoring. The <code>intervals</code> matrix gives their
ranges.</p>
</div>
<div id="factors-in-this-example" class="section level3">
<h3><span style="color:brown">factors in this example</span></h3>
<p>Multilevel factors in <code>xdata</code> require some interpretation.
If you have not worked with multilevel factors, refer to the R
<code>help</code> page for <code>factor</code>. The interpretation of
coefficients for multilevel factors depends on the reference level used
to construct a <em>contrasts</em> matrix. Standard models in R assign
contrasts that may not assume the reference level that is desired.
Moreover, if the reference is unspecified, it depends on on the order of
observations and variables in the data.</p>
<p>In <code>xdata</code> the variable <code>soil</code> is a multilevel
factor, which includes soil types that are both common and have
potentially strong effects. Here are the first few rows of
<code>xdata</code>:</p>
<p>I used the name <code>reference</code> for a soil type to aggregate
types that are rare. Factor levels that rarely occur cannot be estimated
in the model.</p>
<p>The R function <code>relevel</code> allows definition of a reference
level. In this case I want to compare levels to the reference soil type
<code>reference</code>:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" tabindex="-1"></a>xdata<span class="sc">$</span>soil <span class="ot">&lt;-</span> <span class="fu">relevel</span>(xdata<span class="sc">$</span>soil,<span class="st">&#39;reference&#39;</span>)</span></code></pre></div>
<p>To avoid confusion, contrasts can be inspected as
<code>output$modelSummary$contrasts</code>. If the reference class is
all zeros and other classes are zeros and ones, then the intercept is
the reference class.</p>
</div>
<div id="trm-analysis" class="section level3">
<h3><span style="color:brown">TRM analysis</span></h3>
<p>Here is an analysis of the data, with 20 holdout plots. Predictors in
<code>xdata</code> are winter temperature (<code>temp</code>), local
<code>moisture</code>, climatic moisture <code>deficit</code> and
<code>soil</code>. As discussed above, the variable <code>soil</code> is
a multi-level factor.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng =</span> <span class="dv">3000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> tTypes, <span class="at">holdoutN =</span> <span class="dv">20</span>,</span>
<span id="cb71-2"><a href="#cb71-2" tabindex="-1"></a>            <span class="at">censor=</span>censor, <span class="at">notStandard =</span> <span class="fu">c</span>(<span class="st">&#39;u1&#39;</span>,<span class="st">&#39;u2&#39;</span>,<span class="st">&#39;u3&#39;</span>))</span>
<span id="cb71-3"><a href="#cb71-3" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>(<span class="sc">~</span> temp <span class="sc">+</span> stdage <span class="sc">+</span> moisture<span class="sc">*</span>deficit <span class="sc">+</span> deficit<span class="sc">*</span>soil, </span>
<span id="cb71-4"><a href="#cb71-4" tabindex="-1"></a>                 <span class="at">xdata =</span> xdata, <span class="at">ydata =</span> u, <span class="at">modelList =</span> ml)</span>
<span id="cb71-5"><a href="#cb71-5" tabindex="-1"></a>tnames <span class="ot">&lt;-</span> <span class="fu">colnames</span>(u)</span>
<span id="cb71-6"><a href="#cb71-6" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;black&#39;</span>, M)                                  <span class="co"># highlight types</span></span>
<span id="cb71-7"><a href="#cb71-7" tabindex="-1"></a>wo <span class="ot">&lt;-</span> <span class="fu">which</span>(tnames <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;leafN&quot;</span>,<span class="st">&quot;leafP&quot;</span>,<span class="st">&quot;SLA&quot;</span>) )     <span class="co"># foliar traits</span></span>
<span id="cb71-8"><a href="#cb71-8" tabindex="-1"></a>wf <span class="ot">&lt;-</span> <span class="fu">grep</span>(<span class="st">&quot;leaf&quot;</span>,tnames)                              <span class="co"># leaf habit</span></span>
<span id="cb71-9"><a href="#cb71-9" tabindex="-1"></a>wc <span class="ot">&lt;-</span> <span class="fu">which</span>(tnames <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;woodSG&quot;</span>,<span class="st">&quot;diffuse&quot;</span>,<span class="st">&quot;ring&quot;</span>) ) <span class="co"># wood anatomy</span></span>
<span id="cb71-10"><a href="#cb71-10" tabindex="-1"></a></span>
<span id="cb71-11"><a href="#cb71-11" tabindex="-1"></a>sc[wc] <span class="ot">&lt;-</span> <span class="st">&#39;brown&#39;</span></span>
<span id="cb71-12"><a href="#cb71-12" tabindex="-1"></a>sc[wf] <span class="ot">&lt;-</span> <span class="st">&#39;darkblue&#39;</span></span>
<span id="cb71-13"><a href="#cb71-13" tabindex="-1"></a>sc[wo] <span class="ot">&lt;-</span> <span class="st">&#39;darkgreen&#39;</span></span>
<span id="cb71-14"><a href="#cb71-14" tabindex="-1"></a></span>
<span id="cb71-15"><a href="#cb71-15" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">GRIDPLOTS =</span> <span class="cn">TRUE</span>, <span class="at">PLOTALLY =</span> T, <span class="at">specColor =</span> sc)</span>
<span id="cb71-16"><a href="#cb71-16" tabindex="-1"></a><span class="fu">gjamPlot</span>(<span class="at">output =</span> out, <span class="at">plotPars =</span> pl)</span>
<span id="cb71-17"><a href="#cb71-17" tabindex="-1"></a><span class="fu">summary</span>(out)</span></code></pre></div>
<p>The model fit is interpreted in the same way as other gjam analyses.
Note that <code>specColor</code> is used to highlight different types of
traits in the posterior plots for values in coefficient matrix <span class="math inline">\(\mathbf{A}\)</span>. Parameter estimates are
contained in <code>parameters</code>,</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaMu         <span class="co"># Q by M coefficient matrix alpha</span></span>
<span id="cb72-2"><a href="#cb72-2" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXmu   <span class="co"># Q by M standardized for X</span></span>
<span id="cb72-3"><a href="#cb72-3" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaStandXWmu  <span class="co"># (Q-F) by M standardized for W/X, centered factors</span></span>
<span id="cb72-4"><a href="#cb72-4" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTable      <span class="co"># QM by stats posterior summary</span></span>
<span id="cb72-5"><a href="#cb72-5" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sigMu          <span class="co"># M by M covariance matrix omega</span></span>
<span id="cb72-6"><a href="#cb72-6" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>sigSe          <span class="co"># M by M covariance std errors</span></span></code></pre></div>
<p>The <code>output</code> list contains a large number of diagnostics
explained in help pages.<br />
The matrices <code>out$parameters$cutMu</code> and
<code>out$parameters$cutSe</code> hold the estimates for the partion for
ordinal (<code>&#39;OC&#39;</code>) variables shade, drought, and flood
tolerance. Each has three fitted cutpoints, because the first is fixed,
with three estimates to partition the remaining four intervals.</p>
</div>
<div id="interactions-and-indirect-effects-1" class="section level3">
<h3><span style="color:brown">interactions and indirect
effects</span></h3>
<p>Consider the interactions and indirect effects for this model. If
there are no interactions in the <code>formula</code> passed to
<code>gjam</code>, then there will be no interactions to estimate with
the function <code>gjamIIE</code> (there will still be indirect effects,
discussed below). If there are interactions in the <code>formula</code>,
I must specify the values for main effects that are involved in these
interactions to be used for estimating their effects on predictions. For
example, consider a model containing the interaction between predictors
<span class="math inline">\(q\)</span> and <span class="math inline">\(q&#39;\)</span>,</p>
<p><span class="math display">\[E[y_{s}] = \cdots + \beta_{q,s}x_{q} +
\beta_{q&#39;,s}x_{q&#39;} + \beta_{qq&#39;,s}x_{q}x_{q&#39;} +
\cdots\]</span></p>
<p>The ‘effect’ of predictor <span class="math inline">\(x_{q}\)</span>
on <span class="math inline">\(y_{s}\)</span> is the derivative</p>
<p><span class="math display">\[\frac{dy_{s}}{dx_{q}} = \beta_{q,s} +
\beta_{qq&#39;,s}x_{q&#39;}\]</span></p>
<p>which depends not on <span class="math inline">\(x_{q}\)</span>, but
rather on <span class="math inline">\(x_{q&#39;}\)</span>. So if I want
to know how interactions affect the response I have to decide on values
for all of the predictors that are involved in interactions. These
values are passed to <code>gjamIIE</code> in <code>xvector</code>. The
default has <code>sdScaleX = F</code>, which means that effects can be
compared on the basis of variation in <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>In this example interactions involve <code>moisture</code>,
<code>deficit</code>, and the multi-level factor <code>soil</code>, as
specified in the <code>formula</code> passed to <code>gjam</code>. The
first row of the design matrix is used with <code>moisture</code> and
<code>deficit</code> set to -1 or +1 standard deviation to compare dry
and wet sites in a dry climate:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" tabindex="-1"></a>xdrydry <span class="ot">&lt;-</span> xwetdry  <span class="ot">&lt;-</span> out<span class="sc">$</span>inputs<span class="sc">$</span>xUnstand[<span class="dv">1</span>,]</span>
<span id="cb73-2"><a href="#cb73-2" tabindex="-1"></a>xdrydry[<span class="st">&#39;moisture&#39;</span>] <span class="ot">&lt;-</span> xdrydry[<span class="st">&#39;deficit&#39;</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span></span>
<span id="cb73-3"><a href="#cb73-3" tabindex="-1"></a>xwetdry[<span class="st">&#39;moisture&#39;</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb73-4"><a href="#cb73-4" tabindex="-1"></a>xwetdry[<span class="st">&#39;deficit&#39;</span>]  <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span></span></code></pre></div>
<p>The first observation is from the reference soil level
<code>reference</code>, so all other soil classes are zero. Here is a
plot of main effects and interactions for deciduous and evergreen
traits:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">bty=</span><span class="st">&#39;n&#39;</span>, <span class="at">mar=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), </span>
<span id="cb74-2"><a href="#cb74-2" tabindex="-1"></a>    <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">tcl =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">mgp =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">0</span>), <span class="at">family=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb74-3"><a href="#cb74-3" tabindex="-1"></a></span>
<span id="cb74-4"><a href="#cb74-4" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">gjamIIE</span>(<span class="at">output =</span> out, <span class="at">xvector =</span> xdrydry)</span>
<span id="cb74-5"><a href="#cb74-5" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">gjamIIE</span>(<span class="at">output =</span> out, <span class="at">xvector =</span> xwetdry)</span>
<span id="cb74-6"><a href="#cb74-6" tabindex="-1"></a></span>
<span id="cb74-7"><a href="#cb74-7" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit1, <span class="at">response =</span> <span class="st">&#39;leafbroaddeciduous&#39;</span>, </span>
<span id="cb74-8"><a href="#cb74-8" tabindex="-1"></a>            <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), </span>
<span id="cb74-9"><a href="#cb74-9" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;bottomleft&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">31</span>,.<span class="dv">3</span>))</span>
<span id="cb74-10"><a href="#cb74-10" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;deciduous&#39;</span>)</span>
<span id="cb74-11"><a href="#cb74-11" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit1, <span class="at">response =</span> <span class="st">&#39;leafneedleevergreen&#39;</span>, </span>
<span id="cb74-12"><a href="#cb74-12" tabindex="-1"></a>            <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), </span>
<span id="cb74-13"><a href="#cb74-13" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;bottomleft&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">3</span>,.<span class="dv">3</span>))</span>
<span id="cb74-14"><a href="#cb74-14" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;evergreen&#39;</span>)</span>
<span id="cb74-15"><a href="#cb74-15" tabindex="-1"></a></span>
<span id="cb74-16"><a href="#cb74-16" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit2, <span class="at">response =</span> <span class="st">&#39;leafbroaddeciduous&#39;</span>, </span>
<span id="cb74-17"><a href="#cb74-17" tabindex="-1"></a>            <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), </span>
<span id="cb74-18"><a href="#cb74-18" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;bottomleft&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">3</span>,.<span class="dv">3</span>))</span>
<span id="cb74-19"><a href="#cb74-19" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit2, <span class="at">response =</span> <span class="st">&#39;leafneedleevergreen&#39;</span>, </span>
<span id="cb74-20"><a href="#cb74-20" tabindex="-1"></a>            <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;int&#39;</span>), </span>
<span id="cb74-21"><a href="#cb74-21" tabindex="-1"></a>            <span class="at">legLoc =</span> <span class="st">&#39;bottomleft&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">3</span>,.<span class="dv">3</span>))</span></code></pre></div>
<p>The main effects plotted in the graphs do not depend on the values in
<code>xvector</code>. Although this observation is taken from the
<code>reference</code> soil, the plot shows the main effects that would
be obtained if it were on the different soils included in the model. The
interactions show how the effect of each predictor is modified by
interactions with other variables. Again, the interactions from each
predictor do not depend on values for the predictor itself, but rather
on the other variables with which it interacts. For example, the
interaction effect of <code>soilUltKan</code> on the
<code>broaddeciduous</code> trait is positive on dry sites in dry
climates (top left). Combined with a negative main effect, this means
that deciduous trees tend to be more abundance on moist sites in this
soil type. Its main effect on <code>leafneedleevergreen</code> is
positive, but less so on moist sites in dry climates (bottom right).</p>
<p>The indirect effects come from the effects of responses. This example
shows indirect effects for foliar N and P that come through
<code>broaddeciduous</code> leaf habit:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" tabindex="-1"></a>xvector <span class="ot">&lt;-</span> out<span class="sc">$</span>inputs<span class="sc">$</span>xUnstand[<span class="dv">1</span>,]</span>
<span id="cb75-2"><a href="#cb75-2" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">bty=</span><span class="st">&#39;n&#39;</span>, <span class="at">mar=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>), </span>
<span id="cb75-3"><a href="#cb75-3" tabindex="-1"></a>    <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">1</span>), <span class="at">tcl =</span> <span class="sc">-</span><span class="fl">0.5</span>, <span class="at">mgp =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">0</span>), <span class="at">family=</span><span class="st">&#39;&#39;</span>)</span>
<span id="cb75-4"><a href="#cb75-4" tabindex="-1"></a></span>
<span id="cb75-5"><a href="#cb75-5" tabindex="-1"></a>omitY <span class="ot">&lt;-</span> <span class="fu">colnames</span>(u)[<span class="fu">colnames</span>(u) <span class="sc">!=</span> <span class="st">&#39;leafbroaddeciduous&#39;</span>] <span class="co"># omit all but deciduous</span></span>
<span id="cb75-6"><a href="#cb75-6" tabindex="-1"></a></span>
<span id="cb75-7"><a href="#cb75-7" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">gjamIIE</span>(out, xvector)</span>
<span id="cb75-8"><a href="#cb75-8" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit, <span class="at">response =</span> <span class="st">&#39;leafP&#39;</span>, <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;ind&#39;</span>), </span>
<span id="cb75-9"><a href="#cb75-9" tabindex="-1"></a>            <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;ind&#39;</span>), <span class="at">legLoc =</span> <span class="st">&#39;topright&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">6</span>,.<span class="dv">6</span>))</span>
<span id="cb75-10"><a href="#cb75-10" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;foliar P&#39;</span>)</span>
<span id="cb75-11"><a href="#cb75-11" tabindex="-1"></a><span class="fu">gjamIIEplot</span>(fit, <span class="at">response =</span> <span class="st">&#39;leafN&#39;</span>, <span class="at">effectMu =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;ind&#39;</span>), </span>
<span id="cb75-12"><a href="#cb75-12" tabindex="-1"></a>            <span class="at">effectSd =</span> <span class="fu">c</span>(<span class="st">&#39;main&#39;</span>,<span class="st">&#39;ind&#39;</span>), <span class="at">legLoc =</span> <span class="st">&#39;bottomright&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span>.<span class="dv">6</span>,.<span class="dv">6</span>))</span>
<span id="cb75-13"><a href="#cb75-13" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&#39;foliar N&#39;</span>)</span></code></pre></div>
<p>There will always be indirect effects, because they come through the
covariance matrix.</p>
</div>
</div>
<div id="predictive-trait-model-ptm" class="section level2">
<h2><span style="color:teal">predictive trait model (PTM)</span></h2>
<p>The PTM models species abundance data, then predicts traits. This
approach has a number of advantages over TRM discussed in <a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.1453">Clark
2016</a>. The response is the <span class="math inline">\(n \times
S\)</span> matrix <span class="math inline">\(\mathbf{Y}\)</span>, which
could be counts, biomass, and so forth.</p>
<div id="start-with-species-abundance" class="section level3">
<h3><span style="color:brown">start with species abundance</span></h3>
<p>PTM is based on species abundance, but includes trait data for CWMM
prediction. On the latent scale the observation is represented by a
composition (<code>&#39;FC&#39;</code> or <code>&#39;CC&#39;</code>) vector,</p>
<p><span class="math display">\[\mathbf{w}_{i} \sim
MVN(\mathbf{B&#39;}\mathbf{x}_{i},\Sigma)\]</span></p>
<p>where <span class="math inline">\(\mathbf{B}\)</span> is the <span class="math inline">\(Q \times S\)</span> matrix of coefficients, and
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> is the <span class="math inline">\(S \times S\)</span> residual covariance. A
predictive distribution on the trait scale is obtained as a <em>variable
change</em>,</p>
<p><span class="math display">\[\mathbf{A} =
\mathbf{B}\mathbf{T}\]</span> <span class="math display">\[\boldsymbol{\Omega} =
\mathbf{T&#39;}\boldsymbol{\Sigma}\mathbf{T}\]</span> <span class="math display">\[\mathbf{u}_{i} =
\mathbf{T&#39;}\mathbf{w}_{i}\]</span></p>
<p>where <span class="math inline">\(\mathbf{T}\)</span> is a <span class="math inline">\(S \times M\)</span> matrix of trait values for
each species, <span class="math inline">\(\mathbf{A}\)</span> is the
<span class="math inline">\(Q \times M\)</span> matrix of coefficients,
and <span class="math inline">\(\boldsymbol{\Omega}\)</span> is the
<span class="math inline">\(M \times M\)</span> residual covariance
(diagram below).</p>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p><strong>The predictive trait model</strong> fits species data and
predicts traits using the species-by-trait matrix <strong>T</strong>,
contained in the object <code>specbyTrait</code>.</p>
<p><br></p>
<p>The PTM begins by fitting <code>pbys</code>, followed by predicting
<code>plotByTraits</code>. This requires a <code>traitList</code>, which
defines the objects needed for prediction. The species are weights, so
they should be modeled as composition data, eight <code>&#39;FC&#39;</code>
(rows sum to 1) or <code>&#39;CC&#39;</code>. Here the model is fitted with
dimension reduction:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" tabindex="-1"></a>tl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">plotByTrait =</span> u, <span class="at">traitTypes =</span> tTypes, <span class="at">specByTrait =</span> specByTrait)</span>
<span id="cb76-2"><a href="#cb76-2" tabindex="-1"></a>rl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">r =</span> <span class="dv">8</span>, <span class="at">N =</span> <span class="dv">25</span>)</span>
<span id="cb76-3"><a href="#cb76-3" tabindex="-1"></a>ml  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">ng =</span> <span class="dv">2000</span>, <span class="at">burnin =</span> <span class="dv">500</span>, <span class="at">typeNames =</span> <span class="st">&#39;CC&#39;</span>, <span class="at">holdoutN =</span> <span class="dv">20</span>,</span>
<span id="cb76-4"><a href="#cb76-4" tabindex="-1"></a>                  <span class="at">traitList =</span> tl, <span class="at">reductList =</span> rl)</span>
<span id="cb76-5"><a href="#cb76-5" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">gjam</span>(<span class="sc">~</span> temp <span class="sc">+</span> stdage <span class="sc">+</span> deficit<span class="sc">*</span>soil, <span class="at">xdata =</span> xdata, </span>
<span id="cb76-6"><a href="#cb76-6" tabindex="-1"></a>                     <span class="at">ydata =</span> pbys, <span class="at">modelList =</span> ml)</span>
<span id="cb76-7"><a href="#cb76-7" tabindex="-1"></a></span>
<span id="cb76-8"><a href="#cb76-8" tabindex="-1"></a>S  <span class="ot">&lt;-</span> <span class="fu">nrow</span>(specByTrait)</span>
<span id="cb76-9"><a href="#cb76-9" tabindex="-1"></a>sc <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;black&#39;</span>, S)</span>
<span id="cb76-10"><a href="#cb76-10" tabindex="-1"></a>wr <span class="ot">&lt;-</span> <span class="fu">which</span>(specByTrait[,<span class="st">&#39;ring&#39;</span>] <span class="sc">==</span> <span class="dv">1</span>)                  <span class="co"># ring porous</span></span>
<span id="cb76-11"><a href="#cb76-11" tabindex="-1"></a>wb <span class="ot">&lt;-</span> <span class="fu">which</span>(specByTrait[,<span class="st">&#39;leafneedleevergreen&#39;</span>] <span class="sc">==</span> <span class="dv">1</span>)   <span class="co"># needle-leaf evergreen</span></span>
<span id="cb76-12"><a href="#cb76-12" tabindex="-1"></a>wd <span class="ot">&lt;-</span> <span class="fu">which</span>(specByTrait[,<span class="st">&#39;leafneedledeciduous&#39;</span>] <span class="sc">==</span> <span class="dv">1</span>)   <span class="co"># needle-leaf deciduous</span></span>
<span id="cb76-13"><a href="#cb76-13" tabindex="-1"></a>ws <span class="ot">&lt;-</span> <span class="fu">which</span>(specByTrait[,<span class="st">&#39;shade&#39;</span>] <span class="sc">&gt;=</span> <span class="dv">4</span>)                 <span class="co"># shade tolerant</span></span>
<span id="cb76-14"><a href="#cb76-14" tabindex="-1"></a>sc[wr] <span class="ot">&lt;-</span> <span class="st">&#39;#8c510a&#39;</span></span>
<span id="cb76-15"><a href="#cb76-15" tabindex="-1"></a>sc[ws] <span class="ot">&lt;-</span> <span class="st">&#39;#3288bd&#39;</span></span>
<span id="cb76-16"><a href="#cb76-16" tabindex="-1"></a>sc[wb] <span class="ot">&lt;-</span> <span class="st">&#39;#003c30&#39;</span></span>
<span id="cb76-17"><a href="#cb76-17" tabindex="-1"></a>sc[wd] <span class="ot">&lt;-</span> <span class="st">&#39;#80cdc1&#39;</span></span>
<span id="cb76-18"><a href="#cb76-18" tabindex="-1"></a></span>
<span id="cb76-19"><a href="#cb76-19" tabindex="-1"></a>M  <span class="ot">&lt;-</span> <span class="fu">ncol</span>(specByTrait)</span>
<span id="cb76-20"><a href="#cb76-20" tabindex="-1"></a>tc <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="st">&#39;black&#39;</span>, M)</span>
<span id="cb76-21"><a href="#cb76-21" tabindex="-1"></a><span class="fu">names</span>(tc) <span class="ot">&lt;-</span> <span class="fu">colnames</span>(specByTrait)</span>
<span id="cb76-22"><a href="#cb76-22" tabindex="-1"></a>tc[ <span class="st">&#39;ring&#39;</span> ] <span class="ot">&lt;-</span> <span class="st">&#39;#8c510a&#39;</span></span>
<span id="cb76-23"><a href="#cb76-23" tabindex="-1"></a>tc[ <span class="st">&#39;leafneedleevergreen&#39;</span> ] <span class="ot">&lt;-</span> <span class="st">&#39;#3288bd&#39;</span></span>
<span id="cb76-24"><a href="#cb76-24" tabindex="-1"></a>tc[ <span class="st">&#39;leafneedledeciduous&#39;</span> ] <span class="ot">&lt;-</span> <span class="st">&#39;#003c30&#39;</span></span>
<span id="cb76-25"><a href="#cb76-25" tabindex="-1"></a>tc[ <span class="st">&#39;shade&#39;</span> ] <span class="ot">&lt;-</span> <span class="st">&#39;#80cdc1&#39;</span></span>
<span id="cb76-26"><a href="#cb76-26" tabindex="-1"></a></span>
<span id="cb76-27"><a href="#cb76-27" tabindex="-1"></a><span class="fu">par</span>(<span class="at">family =</span> <span class="st">&#39;&#39;</span>)</span>
<span id="cb76-28"><a href="#cb76-28" tabindex="-1"></a>pl  <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">GRIDPLOTS=</span>T,</span>
<span id="cb76-29"><a href="#cb76-29" tabindex="-1"></a>                  <span class="at">specColor =</span> sc, <span class="at">traitColor =</span> tc, <span class="at">ncluster =</span> <span class="dv">5</span>) </span>
<span id="cb76-30"><a href="#cb76-30" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">gjamPlot</span>(<span class="at">output =</span> out, pl)</span></code></pre></div>
<p>Output is interpreted as previously, now with coefficients <span class="math inline">\(\mathbf{B}\)</span> and covariance <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. gjamPlot generates
an additional plot with trait predictions. Parameter values are
here:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTraitXMu     <span class="co"># Q by M coefficient matrix alpha, standardized for X</span></span>
<span id="cb77-2"><a href="#cb77-2" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTraitXWmu    <span class="co"># Q by M standardized for X/W</span></span>
<span id="cb77-3"><a href="#cb77-3" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTraitXTable  <span class="co"># QM by stats posterior summary</span></span>
<span id="cb77-4"><a href="#cb77-4" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>betaTraitXWTable <span class="co"># QM by stats summary for X/W</span></span>
<span id="cb77-5"><a href="#cb77-5" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>varTraitMu       <span class="co"># M by M trait residual covariance, standardized for X</span></span>
<span id="cb77-6"><a href="#cb77-6" tabindex="-1"></a>out<span class="sc">$</span>parameters<span class="sc">$</span>varTraitTable    <span class="co"># M^2 by stats summary, standardized for X/W</span></span></code></pre></div>
<p>Trait predictive distributions are summarized here:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" tabindex="-1"></a>out<span class="sc">$</span>prediction<span class="sc">$</span>tMu[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]     <span class="co"># n by M predictive means</span></span>
<span id="cb78-2"><a href="#cb78-2" tabindex="-1"></a>out<span class="sc">$</span>prediction<span class="sc">$</span>tSe[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]     <span class="co"># n by M predictive std errors</span></span></code></pre></div>
<p>Additional quantities can be predicted from the output using the MCMC
output in the list <code>out$chains</code>.</p>
<p>It is worth checking for combinations of responses and factor levels
that might be missing from the data. That is an issue here, because each
species has a limited geographic distribution, as do the soil types. The
object <code>out$inputs$factorBeta$missFacSpec</code> lists the missing
predictor-response combinations. This list could be the basis for
consolidating factor levels.</p>
</div>
<div id="trouble-shooting-in-ptm" class="section level3">
<h3><span style="color:brown">trouble shooting in PTM</span></h3>
<p>When using <code>gjam</code> in predictive trait mode remember the
following:</p>
<ol style="list-style-type: decimal">
<li><p><code>typeNames</code> for <code>ydata</code> data should be
composition, either <code>CC</code> or <code>FC</code></p></li>
<li><p><code>nrow(plotByTrait)</code> must equal
<code>nrow(ydata)</code></p></li>
<li><p><code>ncol(plotByTrait)</code> must equal
<code>length(traitTypes)</code></p></li>
<li><p><code>ncol(plotByTrait)</code> must equal
<code>length(traitTypes)</code></p></li>
<li><p><code>rownames(specByTrait)</code> must match
<code>colnames(ydata)</code></p></li>
</ol>
<p><br></p>
</div>
</div>
</div>
<div id="selecting-variables" class="section level1">
<h1><span style="color:darkgreen">selecting variables</span></h1>
<p>In a univariate model, there is one response and perhaps a number of
potential predictor variables from which to choose. Variable selection
focuses on <span class="math inline">\(\mathbf{X}\)</span>. In a
multivariate model, the overall fit and predictive capacity depends not
only on what’s in <span class="math inline">\(\mathbf{X}\)</span>, but
also on what’s in <span class="math inline">\(\mathbf{Y}\)</span>. A
different combination of variables in <span class="math inline">\(\mathbf{X}\)</span> will provide the best “fit”
for each combination of variables in <span class="math inline">\(\mathbf{Y}\)</span>. Given that many species may
be rare, and rare types will not be explained by the model, there will
be decisions about what variables to include on both sides of the
likelihood.</p>
<p>These considerations mean that simple rules like ‘lowest DIC’ are not
sensible. Do I want the model that best explains the subset of response
variables having the most ‘signal’? Not necessarily, because many less
abundant types may be of interest. Alternatively, the best model for
responses ranging from rare to abundant will depend on precisely which
of the rare types are included. As discussed in the section on
<strong>dimension reduction</strong>, rare types also affect the
coefficients for abundant types through covariance <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. I often want to
consider a range of variable combinations. Here are a few objects
available in <code>gjam</code> output that can provide some guidance for
selecting variables.</p>
<table>
<colgroup>
<col width="47%" />
<col width="52%" />
</colgroup>
<thead>
<tr class="header">
<th align="right"><code>output</code> or <code>.pdf</code> plot
file</th>
<th align="left">explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>output$fit$DIC</code></td>
<td align="left">Low is good</td>
</tr>
<tr class="even">
<td align="right"><code>output$inputs$designTable</code></td>
<td align="left">Redundant predictors based on high correlation and/or
high VIF (&gt; 10 to 20)?</td>
</tr>
<tr class="odd">
<td align="right"><code>output$inputs$factorBeta$missFacSpec</code></td>
<td align="left">Missing predictor-response combinations listed
here–consider consolidating factor levels or removing predictors and/or
responses.</td>
</tr>
<tr class="even">
<td align="right"><code>output$parameters$sensTable</code>,
<code>sensitivity.pdf</code></td>
<td align="left">High values account for most variation across all
responses.</td>
</tr>
<tr class="odd">
<td align="right"><code>betaAll.pdf</code></td>
<td align="left">Do CIs include zero for all responses?</td>
</tr>
<tr class="even">
<td align="right"><code>betaChains.pdf</code>,
<code>output$chains$bgibbs</code></td>
<td align="left">Any not converged?</td>
</tr>
<tr class="odd">
<td align="right"><code>yPredAll.pdf</code></td>
<td align="left">Generated if <code>PLOTALLY = T</code> in
<code>plotPars</code>; remove some responses that are not well
predicted?</td>
</tr>
<tr class="even">
<td align="right"><code>yPred.pdf</code></td>
<td align="left">Model predicts responses in-sample?</td>
</tr>
<tr class="odd">
<td align="right"><code>xPred.pdf</code>,
<code>xPredFactors.pdf</code></td>
<td align="left">Model inversely predicts inputs?</td>
</tr>
</tbody>
</table>
<p>To cull rare types in <span class="math inline">\(\mathbf{Y}\)</span>
see the help page for <code>gjamTrimY</code>. To evaluate the model with
out-of-sample prediction see the section <strong>missing data,
out-of-sample prediction</strong>.</p>
<p><br></p>
</div>
<div id="trouble-shooting" class="section level1">
<h1><span style="color:darkgreen">trouble shooting</span></h1>
<p>A joint model for data sets with many response variables can be
unstable for several reasons. Because the model can accommodate large,
multivariate data sets, there is temptation to throw everything in and
see what happens. gjam is vulnerable due to the fact that columns in
<code>ydata</code> have different scales and, thus, can range over
orders of magnitude. It’s best to start small, gain a feel for the data
and how it translates to estimates of many coefficients and covariances.
More species and predictors can be added without changing the model. The
opposite approach of throwing in everything is asking for trouble and is
unlikely to generate insight.</p>
<p>If a model won’t execute, start by simplifying it. Use a small number
of predictors and response variables. It’s easy to add complexity later.
If execution fails there are several options.</p>
<p><strong>Check <span class="math inline">\(\mathbf{X}\)</span> and
<span class="math inline">\(\mathbf{Y}\)</span></strong>. Most errors
come from the data. If there are many species (large <span class="math inline">\(\mathbf{Y}\)</span>), some may occur once or not
at all. This is easy to check with the function <code>gjamTrimY</code>.
If I suspect trouble with the design matrix <span class="math inline">\(\mathbf{X}\)</span>, I can make sure it is full
rank, e.g.,</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="fu">gjamSimData</span>(<span class="at">S =</span> <span class="dv">5</span>, <span class="at">typeNames =</span> <span class="st">&#39;CA&#39;</span>)</span>
<span id="cb79-2"><a href="#cb79-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(f<span class="sc">$</span>formula, f<span class="sc">$</span>xdata)</span>
<span id="cb79-3"><a href="#cb79-3" tabindex="-1"></a><span class="fu">qr</span>(x)<span class="sc">$</span>rank</span></code></pre></div>
<p>The rank must equal the number of columns in <code>x</code>.</p>
<p><strong>If I am simulating data</strong>, first try it again. The
simulator aims to generate data that will actually work, more
challenging than would be the case for a univariate simulation of a
single data type. Simulated data are random, so try again.</p>
<p><strong>If the fit is bad</strong>, it could be noisy data (there is
no ‘signal’), but there are other things to check. Again, insure that
all columns in <code>ydata</code> include at least some non-zero values.
One would not expect a univariate model to fit a data set where the
response is all zeros. However, when there are many columns in
<code>ydata</code>, the fact that some are never or rarely observed can
be overlooked. The functions <code>hist</code>, <code>colSums</code>,
and, for discrete data, <code>table</code>, can be used. The function
<code>gjamTrimY(ydata, m)</code> can be used to limit <code>ydata</code>
to only those columns with at least <code>m</code> non-zero
observations.</p>
<p><strong>Large differences in scale</strong> in <code>ydata</code> can
contribute to instability. Unlike <code>xdata</code>, where the design
matrix is standardized, <code>ydata</code> is not rescaled. It is used
as-is, because the user may want effort on a specific scale. However,
the algorithm is most stable when responses in <code>ydata</code> do not
span widely different ranges. For continuous data (<code>&quot;CA&quot;</code>,
<code>&quot;CON&quot;</code>), consider changing the units in <code>ydata</code>
from, say, g to kg or from g ml<span class="math inline">\(^{-1}\)</span> to g l<span class="math inline">\(^{-1}\)</span>.</p>
<p>For discrete counts (<code>&quot;DA&quot;</code>) consider changing the units
for effort, e.g., m<span class="math inline">\(^{2}\)</span> versus ha
or hours versus days. Recall, the dimension for the latent <span class="math inline">\(W\)</span> is <span class="math inline">\(Y/E\)</span>. If I count hundreds or thousands of
animals per hour, I could consider specifying effort in minutes, thus
reducing the scale for <span class="math inline">\(W\)</span> by a
factor of <span class="math inline">\(1/60\)</span>. Rescaling is not
relevant for <code>&quot;CC&quot;</code>, where modeling is done on the <span class="math inline">\([0, 1]\)</span> scale.</p>
<p>Unlike experiments, where attention is paid to balanced design,
observational data often involve <strong>factors</strong>, for which
only some species occur in all factor combinations. This inadequate
distribution of data is compounded when those factors are included in
interaction terms. Consider ways to eliminate factor levels/combinations
that cannot be estimated from the data.</p>
<p>If a simulation fails due to a cholesky error, then there is a
problem inverting <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. Any of these error
messages might arise, even when using dimension reduction:</p>
<p><code>error: chol(): decomposition failed</code></p>
<p><code>error: inv_sympd(): matrix is singular or not positive definite</code></p>
<p><code>Error in invWbyRcpp(sigmaerror, otherpar$Z[otherpar$K, ]) : inv_sympd(): matrix is singular or not positive definite</code></p>
<p>Consider either reducing the number of columns in <code>ydata</code>
using <code>gjamTrimY</code>.</p>
<p>If execution is stopped with the message
<code>overfitted covariance</code>, then try reducing <code>N</code> and
<code>r</code> in <code>reductList</code>.</p>
<p><br></p>
</div>
<div id="reference-notes" class="section level1">
<h1><span style="color:darkgreen">reference notes</span></h1>
<div id="model-summary-1" class="section level2">
<h2><span style="color:teal">model summary</span></h2>
<p>An observation consists of environmental variables and species
attributes, <span class="math inline">\(\lbrace \mathbf{x}_{i},
\mathbf{y}_{i}\rbrace\)</span>, <span class="math inline">\(i = 1,...,
n\)</span>. The vector <span class="math inline">\(\mathbf{x}_{i}\)</span> contains predictors <span class="math inline">\(x_{iq}: q = 1,..., Q\)</span>. The vector <span class="math inline">\(\mathbf{y}_{i}\)</span> contains attributes
(responses), such as species abundance, presence-absence, and so forth,
<span class="math inline">\(y_{is}: s = 1,..., S\)</span>. The effort
<span class="math inline">\(E_{is}\)</span> invested to obtain the
observation of response <span class="math inline">\(s\)</span> at
location <span class="math inline">\(i\)</span> can affect the
observation. The combinations of continuous and discrete measurements in
observed <span class="math inline">\(\mathbf{y}_{i}\)</span> motivate
the three elements of <code>gjam</code>.</p>
<p>A length-<span class="math inline">\(S\)</span> vector <span class="math inline">\(\mathbf{w}_{i}\in{\Re}^S\)</span> represents
response <span class="math inline">\(\mathbf{y}_i\)</span> in continuous
space. This continuous space allows for the dependence structure with a
covariance matrix. An element <span class="math inline">\(w_{is}\)</span> can be known (e.g., continuous
response <span class="math inline">\(y_{is}\)</span>) or unknown (e.g.,
discrete responses).</p>
<p>A length-<span class="math inline">\(S\)</span> vector of integers
<span class="math inline">\(\mathbf{z}_{i}\)</span> represents <span class="math inline">\(\mathbf{y}_i\)</span> in discrete space. Each
observed <span class="math inline">\(y_{is}\)</span> is assigned to an
interval <span class="math inline">\(z_{is} \in
\{0,...,K_{is}\}\)</span>. The number of intervals <span class="math inline">\(K_{is}\)</span> can differ between observations
and between species, because each species can be observed in different
ways.</p>
<p>The partition of continuous space at points <span class="math inline">\(p_{is,z} \in{\mathcal{P}}\)</span> defines
discrete intervals <span class="math inline">\(z_{is}\)</span>. Two
values <span class="math inline">\((p_{is,k}, p_{is,k+1}]\)</span> bound
the <span class="math inline">\(k^{th}\)</span> interval of <span class="math inline">\(s\)</span> in observation <span class="math inline">\(i\)</span>. Intervals are contiguous and provide
support over the real line <span class="math inline">\((-\infty,
\infty)\)</span>. For discrete observations, <span class="math inline">\(k\)</span> is a censored interval, and <span class="math inline">\(w_{is}\)</span> is a latent variable. The set of
censored intervals is <span class="math inline">\(\mathcal{C}\)</span>.
The partition set <span class="math inline">\(\mathcal{P}\)</span> can
include both known (discrete counts, including composition data) and
unknown (ordinal, categorical) points.</p>
<p>An observation <span class="math inline">\(y\)</span> maps to <span class="math inline">\(w\)</span>,</p>
<p><span class="math display">\[y_{is} = \left \{
\begin{matrix}
\ w_{is} &amp; continuous\\
\ z_{is}, &amp; w_{is} \in (p_{z_{is}}, p_{z_{is} + 1}] &amp; discrete
\end{matrix}
\right.\]</span></p>
<p>Effort <span class="math inline">\(E_{is}\)</span> affects the
partition for discrete data. For the simple case where there is no error
in the assignment of discrete intervals, <span class="math inline">\(\mathbf{z}_i\)</span> is known, and the model for
<span class="math inline">\(\mathbf{w}_i\)</span> is</p>
<p><span class="math display">\[\mathbf{w}_i|\mathbf{x}_i, \mathbf{y}_i,
\mathbf{E}_i \sim MVN(\boldsymbol{\mu}_i,\boldsymbol{\Sigma}) \times
\prod_{s=1}^S\mathcal{I}_{is}\]</span> <span class="math display">\[\boldsymbol{\mu}_i =
\mathbf{B}&#39;\mathbf{x}_i\]</span> <span class="math display">\[\mathcal{I}_{is} = \prod_{k \in
\mathcal{C}}I_{is,k}^{I(y_{is} = k)} (1 - I_{is,k})^{I(y_{is} \neq
k)}\]</span></p>
<p>where <span class="math inline">\(I_{is} =I(p_{z_{is}} &lt; w_{is}
&lt; p_{z_{is} + 1}]\)</span>, <span class="math inline">\(\mathcal{C}\)</span> is the set of discrete
intervals, <span class="math inline">\(\mathbf{B}\)</span> is a <span class="math inline">\(Q \times S\)</span> matrix of coefficients, and
<span class="math inline">\(\boldsymbol{\Sigma}\)</span> is a <span class="math inline">\(S \times S\)</span> covariance matrix. There is a
correlation matrix associated with <span class="math inline">\(\boldsymbol{\Sigma}\)</span>,</p>
<p><span class="math display">\[\mathbf{R}_{s,s&#39;} =
\frac{\boldsymbol{\Sigma}_{s,s&#39;}}{\sqrt{\boldsymbol{\Sigma}_{s,s}
\boldsymbol{\Sigma}_{s&#39;,s&#39;}}}\]</span></p>
<p>For <strong>presence-absence</strong> (binary) data, <span class="math inline">\(\mathbf{p}_{is} = (-\infty, 0, \infty)\)</span>.
This is equivalent to Chib and Greenberg’s (2008) model, which could be
written <span class="math inline">\(\mathcal{I}_{is} = I(w_{is} &gt;
0)^{y_{is}}I(w_{is} \leqslant 0)^{1 - y_{is}}\)</span>.</p>
<p>For a continous variable with point mass at zero, <strong>continuous
abundance</strong>, this is a multivariate Tobit model, with <span class="math inline">\(\mathcal{I}_{is} = I(w_{is} = y_{is})^{I(y_{is}
&gt; 0)}I(w_{is} \leqslant 0)^{I(y_{is} = 0)}\)</span>. This is the same
partition used for the probit model, the difference being that the
positive values in the Tobit are uncensored.</p>
<p><strong>Categorical</strong> responses fit within the same framework.
Each categorical response occupies as many columns in <span class="math inline">\(\mathbf{Y}\)</span> as there are independent
levels in response <span class="math inline">\(s\)</span>, levels being
<span class="math inline">\(k = 1,..., K_{s}-1\)</span>. For example, if
randomly sampled plots are scored by one of five cover types, then there
are four columns in <span class="math inline">\(\mathbf{Y}\)</span> for
the response <span class="math inline">\(s\)</span>. The four columns
can have at most one <span class="math inline">\(1\)</span>. If all four
columns are <span class="math inline">\(0\)</span>, then the reference
level is observed. The observed level has the largest value of <span class="math inline">\(w_{is,k}\)</span> (Table 1). This is similar to
Zhang et al.’s (2008) model for categorical data.</p>
<p>For <strong>ordinal counts</strong> gjam is Lawrence et al.’s (2008)
model having the partition <span class="math inline">\(\mathbf{p}_{is} =
(-\infty, 0, p_{is,2}, p_{is,3},..., p_{is,K}, \infty)\)</span>, where
all but the first two and the last elements must be inferred. The
partition must be inferred, because the ordinal scale is only
relative.</p>
<p>Like categorical data, <strong>composition</strong> data have one
reference class. For this and other <strong>discrete count</strong>
data, the partition for observation <span class="math inline">\(i\)</span> can be defined to account for sample
effort (next section).</p>
</div>
<div id="more-on-parameter-dimensions" class="section level2">
<h2><span style="color:teal">more on parameter dimensions</span></h2>
<p>Unlike a univariate model that has one <span class="math inline">\(Y\)</span> per observation or multivariate models
where all <span class="math inline">\(Y\)</span>’s have the same
dimension, gjam has <span class="math inline">\(Y\)</span>’s on multiple
dimensions. So there are two sets of dimensions to consider, the
dimensions for the <span class="math inline">\(X\)</span>’s and those
for the <span class="math inline">\(Y\)</span>’s. To avoid more notation
I just refer to the dimension of a coefficient in the unstandardized
coefficient matrix <span class="math inline">\(\mathbf{B}_u\)</span> as
<span class="math inline">\(W/X\)</span> (Table 2). Except for responses
that have no dimension (presence-absence, ordinal, categorical) <span class="math inline">\(W\)</span> has the same dimension as <span class="math inline">\(Y\)</span> (or <span class="math inline">\(Y/E\)</span>, if effort is specified).
<code>gjam</code> returns unstandardized coefficients in tables
<code>parameters$betaMuUn, parameters$betaSeUn</code>, and in MCMC
<code>chains$bgibbsUn</code>, because they are not prone to be
misinterpreted by a user who has supplied unstandardized predictors in
<code>xdata</code>. I refer to the coefficient matrix as <span class="math inline">\(\mathbf{B}_u\)</span> and corresponding
unstandardized design matrix as <span class="math inline">\(\mathbf{X}_u\)</span>. Each row of
<code>$chains$bgibbsUn</code> is one draw from the <span class="math inline">\(Q \times S\)</span> matrix <span class="math inline">\(\mathbf{B}_u\)</span>.</p>
<p>Models are commonly fitted to covariates <span class="math inline">\(X\)</span> that are ‘standardized’ for mean and
variance. Standardization can stabilize posterior simulation. It is
desirable when coefficients are needed in standard deviations. Inside
<code>gjam</code> design matrix <span class="math inline">\(\mathbf{X}\)</span>, and thus <span class="math inline">\(\mathbf{B}\)</span>, are standardized, thus having
dimension <span class="math inline">\(W\)</span>, not <span class="math inline">\(W/X\)</span>. Of course, for variables in
<code>xdata</code> supplied in standarized form, <span class="math inline">\(\mathbf{B} = \mathbf{B}_u\)</span>. See
<strong>Algorithm summary</strong>. Variables returned by
<code>gjam</code>, including MCMC chains in <code>$chains$bgibbs</code>
and posterior means and standard errors <code>$parameters$betaMu</code>
and <code>$parameters$betaSe</code> are standardized.</p>
<p>The third set of scales comes from the correlation scale for the
<span class="math inline">\(W\)</span>’s. The correlation scale can be
useful when considering responses that have different dimensions. In
addition to <span class="math inline">\(\mathbf{B}_u\)</span> I provide
parameters on the correlation scale. This correlation scale is <span class="math inline">\(\mathbf{B}_r = \mathbf{B}
\mathbf{D}^{-1/2}\)</span>, where <span class="math inline">\(\mathbf{D}
= diag(\boldsymbol{\Sigma})\)</span>. If <span class="math inline">\(\mathbf{X}\)</span> is standardized, <span class="math inline">\(\mathbf{B}_r\)</span> is dimensionless. The MCMC
chains in <code>$chains$bFacGibbs</code> and the estimates in
<code>$parameterTable$fBetaMu</code> and
<code>$parameterTable$fBetaSd</code> are standardized for <span class="math inline">\(X\)</span> (standard deviation scale) and for
<span class="math inline">\(W\)</span> (correlation scale). They are
dimensionless.</p>
<p>For sensitivity over all species and for comparisons between
predictors I provide standardized sensitivity in a length-<span class="math inline">\(Q\)</span> vector <span class="math inline">\(\mathbf{f}\)</span>. The sensitivity matrix to
<span class="math inline">\(X\)</span> across the full model is given
by</p>
<p><span class="math display">\[\mathbf{F} =
\mathbf{B}\boldsymbol{\Sigma}^{-1} \mathbf{B}&#39;\]</span></p>
<p>Note that <span class="math inline">\(\mathbf{F}\)</span> takes <span class="math inline">\(\mathbf{B}_r\)</span>, not <span class="math inline">\(\mathbf{B}\)</span>, and not <span class="math inline">\(\mathbf{B}_u\)</span>. The sensitivity matrix
<span class="math inline">\(\mathbf{F}\)</span> is
<code>$parameters$fmatrix</code>. The sensitivity vector <span class="math inline">\(\mathbf{f} = diag( \mathbf{F} )\)</span> is
<code>vector $parameters$fMu</code>. Details are given in Clark et
al. (2017).</p>
</div>
<div id="more-on-factors-in-mathbfx" class="section level2">
<h2><span style="color:teal">more on factors in <span class="math inline">\(\mathbf{X}\)</span></span></h2>
<p>The coefficient matrix <span class="math inline">\(\boldsymbol{\tilde{\mathbf{B}}}\)</span> is useful
when there are <strong>factors</strong> in the model. Factor treatment
in <code>gjam</code> follows the convention where a reference level is
taken as the overall intercept, and remaining coefficients are added to
the intercept. The reference level can be controlled with the R function
<code>relevel</code>. This approach makes sense in the ANOVA context,
where an experiment has a control level to which other treatment levels
are to be compared. A ‘significant’ level is different from the
reference (e.g., control), but we are not told about its relationship to
other levels. The coefficients in <code>$parameters$betaMu</code> and
<code>$parameters$betaSd</code> are reported this way. Should it be
needed, the contrasts matrix for this design is returned as a list for
all factors in the model as <code>$inputs$factorBeta$contrast</code> and
as a single contrasts matrix for the entire model as
<code>$inputs$factorBeta$eCont</code>.</p>
<p>This standard structure is not the best way to compare factors in
many ecological data sets, where a factor might represent soil type,
cover type, fishing gear, and so on. In all of these cases there is no
‘control’ treatment. Here it is more useful to know how all levels
relate to the mean taken across factor levels.</p>
<p>To provide more informative comparisons across factor levels and
species I introduce a <span class="math inline">\(Q_1 \times S\)</span>
recontrast matrix that translates <span class="math inline">\(\mathbf{B}\)</span>, with intercept, to all factor
levels, without intercept. Consider a three-level factor with levels
<code>a, b, c</code>, the first being the reference class. There is a
matrix <span class="math inline">\(\mathbf{G}\)</span></p>
<pre><code>##   intercept  b  c
## a         1 -1 -1
## b         1  1  0
## c         1  0  1</code></pre>
<p>and a matrix <span class="math inline">\(\mathbf{H}\)</span>,</p>
<pre><code>##            a b c
## intercept  1 0 0
## b         -1 1 0
## c         -1 0 1</code></pre>
<p>With <span class="math inline">\(\mathbf{L&#39;} =
\mathbf{G}^{-1}\)</span>, the recontrasted coefficients are</p>
<p><span class="math display">\[\mathbf{\tilde{B}} =
\mathbf{L}\mathbf{B}\]</span></p>
<p>The rows of <span class="math inline">\(\mathbf{\tilde{B}}\)</span>
correspond to all factor levels. The intercept does not appear, because
it has been distributed across factor levels. The corresponding design
matrix is</p>
<p><span class="math display">\[\mathbf{\tilde{X}} =
\mathbf{X}\mathbf{H}\]</span></p>
<p>If there are multiple factors then <span class="math inline">\(Q_1
&gt; Q\)</span>, because the intercept expands to the reference classes
for each factor. <span class="math inline">\(\mathbf{L}\)</span> is
provided as <code>$inputs$factorBeta$lCont</code>.</p>
<p>With factors, the sensitivity matrix reported in
<code>$parameters$fmatrix</code>is</p>
<p><span class="math display">\[\mathbf{F} =
\mathbf{\tilde{B}}\boldsymbol{\Sigma}^{-1}
\mathbf{\tilde{B}&#39;}\]</span></p>
<p>The response matrix in <code>$parameters$ematrix</code> is</p>
<p><span class="math display">\[\mathbf{E} = \mathbf{\tilde{B}}
\mathbf{\tilde{V}} \mathbf{\tilde{B}&#39;}\]</span></p>
<p>where <span class="math inline">\(\mathbf{\tilde{V}} = cov
\left(\mathbf{X} \mathbf{H} \right)\)</span>.</p>
<p><br></p>
</div>
</div>
<div id="algorithm-summary" class="section level1">
<h1><span style="color:darkgreen">algorithm summary</span></h1>
<p>Model fitting is done by Gibbs sampling. The design matrix <span class="math inline">\(\mathbf{X}\)</span> is centered and standardized.
Parameters <span class="math inline">\(\mathbf{B}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> are sampled
directly,</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\boldsymbol{\Sigma}|\mathbf{W},
\mathbf{B}\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{B}| \boldsymbol{\Sigma},
\mathbf{W}\)</span></p></li>
<li><p>For unknown partition (ordinal variables) the partition is
sampled, <span class="math inline">\(\mathcal{P}|\mathbf{Z},
\mathbf{W}\)</span></p></li>
<li><p>For ordinal, presence-absence, and categorical data, latent
variables are drawn on the correlation scale, <span class="math inline">\(\mathbf{W}|\mathbf{R}, \boldsymbol{\alpha},
\mathbf{P}\)</span>, where <span class="math inline">\(\mathbf{R} =
\mathbf{D}^{-1/2}\boldsymbol{\Sigma}\mathbf{D}^{-1/2}\)</span>, <span class="math inline">\(\boldsymbol{\alpha} =
\mathbf{D}^{-1/2}\mathbf{B}\)</span>, <span class="math inline">\(\mathbf{P} =
\mathbf{D}^{-1/2}\mathcal{P}\)</span>, and <span class="math inline">\(\mathbf{D} =
diag(\boldsymbol{\Sigma})\)</span>.<br />
For other variables that are discrete or censored, latent variables are
drawn on the covariance scale, <span class="math inline">\(\mathbf{W}|
\boldsymbol{\Sigma}, \mathbf{B}, \mathcal{P}\)</span>.</p></li>
</ol>
<p>Parameters in <code>$chains$bgibbsUn</code> are returned on the
original scale <span class="math inline">\(\mathbf{X}_u\)</span>. Let
<span class="math inline">\(\mathbf{X}_u\)</span> be the
uncentered/unstandardized version of <span class="math inline">\(\mathbf{X}\)</span>. Parameters are returned as
<span class="math inline">\(\mathbf{B}_u = \left(\mathbf{X}&#39;_u
\mathbf{X}_u \right)^{-1}\mathbf{X}&#39;_u
\mathbf{X}\mathbf{B}\)</span>. Likewise, <code>$x</code> is returned on
the original scale, i.e., it is <span class="math inline">\(\mathbf{X}_u\)</span>.</p>
<p>Dimension reduction represents the covariance matrix as <span class="math inline">\(\Sigma = \mathbf{A} \mathbf{A}&#39; + \sigma^2
\mathbf{I}\)</span>. The <span class="math inline">\(S \times r\)</span>
matrix <span class="math inline">\(\mathbf{A}\)</span> generates a
random effect with prior distribution <span class="math inline">\(\mathbf{a}_i \sim \mathbf{A} \times
MVN(\mathbf{0}_r, \mathbf{I}_r )\)</span>. The (posterior) estimate of
<span class="math inline">\(\mathbf{a}_i\)</span> depends on observed
<span class="math inline">\(\mathbf{y}_i\)</span>. For in-sample
prediction, we have <span class="math inline">\(\mathbf{w}_i \sim MVN(
\boldsymbol{\mu}_i + \mathbf{a}_i, \sigma^2 \mathbf{I})\)</span>. For
out-of-sample prediction the random effect is marginalized <span class="math inline">\(\mathbf{w}_i \sim MVN( \boldsymbol{\mu}_i,
\Sigma)\)</span>. For variables on the correlation scale, both the mean
and the covariance are on the correlation scale.</p>
<p>Below are mean and variance for prediction sampling, where <span class="math inline">\(\boldsymbol{\mu}_i =
\mathbf{B}&#39;\mathbf{x}_i\)</span>. Values are (mean,
covariance/correlation). Most importantly, for prediction, there is no
partition, because <span class="math inline">\(\mathbf{y}_i\)</span> is
unknown and, thus, <span class="math inline">\(\mathbf{w}_i\)</span> is
unconstrained by observation:</p>
<table>
<colgroup>
<col width="27%" />
<col width="38%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">.</th>
<th align="center">covariance scale</th>
<th align="left">correlation scale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Not dimension reduction:</td>
<td align="center"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="center">in-</td>
<td align="center"><span class="math inline">\(\boldsymbol{\mu}_i,
\Sigma\)</span></td>
<td align="left"><span class="math inline">\(\mathbf{D}^{-1/2}
\boldsymbol{\mu}_i, \mathbf{R}\)</span></td>
</tr>
<tr class="odd">
<td align="center">out-</td>
<td align="center"><span class="math inline">\(\boldsymbol{\mu}_i,
\Sigma\)</span></td>
<td align="left"><span class="math inline">\(\mathbf{D}^{-1/2}
\boldsymbol{\mu}_i, \mathbf{R}\)</span></td>
</tr>
<tr class="even">
<td align="center">Dimension reduction:</td>
<td align="center">.</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="center">in-</td>
<td align="center"><span class="math inline">\(\boldsymbol{\mu}_i +
\mathbf{a}_i\)</span></td>
<td align="left"><span class="math inline">\(\mathbf{D}^{-1/2} (
\boldsymbol{\mu}_i + \mathbf{a}_i), \mathbf{I}_s\)</span></td>
</tr>
<tr class="even">
<td align="center">out-</td>
<td align="center"><span class="math inline">\(\boldsymbol{\mu}_i,
\Sigma\)</span></td>
<td align="left"><span class="math inline">\(\mathbf{D}^{-1/2}
\boldsymbol{\mu}_i, \mathbf{R}\)</span></td>
</tr>
</tbody>
</table>
<p>Inverse prediction of input variables provides sensitivity analysis
(Clark et al. 2011, 2014). Columns in <span class="math inline">\(\mathbf{X}\)</span> that are linear (not involved
in interactions, polynomial terms, or factors) are sampled directly from
the inverted model. Others are sampled by Metropolis. Sampling is
described in the Supplement file to Clark et al. (2017).</p>
<p><a href="http://sites.nicholas.duke.edu/clarklab/code/">website</a></p>
<p><br></p>
</div>
<div id="acknowledgements" class="section level1">
<h1><span style="color:darkgreen">acknowledgements</span></h1>
<p>For valuable feedback on the model and computation I thank Bene
Bachelot, Alan Gelfand, Diana Nemergut, Erin Schliep, Bijan
Seyednasrollah, Daniel Taylor-Rodriquez, Brad Tomasek, Phillip Turner,
and Stacy Zhang. Daniel Taylor-Rodriguez implemented the dimension
reduction. I thank the members of NSF’s <em>SAMSI</em> program on
<em>Ecological Statistics</em> and my class <em>Bayesian Analysis of
Environmental Data</em> at Duke University. Funding came from NSF’s
Macrosystems Biology and EAGER programs.</p>
<p><br></p>
</div>
<div id="references" class="section level1">
<h1><span style="color:darkgreen">references</span></h1>
<p>Brynjarsdottir, J. and A.E. Gelfand. 2014. Collective sensitivity
analysis for ecological regression models with multivariate response.
<em>Journal of Biological, Environmental, and Agricultural
Statistics</em> 19, 481-502.</p>
<p>Chib, S and E Greenberg. 1998. Analysis of multivariate probit
models. <em>Biometrika</em> 85, 347-361.</p>
<p>Clark, JS 2016. Why species tell us more about traits than traits
tell us about species, <em>Ecology</em> 97, 1979-1993.</p>
<p>Clark, JS, DM Bell, MH Hersh, and L Nichols. 2011. Climate change
vulnerability of forest biodiversity: climate and resource tracking of
demographic rates. <em>Global Change Biology</em> 17, 1834-1849.</p>
<p>Clark, JS, DM Bell, M Kwit, A Powell, and K Zhu. 2013. Dynamic
inverse prediction and sensitivity analysis with high-dimensional
responses: application to climate-change vulnerability of biodiversity.
<em>Journal of Biological, Environmental, and Agricultural
Statistics</em> 18, 376-404.</p>
<p>Clark, JS, AE Gelfand, CW Woodall, and K Zhu. 2014. More than the sum
of the parts: forest climate response from joint species distribution
models. <em>Ecological Applications</em> 24, 990-999</p>
<p>Clark, JS, D Nemergut, B Seyednasrollah, P Turner, and S Zhang. 2017.
Generalized joint attribute modeling for biodiversity analysis:
Median-zero, multivariate, multifarious data, <em>Ecological
Monographs</em> 87, 34–56.</p>
<p>Lawrence, E, D Bingham, C Liu, and V N Nair (2008) Bayesian inference
for multivariate ordinal data using parameter expansion.
<em>Technometrics</em> 50, 182-191.</p>
<p>Taylor-Rodriguez, D, K Kaufeld, E Schliep, JS Clark, and AE Gelfand,
2017. Joint Species distribution modeling: dimension reduction using
Dirichlet processes, <em>Bayesian Analysis</em> in press.</p>
<p>Zhang, X, WJ Boscardin, and TR Belin. 2008. Bayesian analysis of
multivariate nominal measures using multivariate multinomial probit
models. <em>Computational Statistics and Data Analysis</em> 52,
3697-3708.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
